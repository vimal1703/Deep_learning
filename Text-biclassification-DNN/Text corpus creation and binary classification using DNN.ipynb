{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8062bf6f",
   "metadata": {},
   "source": [
    "# Text corpus creation and binary classification using DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5648acbd",
   "metadata": {},
   "source": [
    "### 1: Dataset Creation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85389076",
   "metadata": {},
   "source": [
    "__Dataset is created as text file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4e8df12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "import re\n",
    "from string import punctuation\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5ecbb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(\"dataset.txt\", delimiter=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6173b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quotes</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Look deep into nature, and then you will under...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Colors are the smiles of nature.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I believe in God, only I spell it Nature.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nature does not hurry, yet everything is accom...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you truly love nature, you will find beauty...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Quotes  Labels\n",
       "0  Look deep into nature, and then you will under...       0\n",
       "1                   Colors are the smiles of nature.       0\n",
       "2          I believe in God, only I spell it Nature.       0\n",
       "3  Nature does not hurry, yet everything is accom...       0\n",
       "4  If you truly love nature, you will find beauty...       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33cba2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the dataset= 40 \n",
      "Number of columns in the dataset= 2 \n",
      "Size of dataset = 80\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows in the dataset=\", df.shape[0], \n",
    "      \"\\nNumber of columns in the dataset=\", df.shape[1], \n",
    "      \"\\nSize of dataset =\", df.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ecc2b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40 entries, 0 to 39\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Quotes  40 non-null     object\n",
      " 1   Labels  40 non-null     int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 768.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d73ae6",
   "metadata": {},
   "source": [
    "### 2. Pre-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ef26026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    nopunc = [char for char in text if char not in punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    return [word for word in nopunc.split() if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77865c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Clean_Quotes'] = df['Quotes'].apply(lambda x: ' '.join(clean_text(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b893c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quotes</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Clean_Quotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Look deep into nature, and then you will under...</td>\n",
       "      <td>0</td>\n",
       "      <td>look deep nature understand everything better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Colors are the smiles of nature.</td>\n",
       "      <td>0</td>\n",
       "      <td>colors smiles nature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I believe in God, only I spell it Nature.</td>\n",
       "      <td>0</td>\n",
       "      <td>believe god spell nature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nature does not hurry, yet everything is accom...</td>\n",
       "      <td>0</td>\n",
       "      <td>nature hurry yet everything accomplished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you truly love nature, you will find beauty...</td>\n",
       "      <td>0</td>\n",
       "      <td>truly love nature find beauty everywhere</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Quotes  Labels  \\\n",
       "0  Look deep into nature, and then you will under...       0   \n",
       "1                   Colors are the smiles of nature.       0   \n",
       "2          I believe in God, only I spell it Nature.       0   \n",
       "3  Nature does not hurry, yet everything is accom...       0   \n",
       "4  If you truly love nature, you will find beauty...       0   \n",
       "\n",
       "                                    Clean_Quotes  \n",
       "0  look deep nature understand everything better  \n",
       "1                           colors smiles nature  \n",
       "2                       believe god spell nature  \n",
       "3       nature hurry yet everything accomplished  \n",
       "4       truly love nature find beauty everywhere  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8284dd30",
   "metadata": {},
   "source": [
    "#### Creating TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26d055ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TD-IDF Vectorizer\n",
      "\n",
      "    accomplished  acquiring       act      acts   adopted  advanced  advances  \\\n",
      "0       0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "1       0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "2       0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "3       0.519026   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "4       0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "5       0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "6       0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "7       0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "8       0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "9       0.000000   0.000000  0.000000  0.574749  0.000000  0.000000   0.00000   \n",
      "10      0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "11      0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "12      0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "13      0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "14      0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "15      0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "16      0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "17      0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "18      0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "19      0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "20      0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "21      0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "22      0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "23      0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "24      0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "25      0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "26      0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "27      0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "28      0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "29      0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "30      0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "31      0.000000   0.452531  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "32      0.000000   0.000000  0.000000  0.000000  0.664272  0.000000   0.00000   \n",
      "33      0.000000   0.000000  0.447214  0.000000  0.000000  0.000000   0.00000   \n",
      "34      0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "35      0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "36      0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "37      0.000000   0.000000  0.000000  0.000000  0.000000  0.484147   0.00000   \n",
      "38      0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.00000   \n",
      "39      0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   0.40573   \n",
      "\n",
      "    agreement  appallingly     argue  ...       use    useful     visit  \\\n",
      "0    0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "1    0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "2    0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "3    0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "4    0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "5    0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "6    0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "7    0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "8    0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "9    0.000000     0.000000  0.574749  ...  0.000000  0.000000  0.000000   \n",
      "10   0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "11   0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.574749   \n",
      "12   0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "13   0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "14   0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "15   0.486865     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "16   0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "17   0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "18   0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "19   0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "20   0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "21   0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "22   0.000000     0.443909  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "23   0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "24   0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "25   0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "26   0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "27   0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "28   0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "29   0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "30   0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "31   0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "32   0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "33   0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "34   0.000000     0.000000  0.000000  ...  0.508101  0.000000  0.000000   \n",
      "35   0.000000     0.000000  0.000000  ...  0.000000  0.484147  0.000000   \n",
      "36   0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "37   0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "38   0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "39   0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "\n",
      "     whether     whole     word     work     world     wrong       yet  \n",
      "0   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "1   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "2   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "3   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.466681  \n",
      "4   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "5   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "6   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "7   0.000000  0.000000  0.00000  0.00000  0.327909  0.000000  0.000000  \n",
      "8   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "9   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "10  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "11  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "12  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "13  0.000000  0.000000  0.00000  0.00000  0.395900  0.000000  0.000000  \n",
      "14  0.000000  0.411566  0.00000  0.00000  0.340609  0.000000  0.000000  \n",
      "15  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "16  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "17  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "18  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "19  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "20  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "21  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "22  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "23  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "24  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "25  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "26  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "27  0.000000  0.000000  0.40573  0.40573  0.000000  0.000000  0.364811  \n",
      "28  0.681324  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "29  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "30  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "31  0.000000  0.000000  0.00000  0.00000  0.000000  0.406893  0.000000  \n",
      "32  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "33  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "34  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "35  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "36  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "37  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "38  0.000000  0.000000  0.00000  0.00000  0.000000  0.418461  0.000000  \n",
      "39  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "\n",
      "[40 rows x 149 columns]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "tfidf_wm = vectorizer.fit_transform(df['Clean_Quotes'])\n",
    "\n",
    "tfidf_tokens = vectorizer.get_feature_names()\n",
    "\n",
    "df_tfidf = pd.DataFrame(data=tfidf_wm.toarray(), columns=tfidf_tokens)\n",
    "\n",
    "print(\"\\nTD-IDF Vectorizer\\n\")\n",
    "print(df_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "328349a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 149)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f835d8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accomplished</th>\n",
       "      <th>acquiring</th>\n",
       "      <th>act</th>\n",
       "      <th>acts</th>\n",
       "      <th>adopted</th>\n",
       "      <th>advanced</th>\n",
       "      <th>advances</th>\n",
       "      <th>agreement</th>\n",
       "      <th>appallingly</th>\n",
       "      <th>argue</th>\n",
       "      <th>...</th>\n",
       "      <th>use</th>\n",
       "      <th>useful</th>\n",
       "      <th>visit</th>\n",
       "      <th>whether</th>\n",
       "      <th>whole</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "      <th>world</th>\n",
       "      <th>wrong</th>\n",
       "      <th>yet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.519026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.466681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 149 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accomplished  acquiring  act  acts  adopted  advanced  advances  agreement  \\\n",
       "0      0.000000        0.0  0.0   0.0      0.0       0.0       0.0        0.0   \n",
       "1      0.000000        0.0  0.0   0.0      0.0       0.0       0.0        0.0   \n",
       "2      0.000000        0.0  0.0   0.0      0.0       0.0       0.0        0.0   \n",
       "3      0.519026        0.0  0.0   0.0      0.0       0.0       0.0        0.0   \n",
       "4      0.000000        0.0  0.0   0.0      0.0       0.0       0.0        0.0   \n",
       "\n",
       "   appallingly  argue  ...  use  useful  visit  whether  whole  word  work  \\\n",
       "0          0.0    0.0  ...  0.0     0.0    0.0      0.0    0.0   0.0   0.0   \n",
       "1          0.0    0.0  ...  0.0     0.0    0.0      0.0    0.0   0.0   0.0   \n",
       "2          0.0    0.0  ...  0.0     0.0    0.0      0.0    0.0   0.0   0.0   \n",
       "3          0.0    0.0  ...  0.0     0.0    0.0      0.0    0.0   0.0   0.0   \n",
       "4          0.0    0.0  ...  0.0     0.0    0.0      0.0    0.0   0.0   0.0   \n",
       "\n",
       "   world  wrong       yet  \n",
       "0    0.0    0.0  0.000000  \n",
       "1    0.0    0.0  0.000000  \n",
       "2    0.0    0.0  0.000000  \n",
       "3    0.0    0.0  0.466681  \n",
       "4    0.0    0.0  0.000000  \n",
       "\n",
       "[5 rows x 149 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d5d480",
   "metadata": {},
   "source": [
    "### Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4534a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_features=2, n_redundant=0, \n",
    "                           n_informative=2, random_state=1, \n",
    "                           n_clusters_per_class=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bb46c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89b985e",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bec93d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =Sequential()\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ddbf46fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='RMSprop',\n",
    "              metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f437260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.1721 - accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1568 - accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1465 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1385 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1308 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1243 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1184 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1124 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1071 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1020 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0970 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0925 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0881 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0839 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0797 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0757 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0720 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0619 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0588 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0531 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0504 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0479 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0454 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0431 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0387 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0367 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0348 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0312 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0295 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0279 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0236 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0222 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0187 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 0.0176 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0131 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 972us/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 973us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9.4145e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.8120e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8.2595e-04 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 7.6332e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 939us/step - loss: 7.1358e-04 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 6.6346e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 6.2240e-04 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5.8169e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 5.4438e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 5.0941e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4.7639e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 4.4347e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e4e0a44e50>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9a13295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 101ms/step - loss: 6.2657e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0006265719421207905, 1.0]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5912c6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                96        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 129\n",
      "Trainable params: 129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e4009b",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cda53afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 nodes\n",
    "\n",
    "model =Sequential()\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='RMSprop',\n",
    "              metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11a7de4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e4e1cd52e0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "525f5614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1781 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17810305953025818, 1.0]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3833d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16 nodes\n",
    "\n",
    "model =Sequential()\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='RMSprop',metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bdb903c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2974 - accuracy: 0.4933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e4e1e09cd0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22d06335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2903 - accuracy: 0.5200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2902664840221405, 0.5199999809265137]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9c285be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32 nodes\n",
    "\n",
    "model =Sequential()\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='RMSprop',metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "913b6c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1793 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e4e2084fa0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0405ae82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1735 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1734815537929535, 1.0]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "41941440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 64 nodes\n",
    "\n",
    "model =Sequential()\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='RMSprop',metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c92f8672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 310 calls to <function Model.make_train_function.<locals>.train_function at 0x000001E4E31B9C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2542 - accuracy: 0.4533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e4e4203bb0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "94764750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x000001E4E421D4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2339 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23386691510677338, 1.0]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0859fc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 128 nodes\n",
    "\n",
    "model =Sequential()\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='RMSprop',metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d04522f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x000001E4E4338670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3104 - accuracy: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e4e4348f40>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f8ccdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x000001E4E31B9940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2818 - accuracy: 0.5200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2817752957344055, 0.5199999809265137]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f853562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 256 nodes\n",
    "\n",
    "model =Sequential()\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='RMSprop',metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "068a744e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2074 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e4e202c340>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60d7db5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1758 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17583021521568298, 1.0]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ce86977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 512 nodes\n",
    "\n",
    "model =Sequential()\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='RMSprop',metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed9d1325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1996 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e4e54a9ac0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fec8004f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1596 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15961360931396484, 1.0]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2643bfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1028 nodes\n",
    "\n",
    "model =Sequential()\n",
    "model.add(Dense(1028,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='RMSprop',metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5bd8eaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2073 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e4e56d3040>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "77b2db84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1504 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1503923535346985, 1.0]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8db8838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 layers\n",
    "\n",
    "model =Sequential()\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='RMSprop',metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3a59fa17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2567 - accuracy: 0.5067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e4e67cb520>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "59ceea48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2359 - accuracy: 0.4800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23591509461402893, 0.47999998927116394]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b4840a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 layers\n",
    "model =Sequential()\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='RMSprop',metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "75c2e563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step - loss: 0.2373 - accuracy: 0.9733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e4e78f6b80>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0afefdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2216 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22162634134292603, 1.0]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b218fdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 layers\n",
    "model =Sequential()\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='RMSprop',metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3dd54eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2348 - accuracy: 0.5467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e4e7a9fc10>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7ce115bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2105 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21049949526786804, 1.0]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7746494a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 layers\n",
    "model =Sequential()\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='RMSprop',metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "786b445a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2388 - accuracy: 0.5467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e4e8c2ad00>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b62393ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 98ms/step - loss: 0.2238 - accuracy: 0.8800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2237820029258728, 0.8799999952316284]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "71ca9406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating the barchart\n",
    "bar={'8_nodes':0.13,'16_nodes':0.49,'32_nodes':1.0,'64_nodes':0.45,'128_nodes':0.33,'256_nodes':1.0,'512_nodes':1.0,'1028_nodes':1.0}\n",
    "nodes = list(bar.keys())\n",
    "acc = list(bar.values())\n",
    "\n",
    "fig = plt.figure(figsize = (12, 6))\n",
    "\n",
    "# creating the bar plot\n",
    "plt.bar(nodes, acc, color ='blue',width = 0.4)\n",
    "\n",
    "plt.xlabel(\"Number of nodes\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Computing accuracy for different no. of nodes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "54bd3b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating the barchart\n",
    "bar={'2 layers':0.5,'3 layers':0.9,'4 layers':0.5,'5 layers':0.5}\n",
    "layers = list(bar.keys())\n",
    "values = list(bar.values())\n",
    "\n",
    "fig = plt.figure(figsize = (12, 6))\n",
    "\n",
    "# creating the bar plot\n",
    "plt.bar(layers, values, color ='red',width = 0.4)\n",
    "\n",
    "plt.xlabel(\"Number of Layers\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Computing accuracy for different no. of Layers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba0ea1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
