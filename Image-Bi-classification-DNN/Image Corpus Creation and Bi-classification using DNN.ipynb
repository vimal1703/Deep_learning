{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8d1c5bb",
   "metadata": {},
   "source": [
    "# Image Corpus Creation and Binary Classification using DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c46cf5",
   "metadata": {},
   "source": [
    "### Steps 1- Dataset Creation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a333721",
   "metadata": {},
   "source": [
    "Dataset is created and the images are stored in separate folders for each class under one folder name 'Image'.\n",
    "\n",
    "Two classes of images are created they are:\n",
    "\n",
    "1. White Tiger\n",
    "\n",
    "2. Zebra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e950da",
   "metadata": {},
   "source": [
    "### Steps 2- Pre-Processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1925c6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time\n",
    "from time import process_time \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0d898f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "datadir =\"Image\"\n",
    "categories =['Tiger']\n",
    "\n",
    "for category in categories:\n",
    "    path = os.path.join(datadir, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "        plt.imshow(img_array, cmap='gray')\n",
    "        plt.show()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea1e289b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "datadir =\"Image\"\n",
    "categories =['Zebra']\n",
    "\n",
    "for category in categories:\n",
    "    path = os.path.join(datadir, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "        plt.imshow(img_array, cmap='gray')\n",
    "        plt.show()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f760585e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"Image\"\n",
    "categories = ['Tiger', 'Zebra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15a5df17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "img_size=500\n",
    "\n",
    "def preprocess():\n",
    "    for category in categories:\n",
    "        path = os.path.join(datadir, category)\n",
    "        class_num = categories.index(category)\n",
    "        \n",
    "        for img in os.listdir(path):\n",
    "            img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "            num_array = cv2.resize(img_array,(img_size, img_size))\n",
    "            \n",
    "            data.append([num_array, class_num])\n",
    "            \n",
    "preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f5d87ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cf85cd",
   "metadata": {},
   "source": [
    "### Steps 3- Dataset Preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "983588c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features,label in data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.asarray(X).reshape(-1,img_size,img_size,1)\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76646f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9239128a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the following:\n",
      "X_train = (15, 500, 500, 1) \n",
      "X_test = (5, 500, 500, 1) \n",
      "y_train = (15,) \n",
      "y_test = (5,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the following:\")\n",
    "print(\"X_train =\", X_train.shape, \"\\nX_test =\", X_test.shape, \"\\ny_train =\", y_train.shape, \"\\ny_test =\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ca1d73",
   "metadata": {},
   "source": [
    "### Step 4 - Model Creation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae20e5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=1, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df210c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1be5c6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 500, 500, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 500, 500, 1).\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4260 - binary_accuracy: 0.4667WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 500, 500, 1).\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4260 - binary_accuracy: 0.4667 - val_loss: 0.2779 - val_binary_accuracy: 0.5997\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3511 - binary_accuracy: 0.4670 - val_loss: 0.2487 - val_binary_accuracy: 0.5664\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2506 - binary_accuracy: 0.4797 - val_loss: 0.2718 - val_binary_accuracy: 0.4000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2530 - binary_accuracy: 0.5333 - val_loss: 0.2438 - val_binary_accuracy: 0.5899\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2568 - binary_accuracy: 0.4728 - val_loss: 0.2884 - val_binary_accuracy: 0.4000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2607 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5891\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2564 - binary_accuracy: 0.4731 - val_loss: 0.2787 - val_binary_accuracy: 0.4000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2559 - binary_accuracy: 0.5333 - val_loss: 0.2456 - val_binary_accuracy: 0.5859\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2532 - binary_accuracy: 0.4743 - val_loss: 0.2717 - val_binary_accuracy: 0.4000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2529 - binary_accuracy: 0.5333 - val_loss: 0.2468 - val_binary_accuracy: 0.5826\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2520 - binary_accuracy: 0.4755 - val_loss: 0.2694 - val_binary_accuracy: 0.4000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2521 - binary_accuracy: 0.5333 - val_loss: 0.2470 - val_binary_accuracy: 0.5810\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2518 - binary_accuracy: 0.4762 - val_loss: 0.2698 - val_binary_accuracy: 0.4000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2522 - binary_accuracy: 0.5333 - val_loss: 0.2466 - val_binary_accuracy: 0.5826\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2522 - binary_accuracy: 0.4755 - val_loss: 0.2716 - val_binary_accuracy: 0.4000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2529 - binary_accuracy: 0.5333 - val_loss: 0.2460 - val_binary_accuracy: 0.5837\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2528 - binary_accuracy: 0.4751 - val_loss: 0.2734 - val_binary_accuracy: 0.4000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2536 - binary_accuracy: 0.5333 - val_loss: 0.2457 - val_binary_accuracy: 0.5843\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2532 - binary_accuracy: 0.4749 - val_loss: 0.2738 - val_binary_accuracy: 0.4000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2537 - binary_accuracy: 0.5333 - val_loss: 0.2458 - val_binary_accuracy: 0.5837\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2531 - binary_accuracy: 0.4751 - val_loss: 0.2731 - val_binary_accuracy: 0.4000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2534 - binary_accuracy: 0.5333 - val_loss: 0.2461 - val_binary_accuracy: 0.5826\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2528 - binary_accuracy: 0.4755 - val_loss: 0.2724 - val_binary_accuracy: 0.4000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2531 - binary_accuracy: 0.5333 - val_loss: 0.2462 - val_binary_accuracy: 0.5821\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2526 - binary_accuracy: 0.4757 - val_loss: 0.2721 - val_binary_accuracy: 0.4000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2530 - binary_accuracy: 0.5333 - val_loss: 0.2462 - val_binary_accuracy: 0.5815\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2526 - binary_accuracy: 0.4760 - val_loss: 0.2722 - val_binary_accuracy: 0.4000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2531 - binary_accuracy: 0.5333 - val_loss: 0.2462 - val_binary_accuracy: 0.5815\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2527 - binary_accuracy: 0.4760 - val_loss: 0.2725 - val_binary_accuracy: 0.4000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2532 - binary_accuracy: 0.5333 - val_loss: 0.2461 - val_binary_accuracy: 0.5815\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2528 - binary_accuracy: 0.4760 - val_loss: 0.2728 - val_binary_accuracy: 0.4000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2532 - binary_accuracy: 0.5333 - val_loss: 0.2461 - val_binary_accuracy: 0.5815\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2528 - binary_accuracy: 0.4760 - val_loss: 0.2728 - val_binary_accuracy: 0.4000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2532 - binary_accuracy: 0.5333 - val_loss: 0.2461 - val_binary_accuracy: 0.5810\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2528 - binary_accuracy: 0.4762 - val_loss: 0.2727 - val_binary_accuracy: 0.4000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2532 - binary_accuracy: 0.5333 - val_loss: 0.2462 - val_binary_accuracy: 0.5804\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2527 - binary_accuracy: 0.4764 - val_loss: 0.2726 - val_binary_accuracy: 0.4000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2532 - binary_accuracy: 0.5333 - val_loss: 0.2462 - val_binary_accuracy: 0.5804\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2527 - binary_accuracy: 0.4764 - val_loss: 0.2726 - val_binary_accuracy: 0.4000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2531 - binary_accuracy: 0.5333 - val_loss: 0.2462 - val_binary_accuracy: 0.5799\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2527 - binary_accuracy: 0.4766 - val_loss: 0.2726 - val_binary_accuracy: 0.4000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2532 - binary_accuracy: 0.5333 - val_loss: 0.2462 - val_binary_accuracy: 0.5799\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2527 - binary_accuracy: 0.4766 - val_loss: 0.2727 - val_binary_accuracy: 0.4000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2532 - binary_accuracy: 0.5333 - val_loss: 0.2462 - val_binary_accuracy: 0.5792\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2527 - binary_accuracy: 0.4768 - val_loss: 0.2727 - val_binary_accuracy: 0.4000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2532 - binary_accuracy: 0.5333 - val_loss: 0.2462 - val_binary_accuracy: 0.5792\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2527 - binary_accuracy: 0.4768 - val_loss: 0.2727 - val_binary_accuracy: 0.4000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2532 - binary_accuracy: 0.5333 - val_loss: 0.2462 - val_binary_accuracy: 0.5784\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2527 - binary_accuracy: 0.4770 - val_loss: 0.2727 - val_binary_accuracy: 0.4000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2532 - binary_accuracy: 0.5333 - val_loss: 0.2462 - val_binary_accuracy: 0.5784\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2527 - binary_accuracy: 0.4770 - val_loss: 0.2727 - val_binary_accuracy: 0.4000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2532 - binary_accuracy: 0.5333 - val_loss: 0.2462 - val_binary_accuracy: 0.5773\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2527 - binary_accuracy: 0.4773 - val_loss: 0.2727 - val_binary_accuracy: 0.4000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2532 - binary_accuracy: 0.5333 - val_loss: 0.2462 - val_binary_accuracy: 0.5773\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2527 - binary_accuracy: 0.4773 - val_loss: 0.2727 - val_binary_accuracy: 0.4000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2532 - binary_accuracy: 0.5333 - val_loss: 0.2463 - val_binary_accuracy: 0.5763\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2527 - binary_accuracy: 0.4775 - val_loss: 0.2728 - val_binary_accuracy: 0.4000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2531 - binary_accuracy: 0.5333 - val_loss: 0.2463 - val_binary_accuracy: 0.5763\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2527 - binary_accuracy: 0.4775 - val_loss: 0.2728 - val_binary_accuracy: 0.4000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2531 - binary_accuracy: 0.5333 - val_loss: 0.2463 - val_binary_accuracy: 0.5753\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2527 - binary_accuracy: 0.4777 - val_loss: 0.2728 - val_binary_accuracy: 0.4000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2531 - binary_accuracy: 0.5333 - val_loss: 0.2463 - val_binary_accuracy: 0.5753\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2527 - binary_accuracy: 0.4777 - val_loss: 0.2728 - val_binary_accuracy: 0.4000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2531 - binary_accuracy: 0.5333 - val_loss: 0.2463 - val_binary_accuracy: 0.5753\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2527 - binary_accuracy: 0.4777 - val_loss: 0.2728 - val_binary_accuracy: 0.4000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2531 - binary_accuracy: 0.5333 - val_loss: 0.2463 - val_binary_accuracy: 0.5743\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2527 - binary_accuracy: 0.4779 - val_loss: 0.2728 - val_binary_accuracy: 0.4000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2531 - binary_accuracy: 0.5333 - val_loss: 0.2463 - val_binary_accuracy: 0.5743\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2527 - binary_accuracy: 0.4779 - val_loss: 0.2728 - val_binary_accuracy: 0.4000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2531 - binary_accuracy: 0.5333 - val_loss: 0.2463 - val_binary_accuracy: 0.5732\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2527 - binary_accuracy: 0.4781 - val_loss: 0.2728 - val_binary_accuracy: 0.4000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2531 - binary_accuracy: 0.5333 - val_loss: 0.2463 - val_binary_accuracy: 0.5732\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2527 - binary_accuracy: 0.4781 - val_loss: 0.2728 - val_binary_accuracy: 0.4000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2531 - binary_accuracy: 0.5333 - val_loss: 0.2463 - val_binary_accuracy: 0.5722\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2527 - binary_accuracy: 0.4783 - val_loss: 0.2729 - val_binary_accuracy: 0.4000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2531 - binary_accuracy: 0.5333 - val_loss: 0.2464 - val_binary_accuracy: 0.5722\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2527 - binary_accuracy: 0.4783 - val_loss: 0.2729 - val_binary_accuracy: 0.4000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2531 - binary_accuracy: 0.5333 - val_loss: 0.2464 - val_binary_accuracy: 0.5722\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2527 - binary_accuracy: 0.4783 - val_loss: 0.2729 - val_binary_accuracy: 0.4000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2531 - binary_accuracy: 0.5333 - val_loss: 0.2464 - val_binary_accuracy: 0.5712\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2527 - binary_accuracy: 0.4786 - val_loss: 0.2729 - val_binary_accuracy: 0.4000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2531 - binary_accuracy: 0.5333 - val_loss: 0.2464 - val_binary_accuracy: 0.5712\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2527 - binary_accuracy: 0.4786 - val_loss: 0.2729 - val_binary_accuracy: 0.4000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2531 - binary_accuracy: 0.5333 - val_loss: 0.2464 - val_binary_accuracy: 0.5702\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2527 - binary_accuracy: 0.4788 - val_loss: 0.2729 - val_binary_accuracy: 0.4000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2531 - binary_accuracy: 0.5333 - val_loss: 0.2464 - val_binary_accuracy: 0.5702\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2527 - binary_accuracy: 0.4788 - val_loss: 0.2729 - val_binary_accuracy: 0.4000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2531 - binary_accuracy: 0.5333 - val_loss: 0.2464 - val_binary_accuracy: 0.5702\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2527 - binary_accuracy: 0.4788 - val_loss: 0.2729 - val_binary_accuracy: 0.4000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2531 - binary_accuracy: 0.5333 - val_loss: 0.2464 - val_binary_accuracy: 0.5692\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2527 - binary_accuracy: 0.4790 - val_loss: 0.2729 - val_binary_accuracy: 0.4000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2531 - binary_accuracy: 0.5333 - val_loss: 0.2464 - val_binary_accuracy: 0.5692\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2527 - binary_accuracy: 0.4790 - val_loss: 0.2729 - val_binary_accuracy: 0.4000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2531 - binary_accuracy: 0.5333 - val_loss: 0.2464 - val_binary_accuracy: 0.5683\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2527 - binary_accuracy: 0.4792 - val_loss: 0.2730 - val_binary_accuracy: 0.4000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2531 - binary_accuracy: 0.5333 - val_loss: 0.2464 - val_binary_accuracy: 0.5683\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2527 - binary_accuracy: 0.4792 - val_loss: 0.2730 - val_binary_accuracy: 0.4000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2531 - binary_accuracy: 0.5333 - val_loss: 0.2465 - val_binary_accuracy: 0.5683\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2527 - binary_accuracy: 0.4792 - val_loss: 0.2730 - val_binary_accuracy: 0.4000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2531 - binary_accuracy: 0.5333 - val_loss: 0.2465 - val_binary_accuracy: 0.5673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x238e479f790>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80c9fbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 618ms/step - loss: 0.2527 - binary_accuracy: 0.4794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2526600956916809, 0.4794366955757141]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99422f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8)                 16        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25\n",
      "Trainable params: 25\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26131c0",
   "metadata": {},
   "source": [
    "### Step 5 - Performance Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa833537",
   "metadata": {},
   "source": [
    "#### a. Single layer neural network Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "008bf03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_analysis(datadir, categories, img_size, nodes):\n",
    "    \n",
    "    df_results = pd.DataFrame(data=np.zeros(shape=(0, 5)), \n",
    "                              columns = ['Img size','Nodes Number','Accuracy','Loss','Training time'])\n",
    " \n",
    "    training_data = []\n",
    "    \n",
    "    for category in categories:\n",
    "        path = os.path.join(datadir,category)\n",
    "        class_num = categories.index(category)\n",
    "        \n",
    "        for img in os.listdir(path):\n",
    "            img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n",
    "            num_array=cv2.resize(img_array,(img_size,img_size))\n",
    "            training_data.append([num_array,class_num])\n",
    "\n",
    "    X=[]\n",
    "    y=[]\n",
    "    \n",
    "    for features,label in training_data:\n",
    "        X.append(features)\n",
    "        y.append(label)\n",
    "    X=np.asarray(X).reshape(-1,img_size,img_size,1)\n",
    "    y=np.asarray(y)\n",
    "\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.25,random_state=42)\n",
    "\n",
    "    count = 0\n",
    "    t_start = process_time() \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(nodes, input_dim=1, activation='relu'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(loss='mean_squared_error', metrics=['binary_accuracy'])\n",
    "    model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=100)\n",
    "    \n",
    "    t_stop = process_time() \n",
    "    t_elapsed = t_stop - t_start\n",
    "    \n",
    "    score = model.evaluate(X_test,y_test)\n",
    "    \n",
    "    count+=1\n",
    "\n",
    "    df_results.loc[count,'Img size'] = img_size\n",
    "    df_results.loc[count,'Nodes Number'] = nodes\n",
    "    df_results.loc[count,'Accuracy'] = score[1]\n",
    "    df_results.loc[count,'Loss'] = score[0]\n",
    "    df_results.loc[count,'Training time'] = t_elapsed\n",
    "        \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8eb35bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation():\n",
    "    m1 = performance_analysis(\"Image\", ['Tiger', 'Zebra'], 500, 8)\n",
    "    m2 = performance_analysis(\"Image\", ['Tiger', 'Zebra'], 500, 16)\n",
    "    m3 = performance_analysis(\"Image\", ['Tiger', 'Zebra'], 500, 32)\n",
    "    m4 = performance_analysis(\"Image\", ['Tiger', 'Zebra'], 500, 64)\n",
    "    m5 = performance_analysis(\"Image\", ['Tiger', 'Zebra'], 100, 8)\n",
    "    m6 = performance_analysis(\"Image\", ['Tiger', 'Zebra'], 100, 16)\n",
    "    m7 = performance_analysis(\"Image\", ['Tiger', 'Zebra'], 100, 32)\n",
    "    m8 = performance_analysis(\"Image\", ['Tiger', 'Zebra'], 100, 64)\n",
    "    m9 = performance_analysis(\"Image\", ['Tiger', 'Zebra'], 50, 8)\n",
    "    m10 = performance_analysis(\"Image\", ['Tiger', 'Zebra'], 50, 16)\n",
    "    m11 = performance_analysis(\"Image\", ['Tiger', 'Zebra'], 50, 32)\n",
    "    m12 = performance_analysis(\"Image\", ['Tiger', 'Zebra'], 50, 64)\n",
    "    m13 = performance_analysis(\"Image\", ['Tiger', 'Zebra'], 25, 8)\n",
    "    m14 = performance_analysis(\"Image\", ['Tiger', 'Zebra'], 25, 16)\n",
    "    m15 = performance_analysis(\"Image\", ['Tiger', 'Zebra'], 25, 32)\n",
    "    m16 = performance_analysis(\"Image\", ['Tiger', 'Zebra'], 25, 64)\n",
    "    m17 = performance_analysis(\"Image\", ['Tiger', 'Zebra'], 10, 8)\n",
    "    m18 = performance_analysis(\"Image\", ['Tiger', 'Zebra'], 10, 16)\n",
    "    m19 = performance_analysis(\"Image\", ['Tiger', 'Zebra'], 10, 32)\n",
    "    m20 = performance_analysis(\"Image\", ['Tiger', 'Zebra'], 10, 64)\n",
    "    \n",
    "    df = pd.concat([m1,m2,m3,m4,m5,m6,m7,m8,m9,m10,m11,m12,m13,m14,m15,m16,m17,m18,m19,m20], axis=0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cca2b02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_38_input'), name='dense_38_input', description=\"created by layer 'dense_38_input'\"), but it was called on an input with incompatible shape (None, 500, 500, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_38_input'), name='dense_38_input', description=\"created by layer 'dense_38_input'\"), but it was called on an input with incompatible shape (None, 500, 500, 1).\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5068 - binary_accuracy: 0.4667WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_38_input'), name='dense_38_input', description=\"created by layer 'dense_38_input'\"), but it was called on an input with incompatible shape (None, 500, 500, 1).\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5068 - binary_accuracy: 0.4667 - val_loss: 0.3907 - val_binary_accuracy: 0.5997\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5063 - binary_accuracy: 0.4670 - val_loss: 0.3904 - val_binary_accuracy: 0.5997\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5058 - binary_accuracy: 0.4670 - val_loss: 0.3902 - val_binary_accuracy: 0.5997\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5054 - binary_accuracy: 0.4670 - val_loss: 0.3900 - val_binary_accuracy: 0.5997\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5051 - binary_accuracy: 0.4670 - val_loss: 0.3897 - val_binary_accuracy: 0.5997\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5047 - binary_accuracy: 0.4670 - val_loss: 0.3895 - val_binary_accuracy: 0.5997\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5043 - binary_accuracy: 0.4670 - val_loss: 0.3893 - val_binary_accuracy: 0.5997\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5039 - binary_accuracy: 0.4670 - val_loss: 0.3891 - val_binary_accuracy: 0.5997\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5036 - binary_accuracy: 0.4670 - val_loss: 0.3888 - val_binary_accuracy: 0.5997\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5032 - binary_accuracy: 0.4670 - val_loss: 0.3886 - val_binary_accuracy: 0.5997\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5028 - binary_accuracy: 0.4670 - val_loss: 0.3883 - val_binary_accuracy: 0.5997\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5024 - binary_accuracy: 0.4670 - val_loss: 0.3880 - val_binary_accuracy: 0.5997\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5019 - binary_accuracy: 0.4670 - val_loss: 0.3878 - val_binary_accuracy: 0.5997\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5015 - binary_accuracy: 0.4670 - val_loss: 0.3874 - val_binary_accuracy: 0.5997\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5010 - binary_accuracy: 0.4670 - val_loss: 0.3871 - val_binary_accuracy: 0.5997\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5005 - binary_accuracy: 0.4670 - val_loss: 0.3867 - val_binary_accuracy: 0.5997\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4999 - binary_accuracy: 0.4670 - val_loss: 0.3863 - val_binary_accuracy: 0.5997\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4993 - binary_accuracy: 0.4670 - val_loss: 0.3859 - val_binary_accuracy: 0.5997\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4987 - binary_accuracy: 0.4670 - val_loss: 0.3854 - val_binary_accuracy: 0.5997\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4980 - binary_accuracy: 0.4670 - val_loss: 0.3849 - val_binary_accuracy: 0.5997\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4972 - binary_accuracy: 0.4670 - val_loss: 0.3843 - val_binary_accuracy: 0.5997\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4964 - binary_accuracy: 0.4670 - val_loss: 0.3836 - val_binary_accuracy: 0.5997\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4955 - binary_accuracy: 0.4670 - val_loss: 0.3829 - val_binary_accuracy: 0.5960\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4944 - binary_accuracy: 0.4710 - val_loss: 0.3820 - val_binary_accuracy: 0.5960\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4933 - binary_accuracy: 0.4710 - val_loss: 0.3810 - val_binary_accuracy: 0.5960\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4919 - binary_accuracy: 0.4710 - val_loss: 0.3798 - val_binary_accuracy: 0.5960\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4904 - binary_accuracy: 0.4710 - val_loss: 0.3783 - val_binary_accuracy: 0.5960\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4886 - binary_accuracy: 0.4710 - val_loss: 0.3766 - val_binary_accuracy: 0.5960\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4865 - binary_accuracy: 0.4710 - val_loss: 0.3745 - val_binary_accuracy: 0.5960\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4839 - binary_accuracy: 0.4710 - val_loss: 0.3718 - val_binary_accuracy: 0.5953\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4807 - binary_accuracy: 0.4714 - val_loss: 0.3684 - val_binary_accuracy: 0.5953\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4765 - binary_accuracy: 0.4714 - val_loss: 0.3638 - val_binary_accuracy: 0.5953\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4710 - binary_accuracy: 0.4714 - val_loss: 0.3574 - val_binary_accuracy: 0.5945\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4632 - binary_accuracy: 0.4717 - val_loss: 0.3480 - val_binary_accuracy: 0.5934\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4514 - binary_accuracy: 0.4720 - val_loss: 0.3328 - val_binary_accuracy: 0.5924\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4316 - binary_accuracy: 0.4723 - val_loss: 0.3056 - val_binary_accuracy: 0.5891\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3933 - binary_accuracy: 0.4731 - val_loss: 0.2604 - val_binary_accuracy: 0.5831\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3147 - binary_accuracy: 0.4753 - val_loss: 0.2608 - val_binary_accuracy: 0.4000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2564 - val_binary_accuracy: 0.4000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2611 - val_binary_accuracy: 0.4000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2556 - val_binary_accuracy: 0.4000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2491 - binary_accuracy: 0.5333 - val_loss: 0.2629 - val_binary_accuracy: 0.4000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2493 - binary_accuracy: 0.5333 - val_loss: 0.2533 - val_binary_accuracy: 0.4446\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2497 - binary_accuracy: 0.5128 - val_loss: 0.2690 - val_binary_accuracy: 0.4000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2507 - binary_accuracy: 0.5333 - val_loss: 0.2485 - val_binary_accuracy: 0.5211\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2528 - binary_accuracy: 0.4912 - val_loss: 0.2834 - val_binary_accuracy: 0.4000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2563 - binary_accuracy: 0.5333 - val_loss: 0.2463 - val_binary_accuracy: 0.5452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2566 - binary_accuracy: 0.4853 - val_loss: 0.2834 - val_binary_accuracy: 0.4000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2563 - binary_accuracy: 0.5333 - val_loss: 0.2480 - val_binary_accuracy: 0.5265\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2533 - binary_accuracy: 0.4898 - val_loss: 0.2747 - val_binary_accuracy: 0.4000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2526 - binary_accuracy: 0.5333 - val_loss: 0.2498 - val_binary_accuracy: 0.5080\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2515 - binary_accuracy: 0.4955 - val_loss: 0.2711 - val_binary_accuracy: 0.4000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2513 - binary_accuracy: 0.5333 - val_loss: 0.2505 - val_binary_accuracy: 0.5000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2510 - binary_accuracy: 0.4982 - val_loss: 0.2706 - val_binary_accuracy: 0.4000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2512 - binary_accuracy: 0.5333 - val_loss: 0.2502 - val_binary_accuracy: 0.5036\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2512 - binary_accuracy: 0.4970 - val_loss: 0.2720 - val_binary_accuracy: 0.4000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2516 - binary_accuracy: 0.5333 - val_loss: 0.2494 - val_binary_accuracy: 0.5118\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2518 - binary_accuracy: 0.4941 - val_loss: 0.2743 - val_binary_accuracy: 0.4000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2524 - binary_accuracy: 0.5333 - val_loss: 0.2488 - val_binary_accuracy: 0.5185\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2524 - binary_accuracy: 0.4920 - val_loss: 0.2755 - val_binary_accuracy: 0.4000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2529 - binary_accuracy: 0.5333 - val_loss: 0.2487 - val_binary_accuracy: 0.5193\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2525 - binary_accuracy: 0.4917 - val_loss: 0.2750 - val_binary_accuracy: 0.4000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2527 - binary_accuracy: 0.5333 - val_loss: 0.2490 - val_binary_accuracy: 0.5159\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2522 - binary_accuracy: 0.4927 - val_loss: 0.2739 - val_binary_accuracy: 0.4000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2523 - binary_accuracy: 0.5333 - val_loss: 0.2493 - val_binary_accuracy: 0.5126\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2519 - binary_accuracy: 0.4938 - val_loss: 0.2733 - val_binary_accuracy: 0.4000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2521 - binary_accuracy: 0.5333 - val_loss: 0.2494 - val_binary_accuracy: 0.5118\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2518 - binary_accuracy: 0.4941 - val_loss: 0.2733 - val_binary_accuracy: 0.4000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2521 - binary_accuracy: 0.5333 - val_loss: 0.2493 - val_binary_accuracy: 0.5126\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2519 - binary_accuracy: 0.4938 - val_loss: 0.2736 - val_binary_accuracy: 0.4000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2522 - binary_accuracy: 0.5333 - val_loss: 0.2492 - val_binary_accuracy: 0.5142\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2520 - binary_accuracy: 0.4932 - val_loss: 0.2740 - val_binary_accuracy: 0.4000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2524 - binary_accuracy: 0.5333 - val_loss: 0.2491 - val_binary_accuracy: 0.5150\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2521 - binary_accuracy: 0.4930 - val_loss: 0.2741 - val_binary_accuracy: 0.4000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2524 - binary_accuracy: 0.5333 - val_loss: 0.2491 - val_binary_accuracy: 0.5150\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2521 - binary_accuracy: 0.4930 - val_loss: 0.2740 - val_binary_accuracy: 0.4000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2524 - binary_accuracy: 0.5333 - val_loss: 0.2491 - val_binary_accuracy: 0.5150\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2520 - binary_accuracy: 0.4930 - val_loss: 0.2738 - val_binary_accuracy: 0.4000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2523 - binary_accuracy: 0.5333 - val_loss: 0.2492 - val_binary_accuracy: 0.5142\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2520 - binary_accuracy: 0.4932 - val_loss: 0.2737 - val_binary_accuracy: 0.4000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2523 - binary_accuracy: 0.5333 - val_loss: 0.2492 - val_binary_accuracy: 0.5142\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2520 - binary_accuracy: 0.4932 - val_loss: 0.2737 - val_binary_accuracy: 0.4000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2523 - binary_accuracy: 0.5333 - val_loss: 0.2491 - val_binary_accuracy: 0.5142\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2520 - binary_accuracy: 0.4932 - val_loss: 0.2738 - val_binary_accuracy: 0.4000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2523 - binary_accuracy: 0.5333 - val_loss: 0.2491 - val_binary_accuracy: 0.5150\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2520 - binary_accuracy: 0.4930 - val_loss: 0.2738 - val_binary_accuracy: 0.4000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2523 - binary_accuracy: 0.5333 - val_loss: 0.2491 - val_binary_accuracy: 0.5150\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2520 - binary_accuracy: 0.4930 - val_loss: 0.2738 - val_binary_accuracy: 0.4000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2523 - binary_accuracy: 0.5333 - val_loss: 0.2491 - val_binary_accuracy: 0.5150\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2520 - binary_accuracy: 0.4930 - val_loss: 0.2738 - val_binary_accuracy: 0.4000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2523 - binary_accuracy: 0.5333 - val_loss: 0.2491 - val_binary_accuracy: 0.5150\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2520 - binary_accuracy: 0.4930 - val_loss: 0.2738 - val_binary_accuracy: 0.4000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2523 - binary_accuracy: 0.5333 - val_loss: 0.2491 - val_binary_accuracy: 0.5150\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2520 - binary_accuracy: 0.4930 - val_loss: 0.2737 - val_binary_accuracy: 0.4000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2523 - binary_accuracy: 0.5333 - val_loss: 0.2491 - val_binary_accuracy: 0.5150\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2520 - binary_accuracy: 0.4930 - val_loss: 0.2737 - val_binary_accuracy: 0.4000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2523 - binary_accuracy: 0.5333 - val_loss: 0.2491 - val_binary_accuracy: 0.5150\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2520 - binary_accuracy: 0.4930 - val_loss: 0.2738 - val_binary_accuracy: 0.4000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2523 - binary_accuracy: 0.5333 - val_loss: 0.2491 - val_binary_accuracy: 0.5150\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2520 - binary_accuracy: 0.4930 - val_loss: 0.2738 - val_binary_accuracy: 0.4000\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.2738 - binary_accuracy: 0.4000\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_40_input'), name='dense_40_input', description=\"created by layer 'dense_40_input'\"), but it was called on an input with incompatible shape (None, 500, 500, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_40_input'), name='dense_40_input', description=\"created by layer 'dense_40_input'\"), but it was called on an input with incompatible shape (None, 500, 500, 1).\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5109 - binary_accuracy: 0.4667WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_40_input'), name='dense_40_input', description=\"created by layer 'dense_40_input'\"), but it was called on an input with incompatible shape (None, 500, 500, 1).\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5109 - binary_accuracy: 0.4667 - val_loss: 0.3932 - val_binary_accuracy: 0.5997\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5104 - binary_accuracy: 0.4670 - val_loss: 0.3930 - val_binary_accuracy: 0.5997\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5100 - binary_accuracy: 0.4670 - val_loss: 0.3928 - val_binary_accuracy: 0.5997\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5097 - binary_accuracy: 0.4670 - val_loss: 0.3926 - val_binary_accuracy: 0.5997\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5093 - binary_accuracy: 0.4670 - val_loss: 0.3924 - val_binary_accuracy: 0.5997\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5090 - binary_accuracy: 0.4670 - val_loss: 0.3922 - val_binary_accuracy: 0.5997\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5087 - binary_accuracy: 0.4670 - val_loss: 0.3921 - val_binary_accuracy: 0.5997\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5084 - binary_accuracy: 0.4670 - val_loss: 0.3919 - val_binary_accuracy: 0.5997\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5080 - binary_accuracy: 0.4670 - val_loss: 0.3917 - val_binary_accuracy: 0.5997\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5077 - binary_accuracy: 0.4670 - val_loss: 0.3915 - val_binary_accuracy: 0.5997\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5073 - binary_accuracy: 0.4670 - val_loss: 0.3913 - val_binary_accuracy: 0.5997\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5070 - binary_accuracy: 0.4670 - val_loss: 0.3910 - val_binary_accuracy: 0.5997\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5066 - binary_accuracy: 0.4670 - val_loss: 0.3908 - val_binary_accuracy: 0.5997\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5062 - binary_accuracy: 0.4670 - val_loss: 0.3905 - val_binary_accuracy: 0.5997\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5057 - binary_accuracy: 0.4670 - val_loss: 0.3903 - val_binary_accuracy: 0.5997\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5053 - binary_accuracy: 0.4670 - val_loss: 0.3900 - val_binary_accuracy: 0.5997\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5048 - binary_accuracy: 0.4670 - val_loss: 0.3896 - val_binary_accuracy: 0.5997\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5043 - binary_accuracy: 0.4670 - val_loss: 0.3893 - val_binary_accuracy: 0.5997\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5037 - binary_accuracy: 0.4670 - val_loss: 0.3889 - val_binary_accuracy: 0.5997\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5030 - binary_accuracy: 0.4670 - val_loss: 0.3884 - val_binary_accuracy: 0.5997\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5023 - binary_accuracy: 0.4670 - val_loss: 0.3879 - val_binary_accuracy: 0.5997\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5015 - binary_accuracy: 0.4670 - val_loss: 0.3873 - val_binary_accuracy: 0.5997\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5005 - binary_accuracy: 0.4670 - val_loss: 0.3866 - val_binary_accuracy: 0.5960\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4994 - binary_accuracy: 0.4710 - val_loss: 0.3857 - val_binary_accuracy: 0.5960\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4981 - binary_accuracy: 0.4710 - val_loss: 0.3846 - val_binary_accuracy: 0.5960\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4966 - binary_accuracy: 0.4710 - val_loss: 0.3832 - val_binary_accuracy: 0.5960\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4946 - binary_accuracy: 0.4710 - val_loss: 0.3812 - val_binary_accuracy: 0.5960\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4920 - binary_accuracy: 0.4710 - val_loss: 0.3783 - val_binary_accuracy: 0.5953\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4883 - binary_accuracy: 0.4714 - val_loss: 0.3739 - val_binary_accuracy: 0.5953\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4829 - binary_accuracy: 0.4714 - val_loss: 0.3664 - val_binary_accuracy: 0.5945\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4738 - binary_accuracy: 0.4717 - val_loss: 0.3513 - val_binary_accuracy: 0.5924\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4552 - binary_accuracy: 0.4723 - val_loss: 0.3110 - val_binary_accuracy: 0.5877\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4009 - binary_accuracy: 0.4736 - val_loss: 0.2592 - val_binary_accuracy: 0.4000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2605 - val_binary_accuracy: 0.4000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2521 - val_binary_accuracy: 0.4829\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2506 - binary_accuracy: 0.5030 - val_loss: 0.3632 - val_binary_accuracy: 0.4000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3048 - binary_accuracy: 0.5333 - val_loss: 0.2600 - val_binary_accuracy: 0.5810\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3130 - binary_accuracy: 0.4762 - val_loss: 0.3347 - val_binary_accuracy: 0.4000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2858 - binary_accuracy: 0.5333 - val_loss: 0.2461 - val_binary_accuracy: 0.5630\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2703 - binary_accuracy: 0.4806 - val_loss: 0.3220 - val_binary_accuracy: 0.4000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2777 - binary_accuracy: 0.5333 - val_loss: 0.2458 - val_binary_accuracy: 0.5542\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2630 - binary_accuracy: 0.4831 - val_loss: 0.3047 - val_binary_accuracy: 0.4000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2671 - binary_accuracy: 0.5333 - val_loss: 0.2459 - val_binary_accuracy: 0.5523\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2620 - binary_accuracy: 0.4836 - val_loss: 0.2995 - val_binary_accuracy: 0.4000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2642 - binary_accuracy: 0.5333 - val_loss: 0.2461 - val_binary_accuracy: 0.5493\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2603 - binary_accuracy: 0.4843 - val_loss: 0.2958 - val_binary_accuracy: 0.4000\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.2622 - binary_accuracy: 0.5333 - val_loss: 0.2462 - val_binary_accuracy: 0.5473\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2595 - binary_accuracy: 0.4848 - val_loss: 0.2942 - val_binary_accuracy: 0.4000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2613 - binary_accuracy: 0.5333 - val_loss: 0.2463 - val_binary_accuracy: 0.5462\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2592 - binary_accuracy: 0.4850 - val_loss: 0.2937 - val_binary_accuracy: 0.4000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2611 - binary_accuracy: 0.5333 - val_loss: 0.2463 - val_binary_accuracy: 0.5462\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2591 - binary_accuracy: 0.4850 - val_loss: 0.2936 - val_binary_accuracy: 0.4000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2610 - binary_accuracy: 0.5333 - val_loss: 0.2463 - val_binary_accuracy: 0.5462\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2591 - binary_accuracy: 0.4850 - val_loss: 0.2937 - val_binary_accuracy: 0.4000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2611 - binary_accuracy: 0.5333 - val_loss: 0.2463 - val_binary_accuracy: 0.5462\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2591 - binary_accuracy: 0.4850 - val_loss: 0.2937 - val_binary_accuracy: 0.4000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2611 - binary_accuracy: 0.5333 - val_loss: 0.2462 - val_binary_accuracy: 0.5462\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2591 - binary_accuracy: 0.4850 - val_loss: 0.2937 - val_binary_accuracy: 0.4000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2611 - binary_accuracy: 0.5333 - val_loss: 0.2462 - val_binary_accuracy: 0.5462\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2591 - binary_accuracy: 0.4850 - val_loss: 0.2937 - val_binary_accuracy: 0.4000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2611 - binary_accuracy: 0.5333 - val_loss: 0.2462 - val_binary_accuracy: 0.5462\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2591 - binary_accuracy: 0.4850 - val_loss: 0.2937 - val_binary_accuracy: 0.4000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2611 - binary_accuracy: 0.5333 - val_loss: 0.2462 - val_binary_accuracy: 0.5462\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2591 - binary_accuracy: 0.4850 - val_loss: 0.2937 - val_binary_accuracy: 0.4000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2611 - binary_accuracy: 0.5333 - val_loss: 0.2462 - val_binary_accuracy: 0.5462\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2591 - binary_accuracy: 0.4850 - val_loss: 0.2937 - val_binary_accuracy: 0.4000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2611 - binary_accuracy: 0.5333 - val_loss: 0.2462 - val_binary_accuracy: 0.5473\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2591 - binary_accuracy: 0.4848 - val_loss: 0.2937 - val_binary_accuracy: 0.4000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2611 - binary_accuracy: 0.5333 - val_loss: 0.2462 - val_binary_accuracy: 0.5473\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2591 - binary_accuracy: 0.4848 - val_loss: 0.2937 - val_binary_accuracy: 0.4000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2611 - binary_accuracy: 0.5333 - val_loss: 0.2462 - val_binary_accuracy: 0.5473\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2591 - binary_accuracy: 0.4848 - val_loss: 0.2936 - val_binary_accuracy: 0.4000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2611 - binary_accuracy: 0.5333 - val_loss: 0.2462 - val_binary_accuracy: 0.5473\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2591 - binary_accuracy: 0.4848 - val_loss: 0.2936 - val_binary_accuracy: 0.4000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2611 - binary_accuracy: 0.5333 - val_loss: 0.2462 - val_binary_accuracy: 0.5473\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2591 - binary_accuracy: 0.4848 - val_loss: 0.2936 - val_binary_accuracy: 0.4000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2611 - binary_accuracy: 0.5333 - val_loss: 0.2462 - val_binary_accuracy: 0.5473\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2591 - binary_accuracy: 0.4848 - val_loss: 0.2936 - val_binary_accuracy: 0.4000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2611 - binary_accuracy: 0.5333 - val_loss: 0.2461 - val_binary_accuracy: 0.5473\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2591 - binary_accuracy: 0.4848 - val_loss: 0.2936 - val_binary_accuracy: 0.4000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2611 - binary_accuracy: 0.5333 - val_loss: 0.2461 - val_binary_accuracy: 0.5473\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2591 - binary_accuracy: 0.4848 - val_loss: 0.2936 - val_binary_accuracy: 0.4000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2611 - binary_accuracy: 0.5333 - val_loss: 0.2461 - val_binary_accuracy: 0.5473\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2591 - binary_accuracy: 0.4848 - val_loss: 0.2936 - val_binary_accuracy: 0.4000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2611 - binary_accuracy: 0.5333 - val_loss: 0.2461 - val_binary_accuracy: 0.5473\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2591 - binary_accuracy: 0.4848 - val_loss: 0.2936 - val_binary_accuracy: 0.4000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2611 - binary_accuracy: 0.5333 - val_loss: 0.2461 - val_binary_accuracy: 0.5473\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2591 - binary_accuracy: 0.4848 - val_loss: 0.2936 - val_binary_accuracy: 0.4000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2611 - binary_accuracy: 0.5333 - val_loss: 0.2461 - val_binary_accuracy: 0.5473\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2591 - binary_accuracy: 0.4848 - val_loss: 0.2935 - val_binary_accuracy: 0.4000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2611 - binary_accuracy: 0.5333 - val_loss: 0.2461 - val_binary_accuracy: 0.5483\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2591 - binary_accuracy: 0.4845 - val_loss: 0.2935 - val_binary_accuracy: 0.4000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2611 - binary_accuracy: 0.5333 - val_loss: 0.2461 - val_binary_accuracy: 0.5483\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2591 - binary_accuracy: 0.4845 - val_loss: 0.2935 - val_binary_accuracy: 0.4000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2611 - binary_accuracy: 0.5333 - val_loss: 0.2461 - val_binary_accuracy: 0.5483\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2591 - binary_accuracy: 0.4845 - val_loss: 0.2935 - val_binary_accuracy: 0.4000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2611 - binary_accuracy: 0.5333 - val_loss: 0.2461 - val_binary_accuracy: 0.5483\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2591 - binary_accuracy: 0.4845 - val_loss: 0.2935 - val_binary_accuracy: 0.4000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2611 - binary_accuracy: 0.5333 - val_loss: 0.2461 - val_binary_accuracy: 0.5483\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2591 - binary_accuracy: 0.4845 - val_loss: 0.2935 - val_binary_accuracy: 0.4000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.2935 - binary_accuracy: 0.4000\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_42_input'), name='dense_42_input', description=\"created by layer 'dense_42_input'\"), but it was called on an input with incompatible shape (None, 500, 500, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_42_input'), name='dense_42_input', description=\"created by layer 'dense_42_input'\"), but it was called on an input with incompatible shape (None, 500, 500, 1).\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4539 - binary_accuracy: 0.4667WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_42_input'), name='dense_42_input', description=\"created by layer 'dense_42_input'\"), but it was called on an input with incompatible shape (None, 500, 500, 1).\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4539 - binary_accuracy: 0.4667 - val_loss: 0.2951 - val_binary_accuracy: 0.5997\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3790 - binary_accuracy: 0.4670 - val_loss: 0.2809 - val_binary_accuracy: 0.4000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2569 - binary_accuracy: 0.5333 - val_loss: 0.2565 - val_binary_accuracy: 0.5953\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3098 - binary_accuracy: 0.4714 - val_loss: 0.3283 - val_binary_accuracy: 0.4000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2844 - binary_accuracy: 0.5333 - val_loss: 0.2429 - val_binary_accuracy: 0.5899\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2628 - binary_accuracy: 0.4728 - val_loss: 0.3062 - val_binary_accuracy: 0.4000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2706 - binary_accuracy: 0.5333 - val_loss: 0.2430 - val_binary_accuracy: 0.5891\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2616 - binary_accuracy: 0.4731 - val_loss: 0.2961 - val_binary_accuracy: 0.4000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2647 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5884\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2592 - binary_accuracy: 0.4734 - val_loss: 0.2897 - val_binary_accuracy: 0.4000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2612 - binary_accuracy: 0.5333 - val_loss: 0.2435 - val_binary_accuracy: 0.5871\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2580 - binary_accuracy: 0.4739 - val_loss: 0.2869 - val_binary_accuracy: 0.4000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2598 - binary_accuracy: 0.5333 - val_loss: 0.2437 - val_binary_accuracy: 0.5871\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2575 - binary_accuracy: 0.4739 - val_loss: 0.2860 - val_binary_accuracy: 0.4000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2593 - binary_accuracy: 0.5333 - val_loss: 0.2437 - val_binary_accuracy: 0.5865\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2573 - binary_accuracy: 0.4741 - val_loss: 0.2859 - val_binary_accuracy: 0.4000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2592 - binary_accuracy: 0.5333 - val_loss: 0.2437 - val_binary_accuracy: 0.5865\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - binary_accuracy: 0.4741 - val_loss: 0.2861 - val_binary_accuracy: 0.4000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2593 - binary_accuracy: 0.5333 - val_loss: 0.2437 - val_binary_accuracy: 0.5865\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - binary_accuracy: 0.4741 - val_loss: 0.2862 - val_binary_accuracy: 0.4000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2594 - binary_accuracy: 0.5333 - val_loss: 0.2437 - val_binary_accuracy: 0.5865\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2575 - binary_accuracy: 0.4741 - val_loss: 0.2863 - val_binary_accuracy: 0.4000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2594 - binary_accuracy: 0.5333 - val_loss: 0.2437 - val_binary_accuracy: 0.5859\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2575 - binary_accuracy: 0.4743 - val_loss: 0.2863 - val_binary_accuracy: 0.4000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2594 - binary_accuracy: 0.5333 - val_loss: 0.2437 - val_binary_accuracy: 0.5859\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2575 - binary_accuracy: 0.4743 - val_loss: 0.2863 - val_binary_accuracy: 0.4000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2594 - binary_accuracy: 0.5333 - val_loss: 0.2437 - val_binary_accuracy: 0.5859\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2575 - binary_accuracy: 0.4743 - val_loss: 0.2863 - val_binary_accuracy: 0.4000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2594 - binary_accuracy: 0.5333 - val_loss: 0.2438 - val_binary_accuracy: 0.5859\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2575 - binary_accuracy: 0.4743 - val_loss: 0.2863 - val_binary_accuracy: 0.4000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2594 - binary_accuracy: 0.5333 - val_loss: 0.2438 - val_binary_accuracy: 0.5853\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2575 - binary_accuracy: 0.4745 - val_loss: 0.2863 - val_binary_accuracy: 0.4000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2594 - binary_accuracy: 0.5333 - val_loss: 0.2438 - val_binary_accuracy: 0.5853\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2575 - binary_accuracy: 0.4745 - val_loss: 0.2863 - val_binary_accuracy: 0.4000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2594 - binary_accuracy: 0.5333 - val_loss: 0.2438 - val_binary_accuracy: 0.5853\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2575 - binary_accuracy: 0.4745 - val_loss: 0.2863 - val_binary_accuracy: 0.4000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2594 - binary_accuracy: 0.5333 - val_loss: 0.2438 - val_binary_accuracy: 0.5853\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2574 - binary_accuracy: 0.4745 - val_loss: 0.2863 - val_binary_accuracy: 0.4000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2594 - binary_accuracy: 0.5333 - val_loss: 0.2438 - val_binary_accuracy: 0.5848\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - binary_accuracy: 0.4747 - val_loss: 0.2863 - val_binary_accuracy: 0.4000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2594 - binary_accuracy: 0.5333 - val_loss: 0.2438 - val_binary_accuracy: 0.5848\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - binary_accuracy: 0.4747 - val_loss: 0.2863 - val_binary_accuracy: 0.4000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2594 - binary_accuracy: 0.5333 - val_loss: 0.2438 - val_binary_accuracy: 0.5848\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - binary_accuracy: 0.4747 - val_loss: 0.2863 - val_binary_accuracy: 0.4000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2594 - binary_accuracy: 0.5333 - val_loss: 0.2438 - val_binary_accuracy: 0.5843\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - binary_accuracy: 0.4749 - val_loss: 0.2864 - val_binary_accuracy: 0.4000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2594 - binary_accuracy: 0.5333 - val_loss: 0.2438 - val_binary_accuracy: 0.5843\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - binary_accuracy: 0.4749 - val_loss: 0.2864 - val_binary_accuracy: 0.4000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2593 - binary_accuracy: 0.5333 - val_loss: 0.2438 - val_binary_accuracy: 0.5843\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - binary_accuracy: 0.4749 - val_loss: 0.2864 - val_binary_accuracy: 0.4000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2593 - binary_accuracy: 0.5333 - val_loss: 0.2438 - val_binary_accuracy: 0.5843\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - binary_accuracy: 0.4749 - val_loss: 0.2864 - val_binary_accuracy: 0.4000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2593 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5843\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - binary_accuracy: 0.4749 - val_loss: 0.2864 - val_binary_accuracy: 0.4000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2593 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5837\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - binary_accuracy: 0.4751 - val_loss: 0.2864 - val_binary_accuracy: 0.4000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2593 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5837\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - binary_accuracy: 0.4751 - val_loss: 0.2864 - val_binary_accuracy: 0.4000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2593 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5837\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - binary_accuracy: 0.4751 - val_loss: 0.2864 - val_binary_accuracy: 0.4000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2593 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5837\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - binary_accuracy: 0.4751 - val_loss: 0.2864 - val_binary_accuracy: 0.4000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2593 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5831\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - binary_accuracy: 0.4753 - val_loss: 0.2864 - val_binary_accuracy: 0.4000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2593 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5831\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - binary_accuracy: 0.4753 - val_loss: 0.2864 - val_binary_accuracy: 0.4000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2593 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5831\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - binary_accuracy: 0.4753 - val_loss: 0.2864 - val_binary_accuracy: 0.4000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2593 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5831\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - binary_accuracy: 0.4753 - val_loss: 0.2865 - val_binary_accuracy: 0.4000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2593 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5826\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - binary_accuracy: 0.4755 - val_loss: 0.2865 - val_binary_accuracy: 0.4000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2593 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5826\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - binary_accuracy: 0.4755 - val_loss: 0.2865 - val_binary_accuracy: 0.4000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2593 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5826\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - binary_accuracy: 0.4755 - val_loss: 0.2865 - val_binary_accuracy: 0.4000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2593 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5826\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - binary_accuracy: 0.4755 - val_loss: 0.2865 - val_binary_accuracy: 0.4000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2593 - binary_accuracy: 0.5333 - val_loss: 0.2440 - val_binary_accuracy: 0.5826\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - binary_accuracy: 0.4755 - val_loss: 0.2865 - val_binary_accuracy: 0.4000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2593 - binary_accuracy: 0.5333 - val_loss: 0.2440 - val_binary_accuracy: 0.5821\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - binary_accuracy: 0.4757 - val_loss: 0.2865 - val_binary_accuracy: 0.4000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2593 - binary_accuracy: 0.5333 - val_loss: 0.2440 - val_binary_accuracy: 0.5821\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - binary_accuracy: 0.4757 - val_loss: 0.2865 - val_binary_accuracy: 0.4000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2593 - binary_accuracy: 0.5333 - val_loss: 0.2440 - val_binary_accuracy: 0.5821\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - binary_accuracy: 0.4757 - val_loss: 0.2865 - val_binary_accuracy: 0.4000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2593 - binary_accuracy: 0.5333 - val_loss: 0.2440 - val_binary_accuracy: 0.5821\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - binary_accuracy: 0.4757 - val_loss: 0.2865 - val_binary_accuracy: 0.4000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2593 - binary_accuracy: 0.5333 - val_loss: 0.2440 - val_binary_accuracy: 0.5821\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - binary_accuracy: 0.4757 - val_loss: 0.2865 - val_binary_accuracy: 0.4000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2593 - binary_accuracy: 0.5333 - val_loss: 0.2440 - val_binary_accuracy: 0.5815\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - binary_accuracy: 0.4760 - val_loss: 0.2865 - val_binary_accuracy: 0.4000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2593 - binary_accuracy: 0.5333 - val_loss: 0.2440 - val_binary_accuracy: 0.5815\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - binary_accuracy: 0.4760 - val_loss: 0.2865 - val_binary_accuracy: 0.4000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2593 - binary_accuracy: 0.5333 - val_loss: 0.2440 - val_binary_accuracy: 0.5815\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - binary_accuracy: 0.4760 - val_loss: 0.2865 - val_binary_accuracy: 0.4000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2593 - binary_accuracy: 0.5333 - val_loss: 0.2440 - val_binary_accuracy: 0.5815\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2574 - binary_accuracy: 0.4760 - val_loss: 0.2866 - val_binary_accuracy: 0.4000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2593 - binary_accuracy: 0.5333 - val_loss: 0.2440 - val_binary_accuracy: 0.5810\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - binary_accuracy: 0.4762 - val_loss: 0.2866 - val_binary_accuracy: 0.4000\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.2866 - binary_accuracy: 0.4000\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_44_input'), name='dense_44_input', description=\"created by layer 'dense_44_input'\"), but it was called on an input with incompatible shape (None, 500, 500, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_44_input'), name='dense_44_input', description=\"created by layer 'dense_44_input'\"), but it was called on an input with incompatible shape (None, 500, 500, 1).\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4278 - binary_accuracy: 0.5330WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_44_input'), name='dense_44_input', description=\"created by layer 'dense_44_input'\"), but it was called on an input with incompatible shape (None, 500, 500, 1).\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.4278 - binary_accuracy: 0.5330 - val_loss: 0.5105 - val_binary_accuracy: 0.4003\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.4023 - binary_accuracy: 0.5330 - val_loss: 0.2608 - val_binary_accuracy: 0.4169\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2501 - binary_accuracy: 0.5247 - val_loss: 0.3294 - val_binary_accuracy: 0.6000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.4287 - binary_accuracy: 0.4667 - val_loss: 0.2956 - val_binary_accuracy: 0.4066\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2652 - binary_accuracy: 0.5280 - val_loss: 0.3297 - val_binary_accuracy: 0.6000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.4291 - binary_accuracy: 0.4667 - val_loss: 0.2681 - val_binary_accuracy: 0.6000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3339 - binary_accuracy: 0.4667 - val_loss: 0.4303 - val_binary_accuracy: 0.4003\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3526 - binary_accuracy: 0.5330 - val_loss: 0.2863 - val_binary_accuracy: 0.4055\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2601 - binary_accuracy: 0.5283 - val_loss: 0.2707 - val_binary_accuracy: 0.6000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3387 - binary_accuracy: 0.4667 - val_loss: 0.3622 - val_binary_accuracy: 0.4040\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3074 - binary_accuracy: 0.5290 - val_loss: 0.2457 - val_binary_accuracy: 0.6000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2824 - binary_accuracy: 0.4667 - val_loss: 0.3860 - val_binary_accuracy: 0.4003\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3233 - binary_accuracy: 0.5330 - val_loss: 0.2507 - val_binary_accuracy: 0.4517\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2498 - binary_accuracy: 0.5155 - val_loss: 0.2716 - val_binary_accuracy: 0.4066\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2533 - binary_accuracy: 0.5280 - val_loss: 0.2442 - val_binary_accuracy: 0.6000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2768 - binary_accuracy: 0.4667 - val_loss: 0.3798 - val_binary_accuracy: 0.4003\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3192 - binary_accuracy: 0.5330 - val_loss: 0.2470 - val_binary_accuracy: 0.6000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2515 - binary_accuracy: 0.4667 - val_loss: 0.2947 - val_binary_accuracy: 0.4047\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2645 - binary_accuracy: 0.5286 - val_loss: 0.2525 - val_binary_accuracy: 0.6000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3013 - binary_accuracy: 0.4667 - val_loss: 0.3623 - val_binary_accuracy: 0.4003\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3074 - binary_accuracy: 0.5330 - val_loss: 0.2431 - val_binary_accuracy: 0.6000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2580 - binary_accuracy: 0.4667 - val_loss: 0.3259 - val_binary_accuracy: 0.4040\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2835 - binary_accuracy: 0.5290 - val_loss: 0.2464 - val_binary_accuracy: 0.6000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2847 - binary_accuracy: 0.4667 - val_loss: 0.3538 - val_binary_accuracy: 0.4003\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3018 - binary_accuracy: 0.5330 - val_loss: 0.2429 - val_binary_accuracy: 0.6000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2587 - binary_accuracy: 0.4667 - val_loss: 0.3204 - val_binary_accuracy: 0.4040\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2800 - binary_accuracy: 0.5290 - val_loss: 0.2451 - val_binary_accuracy: 0.6000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2802 - binary_accuracy: 0.4667 - val_loss: 0.3458 - val_binary_accuracy: 0.4003\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2964 - binary_accuracy: 0.5330 - val_loss: 0.2426 - val_binary_accuracy: 0.6000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2611 - binary_accuracy: 0.4667 - val_loss: 0.3225 - val_binary_accuracy: 0.4040\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2813 - binary_accuracy: 0.5290 - val_loss: 0.2438 - val_binary_accuracy: 0.6000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2750 - binary_accuracy: 0.4667 - val_loss: 0.3393 - val_binary_accuracy: 0.4003\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2921 - binary_accuracy: 0.5330 - val_loss: 0.2425 - val_binary_accuracy: 0.6000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2633 - binary_accuracy: 0.4667 - val_loss: 0.3244 - val_binary_accuracy: 0.4003\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2824 - binary_accuracy: 0.5330 - val_loss: 0.2432 - val_binary_accuracy: 0.6000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2717 - binary_accuracy: 0.4667 - val_loss: 0.3343 - val_binary_accuracy: 0.4003\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2889 - binary_accuracy: 0.5330 - val_loss: 0.2425 - val_binary_accuracy: 0.6000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2651 - binary_accuracy: 0.4667 - val_loss: 0.3256 - val_binary_accuracy: 0.4003\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2832 - binary_accuracy: 0.5330 - val_loss: 0.2429 - val_binary_accuracy: 0.6000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2697 - binary_accuracy: 0.4667 - val_loss: 0.3309 - val_binary_accuracy: 0.4003\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2866 - binary_accuracy: 0.5330 - val_loss: 0.2426 - val_binary_accuracy: 0.6000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2662 - binary_accuracy: 0.4667 - val_loss: 0.3262 - val_binary_accuracy: 0.4003\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2836 - binary_accuracy: 0.5330 - val_loss: 0.2428 - val_binary_accuracy: 0.6000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2686 - binary_accuracy: 0.4667 - val_loss: 0.3287 - val_binary_accuracy: 0.4003\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step - loss: 0.2852 - binary_accuracy: 0.5330 - val_loss: 0.2426 - val_binary_accuracy: 0.6000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2669 - binary_accuracy: 0.4667 - val_loss: 0.3264 - val_binary_accuracy: 0.4003\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2837 - binary_accuracy: 0.5330 - val_loss: 0.2427 - val_binary_accuracy: 0.6000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2680 - binary_accuracy: 0.4667 - val_loss: 0.3275 - val_binary_accuracy: 0.4003\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2844 - binary_accuracy: 0.5330 - val_loss: 0.2427 - val_binary_accuracy: 0.6000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2673 - binary_accuracy: 0.4667 - val_loss: 0.3263 - val_binary_accuracy: 0.4003\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2836 - binary_accuracy: 0.5330 - val_loss: 0.2427 - val_binary_accuracy: 0.6000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2678 - binary_accuracy: 0.4667 - val_loss: 0.3268 - val_binary_accuracy: 0.4003\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2839 - binary_accuracy: 0.5330 - val_loss: 0.2427 - val_binary_accuracy: 0.6000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2674 - binary_accuracy: 0.4667 - val_loss: 0.3263 - val_binary_accuracy: 0.4003\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2836 - binary_accuracy: 0.5330 - val_loss: 0.2427 - val_binary_accuracy: 0.6000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2676 - binary_accuracy: 0.4667 - val_loss: 0.3264 - val_binary_accuracy: 0.4003\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2837 - binary_accuracy: 0.5330 - val_loss: 0.2427 - val_binary_accuracy: 0.6000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2675 - binary_accuracy: 0.4667 - val_loss: 0.3262 - val_binary_accuracy: 0.4000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2835 - binary_accuracy: 0.5333 - val_loss: 0.2427 - val_binary_accuracy: 0.6000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2676 - binary_accuracy: 0.4667 - val_loss: 0.3262 - val_binary_accuracy: 0.4000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2835 - binary_accuracy: 0.5333 - val_loss: 0.2427 - val_binary_accuracy: 0.6000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2675 - binary_accuracy: 0.4667 - val_loss: 0.3261 - val_binary_accuracy: 0.4000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2834 - binary_accuracy: 0.5333 - val_loss: 0.2427 - val_binary_accuracy: 0.6000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2676 - binary_accuracy: 0.4667 - val_loss: 0.3261 - val_binary_accuracy: 0.4000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2834 - binary_accuracy: 0.5333 - val_loss: 0.2427 - val_binary_accuracy: 0.6000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2675 - binary_accuracy: 0.4667 - val_loss: 0.3261 - val_binary_accuracy: 0.4000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2834 - binary_accuracy: 0.5333 - val_loss: 0.2427 - val_binary_accuracy: 0.6000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2675 - binary_accuracy: 0.4667 - val_loss: 0.3261 - val_binary_accuracy: 0.4000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2834 - binary_accuracy: 0.5333 - val_loss: 0.2427 - val_binary_accuracy: 0.6000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2675 - binary_accuracy: 0.4667 - val_loss: 0.3261 - val_binary_accuracy: 0.4000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2834 - binary_accuracy: 0.5333 - val_loss: 0.2428 - val_binary_accuracy: 0.6000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2675 - binary_accuracy: 0.4667 - val_loss: 0.3260 - val_binary_accuracy: 0.4000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2833 - binary_accuracy: 0.5333 - val_loss: 0.2428 - val_binary_accuracy: 0.6000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2675 - binary_accuracy: 0.4667 - val_loss: 0.3260 - val_binary_accuracy: 0.4000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2833 - binary_accuracy: 0.5333 - val_loss: 0.2428 - val_binary_accuracy: 0.6000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2675 - binary_accuracy: 0.4667 - val_loss: 0.3260 - val_binary_accuracy: 0.4000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2833 - binary_accuracy: 0.5333 - val_loss: 0.2428 - val_binary_accuracy: 0.6000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2676 - binary_accuracy: 0.4667 - val_loss: 0.3260 - val_binary_accuracy: 0.4000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2833 - binary_accuracy: 0.5333 - val_loss: 0.2428 - val_binary_accuracy: 0.6000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2675 - binary_accuracy: 0.4667 - val_loss: 0.3260 - val_binary_accuracy: 0.4000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2833 - binary_accuracy: 0.5333 - val_loss: 0.2428 - val_binary_accuracy: 0.5997\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2676 - binary_accuracy: 0.4670 - val_loss: 0.3260 - val_binary_accuracy: 0.4000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2833 - binary_accuracy: 0.5333 - val_loss: 0.2428 - val_binary_accuracy: 0.5997\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2676 - binary_accuracy: 0.4670 - val_loss: 0.3260 - val_binary_accuracy: 0.4000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2833 - binary_accuracy: 0.5333 - val_loss: 0.2428 - val_binary_accuracy: 0.5997\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2676 - binary_accuracy: 0.4670 - val_loss: 0.3260 - val_binary_accuracy: 0.4000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2832 - binary_accuracy: 0.5333 - val_loss: 0.2428 - val_binary_accuracy: 0.5997\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2676 - binary_accuracy: 0.4670 - val_loss: 0.3259 - val_binary_accuracy: 0.4000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2832 - binary_accuracy: 0.5333 - val_loss: 0.2428 - val_binary_accuracy: 0.5997\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2676 - binary_accuracy: 0.4670 - val_loss: 0.3259 - val_binary_accuracy: 0.4000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2832 - binary_accuracy: 0.5333 - val_loss: 0.2428 - val_binary_accuracy: 0.5997\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2676 - binary_accuracy: 0.4670 - val_loss: 0.3259 - val_binary_accuracy: 0.4000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2832 - binary_accuracy: 0.5333 - val_loss: 0.2428 - val_binary_accuracy: 0.5997\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2676 - binary_accuracy: 0.4670 - val_loss: 0.3259 - val_binary_accuracy: 0.4000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2832 - binary_accuracy: 0.5333 - val_loss: 0.2428 - val_binary_accuracy: 0.5997\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2676 - binary_accuracy: 0.4670 - val_loss: 0.3259 - val_binary_accuracy: 0.4000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2832 - binary_accuracy: 0.5333 - val_loss: 0.2428 - val_binary_accuracy: 0.5997\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2676 - binary_accuracy: 0.4670 - val_loss: 0.3259 - val_binary_accuracy: 0.4000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2832 - binary_accuracy: 0.5333 - val_loss: 0.2428 - val_binary_accuracy: 0.5997\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2676 - binary_accuracy: 0.4670 - val_loss: 0.3259 - val_binary_accuracy: 0.4000\n",
      "1/1 [==============================] - 0s 500ms/step - loss: 0.3259 - binary_accuracy: 0.4000\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_46_input'), name='dense_46_input', description=\"created by layer 'dense_46_input'\"), but it was called on an input with incompatible shape (None, 100, 100, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_46_input'), name='dense_46_input', description=\"created by layer 'dense_46_input'\"), but it was called on an input with incompatible shape (None, 100, 100, 1).\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5071 - binary_accuracy: 0.4667WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_46_input'), name='dense_46_input', description=\"created by layer 'dense_46_input'\"), but it was called on an input with incompatible shape (None, 100, 100, 1).\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5071 - binary_accuracy: 0.4667 - val_loss: 0.3910 - val_binary_accuracy: 0.5997\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5067 - binary_accuracy: 0.4670 - val_loss: 0.3908 - val_binary_accuracy: 0.5997\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5063 - binary_accuracy: 0.4670 - val_loss: 0.3906 - val_binary_accuracy: 0.5997\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5060 - binary_accuracy: 0.4670 - val_loss: 0.3904 - val_binary_accuracy: 0.5997\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.5057 - binary_accuracy: 0.4670 - val_loss: 0.3902 - val_binary_accuracy: 0.5997\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5054 - binary_accuracy: 0.4670 - val_loss: 0.3900 - val_binary_accuracy: 0.5997\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5051 - binary_accuracy: 0.4670 - val_loss: 0.3899 - val_binary_accuracy: 0.5997\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5048 - binary_accuracy: 0.4670 - val_loss: 0.3897 - val_binary_accuracy: 0.5997\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.5045 - binary_accuracy: 0.4670 - val_loss: 0.3895 - val_binary_accuracy: 0.5997\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5042 - binary_accuracy: 0.4670 - val_loss: 0.3893 - val_binary_accuracy: 0.5997\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5039 - binary_accuracy: 0.4670 - val_loss: 0.3891 - val_binary_accuracy: 0.5997\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5036 - binary_accuracy: 0.4670 - val_loss: 0.3889 - val_binary_accuracy: 0.5997\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5033 - binary_accuracy: 0.4670 - val_loss: 0.3887 - val_binary_accuracy: 0.5997\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5030 - binary_accuracy: 0.4670 - val_loss: 0.3885 - val_binary_accuracy: 0.5997\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5026 - binary_accuracy: 0.4670 - val_loss: 0.3883 - val_binary_accuracy: 0.5997\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5023 - binary_accuracy: 0.4670 - val_loss: 0.3880 - val_binary_accuracy: 0.5997\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.5019 - binary_accuracy: 0.4670 - val_loss: 0.3878 - val_binary_accuracy: 0.5997\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5015 - binary_accuracy: 0.4670 - val_loss: 0.3875 - val_binary_accuracy: 0.5997\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.5011 - binary_accuracy: 0.4670 - val_loss: 0.3872 - val_binary_accuracy: 0.5997\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5006 - binary_accuracy: 0.4670 - val_loss: 0.3869 - val_binary_accuracy: 0.5997\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5001 - binary_accuracy: 0.4670 - val_loss: 0.3865 - val_binary_accuracy: 0.5997\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4996 - binary_accuracy: 0.4670 - val_loss: 0.3861 - val_binary_accuracy: 0.5997\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.4991 - binary_accuracy: 0.4670 - val_loss: 0.3857 - val_binary_accuracy: 0.5997\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4985 - binary_accuracy: 0.4670 - val_loss: 0.3853 - val_binary_accuracy: 0.5997\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4978 - binary_accuracy: 0.4670 - val_loss: 0.3848 - val_binary_accuracy: 0.5997\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4971 - binary_accuracy: 0.4670 - val_loss: 0.3842 - val_binary_accuracy: 0.5997\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.4963 - binary_accuracy: 0.4670 - val_loss: 0.3836 - val_binary_accuracy: 0.5997\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.4955 - binary_accuracy: 0.4670 - val_loss: 0.3829 - val_binary_accuracy: 0.5997\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.4945 - binary_accuracy: 0.4670 - val_loss: 0.3820 - val_binary_accuracy: 0.5997\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.4935 - binary_accuracy: 0.4670 - val_loss: 0.3811 - val_binary_accuracy: 0.5997\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.4923 - binary_accuracy: 0.4670 - val_loss: 0.3800 - val_binary_accuracy: 0.5997\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4909 - binary_accuracy: 0.4670 - val_loss: 0.3787 - val_binary_accuracy: 0.5960\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.4893 - binary_accuracy: 0.4710 - val_loss: 0.3772 - val_binary_accuracy: 0.5960\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4874 - binary_accuracy: 0.4710 - val_loss: 0.3753 - val_binary_accuracy: 0.5960\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4851 - binary_accuracy: 0.4710 - val_loss: 0.3730 - val_binary_accuracy: 0.5960\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4823 - binary_accuracy: 0.4710 - val_loss: 0.3701 - val_binary_accuracy: 0.5960\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.4788 - binary_accuracy: 0.4710 - val_loss: 0.3664 - val_binary_accuracy: 0.5960\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4743 - binary_accuracy: 0.4710 - val_loss: 0.3613 - val_binary_accuracy: 0.5952\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.4682 - binary_accuracy: 0.4714 - val_loss: 0.3542 - val_binary_accuracy: 0.5952\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.4594 - binary_accuracy: 0.4714 - val_loss: 0.3434 - val_binary_accuracy: 0.5945\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.4457 - binary_accuracy: 0.4717 - val_loss: 0.3254 - val_binary_accuracy: 0.5934\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.4220 - binary_accuracy: 0.4720 - val_loss: 0.2930 - val_binary_accuracy: 0.5899\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3744 - binary_accuracy: 0.4728 - val_loss: 0.2482 - val_binary_accuracy: 0.5820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.2852 - binary_accuracy: 0.4758 - val_loss: 0.2772 - val_binary_accuracy: 0.4000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2540 - binary_accuracy: 0.5333 - val_loss: 0.2493 - val_binary_accuracy: 0.5133\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.2512 - binary_accuracy: 0.4936 - val_loss: 0.2672 - val_binary_accuracy: 0.4000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.2505 - binary_accuracy: 0.5333 - val_loss: 0.2513 - val_binary_accuracy: 0.4756\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2500 - binary_accuracy: 0.5047 - val_loss: 0.2652 - val_binary_accuracy: 0.4000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.2499 - binary_accuracy: 0.5333 - val_loss: 0.2514 - val_binary_accuracy: 0.4712\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2499 - binary_accuracy: 0.5059 - val_loss: 0.2661 - val_binary_accuracy: 0.4000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2502 - binary_accuracy: 0.5333 - val_loss: 0.2503 - val_binary_accuracy: 0.4996\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.2505 - binary_accuracy: 0.4985 - val_loss: 0.2698 - val_binary_accuracy: 0.4000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.2513 - binary_accuracy: 0.5333 - val_loss: 0.2483 - val_binary_accuracy: 0.5263\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.2520 - binary_accuracy: 0.4898 - val_loss: 0.2752 - val_binary_accuracy: 0.4000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.2532 - binary_accuracy: 0.5333 - val_loss: 0.2471 - val_binary_accuracy: 0.5418\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.2534 - binary_accuracy: 0.4861 - val_loss: 0.2768 - val_binary_accuracy: 0.4000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.2539 - binary_accuracy: 0.5333 - val_loss: 0.2474 - val_binary_accuracy: 0.5363\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.2529 - binary_accuracy: 0.4874 - val_loss: 0.2740 - val_binary_accuracy: 0.4000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.2528 - binary_accuracy: 0.5333 - val_loss: 0.2483 - val_binary_accuracy: 0.5254\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.2519 - binary_accuracy: 0.4901 - val_loss: 0.2716 - val_binary_accuracy: 0.4000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2519 - binary_accuracy: 0.5333 - val_loss: 0.2489 - val_binary_accuracy: 0.5185\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2515 - binary_accuracy: 0.4920 - val_loss: 0.2708 - val_binary_accuracy: 0.4000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2516 - binary_accuracy: 0.5333 - val_loss: 0.2489 - val_binary_accuracy: 0.5185\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.2514 - binary_accuracy: 0.4920 - val_loss: 0.2713 - val_binary_accuracy: 0.4000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.2518 - binary_accuracy: 0.5333 - val_loss: 0.2486 - val_binary_accuracy: 0.5228\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.2517 - binary_accuracy: 0.4908 - val_loss: 0.2723 - val_binary_accuracy: 0.4000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.2521 - binary_accuracy: 0.5333 - val_loss: 0.2482 - val_binary_accuracy: 0.5263\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2520 - binary_accuracy: 0.4898 - val_loss: 0.2731 - val_binary_accuracy: 0.4000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.2524 - binary_accuracy: 0.5333 - val_loss: 0.2481 - val_binary_accuracy: 0.5283\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2521 - binary_accuracy: 0.4894 - val_loss: 0.2731 - val_binary_accuracy: 0.4000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.2524 - binary_accuracy: 0.5333 - val_loss: 0.2482 - val_binary_accuracy: 0.5263\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.2520 - binary_accuracy: 0.4898 - val_loss: 0.2726 - val_binary_accuracy: 0.4000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2522 - binary_accuracy: 0.5333 - val_loss: 0.2484 - val_binary_accuracy: 0.5245\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.2519 - binary_accuracy: 0.4903 - val_loss: 0.2722 - val_binary_accuracy: 0.4000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.2521 - binary_accuracy: 0.5333 - val_loss: 0.2485 - val_binary_accuracy: 0.5236\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.2518 - binary_accuracy: 0.4906 - val_loss: 0.2721 - val_binary_accuracy: 0.4000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.2520 - binary_accuracy: 0.5333 - val_loss: 0.2485 - val_binary_accuracy: 0.5236\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.2518 - binary_accuracy: 0.4906 - val_loss: 0.2722 - val_binary_accuracy: 0.4000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.2521 - binary_accuracy: 0.5333 - val_loss: 0.2484 - val_binary_accuracy: 0.5245\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.2519 - binary_accuracy: 0.4903 - val_loss: 0.2724 - val_binary_accuracy: 0.4000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2522 - binary_accuracy: 0.5333 - val_loss: 0.2484 - val_binary_accuracy: 0.5254\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2519 - binary_accuracy: 0.4901 - val_loss: 0.2725 - val_binary_accuracy: 0.4000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.2522 - binary_accuracy: 0.5333 - val_loss: 0.2484 - val_binary_accuracy: 0.5254\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.2519 - binary_accuracy: 0.4901 - val_loss: 0.2725 - val_binary_accuracy: 0.4000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.2522 - binary_accuracy: 0.5333 - val_loss: 0.2484 - val_binary_accuracy: 0.5245\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.2519 - binary_accuracy: 0.4903 - val_loss: 0.2724 - val_binary_accuracy: 0.4000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.2521 - binary_accuracy: 0.5333 - val_loss: 0.2484 - val_binary_accuracy: 0.5245\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.2519 - binary_accuracy: 0.4903 - val_loss: 0.2723 - val_binary_accuracy: 0.4000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.2521 - binary_accuracy: 0.5333 - val_loss: 0.2484 - val_binary_accuracy: 0.5245\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2518 - binary_accuracy: 0.4903 - val_loss: 0.2723 - val_binary_accuracy: 0.4000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2521 - binary_accuracy: 0.5333 - val_loss: 0.2484 - val_binary_accuracy: 0.5245\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.2518 - binary_accuracy: 0.4903 - val_loss: 0.2723 - val_binary_accuracy: 0.4000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.2521 - binary_accuracy: 0.5333 - val_loss: 0.2484 - val_binary_accuracy: 0.5245\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.2519 - binary_accuracy: 0.4903 - val_loss: 0.2723 - val_binary_accuracy: 0.4000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.2521 - binary_accuracy: 0.5333 - val_loss: 0.2484 - val_binary_accuracy: 0.5245\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.2519 - binary_accuracy: 0.4903 - val_loss: 0.2723 - val_binary_accuracy: 0.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.2521 - binary_accuracy: 0.5333 - val_loss: 0.2484 - val_binary_accuracy: 0.5245\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.2519 - binary_accuracy: 0.4903 - val_loss: 0.2723 - val_binary_accuracy: 0.4000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.2521 - binary_accuracy: 0.5333 - val_loss: 0.2485 - val_binary_accuracy: 0.5236\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2518 - binary_accuracy: 0.4906 - val_loss: 0.2723 - val_binary_accuracy: 0.4000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2723 - binary_accuracy: 0.4000\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_48_input'), name='dense_48_input', description=\"created by layer 'dense_48_input'\"), but it was called on an input with incompatible shape (None, 100, 100, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_48_input'), name='dense_48_input', description=\"created by layer 'dense_48_input'\"), but it was called on an input with incompatible shape (None, 100, 100, 1).\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4501 - binary_accuracy: 0.5330WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_48_input'), name='dense_48_input', description=\"created by layer 'dense_48_input'\"), but it was called on an input with incompatible shape (None, 100, 100, 1).\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4501 - binary_accuracy: 0.5330 - val_loss: 0.5900 - val_binary_accuracy: 0.4003\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.4499 - binary_accuracy: 0.5330 - val_loss: 0.5898 - val_binary_accuracy: 0.4003\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.4498 - binary_accuracy: 0.5330 - val_loss: 0.5896 - val_binary_accuracy: 0.4003\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.4497 - binary_accuracy: 0.5330 - val_loss: 0.5895 - val_binary_accuracy: 0.4003\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.4496 - binary_accuracy: 0.5330 - val_loss: 0.5893 - val_binary_accuracy: 0.4003\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.4495 - binary_accuracy: 0.5330 - val_loss: 0.5892 - val_binary_accuracy: 0.4003\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.4494 - binary_accuracy: 0.5330 - val_loss: 0.5891 - val_binary_accuracy: 0.4003\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.4493 - binary_accuracy: 0.5330 - val_loss: 0.5890 - val_binary_accuracy: 0.4003\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.4492 - binary_accuracy: 0.5330 - val_loss: 0.5888 - val_binary_accuracy: 0.4003\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.4491 - binary_accuracy: 0.5330 - val_loss: 0.5887 - val_binary_accuracy: 0.4003\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.4490 - binary_accuracy: 0.5330 - val_loss: 0.5886 - val_binary_accuracy: 0.4003\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.4489 - binary_accuracy: 0.5330 - val_loss: 0.5885 - val_binary_accuracy: 0.4003\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.4489 - binary_accuracy: 0.5330 - val_loss: 0.5884 - val_binary_accuracy: 0.4003\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.4488 - binary_accuracy: 0.5330 - val_loss: 0.5883 - val_binary_accuracy: 0.4003\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.4487 - binary_accuracy: 0.5330 - val_loss: 0.5881 - val_binary_accuracy: 0.4003\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.4486 - binary_accuracy: 0.5330 - val_loss: 0.5880 - val_binary_accuracy: 0.4003\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.4485 - binary_accuracy: 0.5330 - val_loss: 0.5879 - val_binary_accuracy: 0.4003\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.4484 - binary_accuracy: 0.5330 - val_loss: 0.5878 - val_binary_accuracy: 0.4003\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.4484 - binary_accuracy: 0.5330 - val_loss: 0.5876 - val_binary_accuracy: 0.4003\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.4483 - binary_accuracy: 0.5330 - val_loss: 0.5875 - val_binary_accuracy: 0.4003\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.4482 - binary_accuracy: 0.5330 - val_loss: 0.5874 - val_binary_accuracy: 0.4003\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.4481 - binary_accuracy: 0.5330 - val_loss: 0.5873 - val_binary_accuracy: 0.4003\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.4480 - binary_accuracy: 0.5330 - val_loss: 0.5871 - val_binary_accuracy: 0.4003\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.4479 - binary_accuracy: 0.5330 - val_loss: 0.5870 - val_binary_accuracy: 0.4003\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.4479 - binary_accuracy: 0.5330 - val_loss: 0.5869 - val_binary_accuracy: 0.4003\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.4478 - binary_accuracy: 0.5330 - val_loss: 0.5867 - val_binary_accuracy: 0.4003\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.4477 - binary_accuracy: 0.5330 - val_loss: 0.5866 - val_binary_accuracy: 0.4003\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4476 - binary_accuracy: 0.5330 - val_loss: 0.5865 - val_binary_accuracy: 0.4003\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.4475 - binary_accuracy: 0.5330 - val_loss: 0.5863 - val_binary_accuracy: 0.4003\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.4474 - binary_accuracy: 0.5330 - val_loss: 0.5862 - val_binary_accuracy: 0.4003\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.4473 - binary_accuracy: 0.5330 - val_loss: 0.5861 - val_binary_accuracy: 0.4003\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.4472 - binary_accuracy: 0.5330 - val_loss: 0.5859 - val_binary_accuracy: 0.4003\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.4471 - binary_accuracy: 0.5330 - val_loss: 0.5858 - val_binary_accuracy: 0.4003\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.4470 - binary_accuracy: 0.5330 - val_loss: 0.5856 - val_binary_accuracy: 0.4003\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.4470 - binary_accuracy: 0.5330 - val_loss: 0.5855 - val_binary_accuracy: 0.4003\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.4469 - binary_accuracy: 0.5330 - val_loss: 0.5853 - val_binary_accuracy: 0.4003\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.4468 - binary_accuracy: 0.5330 - val_loss: 0.5852 - val_binary_accuracy: 0.4003\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.4467 - binary_accuracy: 0.5330 - val_loss: 0.5850 - val_binary_accuracy: 0.4003\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.4466 - binary_accuracy: 0.5330 - val_loss: 0.5849 - val_binary_accuracy: 0.4003\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.4465 - binary_accuracy: 0.5330 - val_loss: 0.5847 - val_binary_accuracy: 0.4003\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.4464 - binary_accuracy: 0.5330 - val_loss: 0.5845 - val_binary_accuracy: 0.4003\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.4462 - binary_accuracy: 0.5330 - val_loss: 0.5844 - val_binary_accuracy: 0.4003\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.4461 - binary_accuracy: 0.5330 - val_loss: 0.5842 - val_binary_accuracy: 0.4003\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.4460 - binary_accuracy: 0.5330 - val_loss: 0.5840 - val_binary_accuracy: 0.4003\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.4459 - binary_accuracy: 0.5330 - val_loss: 0.5839 - val_binary_accuracy: 0.4003\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.4458 - binary_accuracy: 0.5330 - val_loss: 0.5837 - val_binary_accuracy: 0.4003\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.4457 - binary_accuracy: 0.5330 - val_loss: 0.5835 - val_binary_accuracy: 0.4003\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.4456 - binary_accuracy: 0.5330 - val_loss: 0.5833 - val_binary_accuracy: 0.4003\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.4455 - binary_accuracy: 0.5330 - val_loss: 0.5831 - val_binary_accuracy: 0.4003\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.4453 - binary_accuracy: 0.5330 - val_loss: 0.5829 - val_binary_accuracy: 0.4003\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.4452 - binary_accuracy: 0.5330 - val_loss: 0.5827 - val_binary_accuracy: 0.4003\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.4451 - binary_accuracy: 0.5330 - val_loss: 0.5825 - val_binary_accuracy: 0.4003\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.4449 - binary_accuracy: 0.5330 - val_loss: 0.5823 - val_binary_accuracy: 0.4003\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.4448 - binary_accuracy: 0.5330 - val_loss: 0.5820 - val_binary_accuracy: 0.4003\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.4446 - binary_accuracy: 0.5330 - val_loss: 0.5818 - val_binary_accuracy: 0.4003\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.4445 - binary_accuracy: 0.5330 - val_loss: 0.5815 - val_binary_accuracy: 0.4003\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.4443 - binary_accuracy: 0.5330 - val_loss: 0.5813 - val_binary_accuracy: 0.4003\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.4442 - binary_accuracy: 0.5330 - val_loss: 0.5810 - val_binary_accuracy: 0.4003\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.4440 - binary_accuracy: 0.5330 - val_loss: 0.5807 - val_binary_accuracy: 0.4003\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.4438 - binary_accuracy: 0.5330 - val_loss: 0.5805 - val_binary_accuracy: 0.4003\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.4436 - binary_accuracy: 0.5330 - val_loss: 0.5802 - val_binary_accuracy: 0.4003\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.4434 - binary_accuracy: 0.5330 - val_loss: 0.5798 - val_binary_accuracy: 0.4003\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.4432 - binary_accuracy: 0.5330 - val_loss: 0.5795 - val_binary_accuracy: 0.4003\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.4430 - binary_accuracy: 0.5330 - val_loss: 0.5792 - val_binary_accuracy: 0.4003\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.4428 - binary_accuracy: 0.5330 - val_loss: 0.5788 - val_binary_accuracy: 0.4003\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.4426 - binary_accuracy: 0.5330 - val_loss: 0.5784 - val_binary_accuracy: 0.4003\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.4423 - binary_accuracy: 0.5330 - val_loss: 0.5780 - val_binary_accuracy: 0.4003\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.4421 - binary_accuracy: 0.5330 - val_loss: 0.5776 - val_binary_accuracy: 0.4040\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.4418 - binary_accuracy: 0.5290 - val_loss: 0.5771 - val_binary_accuracy: 0.4040\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.4415 - binary_accuracy: 0.5290 - val_loss: 0.5767 - val_binary_accuracy: 0.4040\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.4412 - binary_accuracy: 0.5290 - val_loss: 0.5761 - val_binary_accuracy: 0.4040\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.4409 - binary_accuracy: 0.5290 - val_loss: 0.5756 - val_binary_accuracy: 0.4040\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.4405 - binary_accuracy: 0.5290 - val_loss: 0.5750 - val_binary_accuracy: 0.4040\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.4402 - binary_accuracy: 0.5290 - val_loss: 0.5743 - val_binary_accuracy: 0.4040\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.4398 - binary_accuracy: 0.5290 - val_loss: 0.5736 - val_binary_accuracy: 0.4040\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.4393 - binary_accuracy: 0.5290 - val_loss: 0.5728 - val_binary_accuracy: 0.4040\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.4388 - binary_accuracy: 0.5290 - val_loss: 0.5720 - val_binary_accuracy: 0.4040\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.4383 - binary_accuracy: 0.5290 - val_loss: 0.5711 - val_binary_accuracy: 0.4040\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.4378 - binary_accuracy: 0.5290 - val_loss: 0.5700 - val_binary_accuracy: 0.4040\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.4371 - binary_accuracy: 0.5290 - val_loss: 0.5688 - val_binary_accuracy: 0.4040\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.4364 - binary_accuracy: 0.5290 - val_loss: 0.5675 - val_binary_accuracy: 0.4040\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.4357 - binary_accuracy: 0.5290 - val_loss: 0.5660 - val_binary_accuracy: 0.4048\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.4348 - binary_accuracy: 0.5286 - val_loss: 0.5643 - val_binary_accuracy: 0.4048\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.4338 - binary_accuracy: 0.5286 - val_loss: 0.5623 - val_binary_accuracy: 0.4048\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.4326 - binary_accuracy: 0.5286 - val_loss: 0.5599 - val_binary_accuracy: 0.4048\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.4313 - binary_accuracy: 0.5286 - val_loss: 0.5570 - val_binary_accuracy: 0.4048\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.4297 - binary_accuracy: 0.5286 - val_loss: 0.5536 - val_binary_accuracy: 0.4055\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.4277 - binary_accuracy: 0.5283 - val_loss: 0.5493 - val_binary_accuracy: 0.4055\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.4253 - binary_accuracy: 0.5283 - val_loss: 0.5438 - val_binary_accuracy: 0.4055\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.4223 - binary_accuracy: 0.5283 - val_loss: 0.5366 - val_binary_accuracy: 0.4066\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.4183 - binary_accuracy: 0.5280 - val_loss: 0.5268 - val_binary_accuracy: 0.4075\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.4128 - binary_accuracy: 0.5277 - val_loss: 0.5127 - val_binary_accuracy: 0.4088\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.4049 - binary_accuracy: 0.5274 - val_loss: 0.4908 - val_binary_accuracy: 0.4108\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 113ms/step - loss: 0.3922 - binary_accuracy: 0.5269 - val_loss: 0.4527 - val_binary_accuracy: 0.4127\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.3694 - binary_accuracy: 0.5261 - val_loss: 0.3791 - val_binary_accuracy: 0.4175\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.3225 - binary_accuracy: 0.5245 - val_loss: 0.2667 - val_binary_accuracy: 0.4560\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.2548 - binary_accuracy: 0.5145 - val_loss: 0.2409 - val_binary_accuracy: 0.6000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2869 - val_binary_accuracy: 0.4370\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.2642 - binary_accuracy: 0.5193 - val_loss: 0.2421 - val_binary_accuracy: 0.6000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.2565 - binary_accuracy: 0.4667 - val_loss: 0.2701 - val_binary_accuracy: 0.4499\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2701 - binary_accuracy: 0.4499\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_50_input'), name='dense_50_input', description=\"created by layer 'dense_50_input'\"), but it was called on an input with incompatible shape (None, 100, 100, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_50_input'), name='dense_50_input', description=\"created by layer 'dense_50_input'\"), but it was called on an input with incompatible shape (None, 100, 100, 1).\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4492 - binary_accuracy: 0.5330WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_50_input'), name='dense_50_input', description=\"created by layer 'dense_50_input'\"), but it was called on an input with incompatible shape (None, 100, 100, 1).\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4492 - binary_accuracy: 0.5330 - val_loss: 0.5884 - val_binary_accuracy: 0.4003\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.4488 - binary_accuracy: 0.5330 - val_loss: 0.5880 - val_binary_accuracy: 0.4003\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.4485 - binary_accuracy: 0.5330 - val_loss: 0.5877 - val_binary_accuracy: 0.4003\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.4483 - binary_accuracy: 0.5330 - val_loss: 0.5873 - val_binary_accuracy: 0.4003\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.4480 - binary_accuracy: 0.5330 - val_loss: 0.5869 - val_binary_accuracy: 0.4003\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.4478 - binary_accuracy: 0.5330 - val_loss: 0.5866 - val_binary_accuracy: 0.4003\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.4476 - binary_accuracy: 0.5330 - val_loss: 0.5862 - val_binary_accuracy: 0.4003\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.4473 - binary_accuracy: 0.5330 - val_loss: 0.5859 - val_binary_accuracy: 0.4003\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.4471 - binary_accuracy: 0.5330 - val_loss: 0.5855 - val_binary_accuracy: 0.4003\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.4469 - binary_accuracy: 0.5330 - val_loss: 0.5851 - val_binary_accuracy: 0.4003\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.4466 - binary_accuracy: 0.5330 - val_loss: 0.5847 - val_binary_accuracy: 0.4003\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.4463 - binary_accuracy: 0.5330 - val_loss: 0.5843 - val_binary_accuracy: 0.4003\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.4461 - binary_accuracy: 0.5330 - val_loss: 0.5838 - val_binary_accuracy: 0.4003\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.4458 - binary_accuracy: 0.5330 - val_loss: 0.5833 - val_binary_accuracy: 0.4003\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.4455 - binary_accuracy: 0.5330 - val_loss: 0.5828 - val_binary_accuracy: 0.4003\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.4451 - binary_accuracy: 0.5330 - val_loss: 0.5823 - val_binary_accuracy: 0.4003\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.4448 - binary_accuracy: 0.5330 - val_loss: 0.5817 - val_binary_accuracy: 0.4003\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.4444 - binary_accuracy: 0.5330 - val_loss: 0.5810 - val_binary_accuracy: 0.4003\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.4439 - binary_accuracy: 0.5330 - val_loss: 0.5803 - val_binary_accuracy: 0.4003\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.4435 - binary_accuracy: 0.5330 - val_loss: 0.5795 - val_binary_accuracy: 0.4003\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.4429 - binary_accuracy: 0.5330 - val_loss: 0.5785 - val_binary_accuracy: 0.4003\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.4423 - binary_accuracy: 0.5330 - val_loss: 0.5774 - val_binary_accuracy: 0.4003\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.4416 - binary_accuracy: 0.5330 - val_loss: 0.5762 - val_binary_accuracy: 0.4003\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.4408 - binary_accuracy: 0.5330 - val_loss: 0.5746 - val_binary_accuracy: 0.4040\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.4399 - binary_accuracy: 0.5290 - val_loss: 0.5727 - val_binary_accuracy: 0.4040\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.4387 - binary_accuracy: 0.5290 - val_loss: 0.5702 - val_binary_accuracy: 0.4040\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.4372 - binary_accuracy: 0.5290 - val_loss: 0.5669 - val_binary_accuracy: 0.4040\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.4352 - binary_accuracy: 0.5290 - val_loss: 0.5620 - val_binary_accuracy: 0.4048\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.4324 - binary_accuracy: 0.5286 - val_loss: 0.5544 - val_binary_accuracy: 0.4048\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.4281 - binary_accuracy: 0.5286 - val_loss: 0.5410 - val_binary_accuracy: 0.4055\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.4206 - binary_accuracy: 0.5283 - val_loss: 0.5125 - val_binary_accuracy: 0.4075\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.4045 - binary_accuracy: 0.5277 - val_loss: 0.4240 - val_binary_accuracy: 0.4127\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.3508 - binary_accuracy: 0.5261 - val_loss: 0.2453 - val_binary_accuracy: 0.6000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.2871 - binary_accuracy: 0.4667 - val_loss: 0.4134 - val_binary_accuracy: 0.4135\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.3441 - binary_accuracy: 0.5259 - val_loss: 0.2988 - val_binary_accuracy: 0.4280\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.2704 - binary_accuracy: 0.5216 - val_loss: 0.2510 - val_binary_accuracy: 0.6000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.3020 - binary_accuracy: 0.4667 - val_loss: 0.3374 - val_binary_accuracy: 0.4191\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.2944 - binary_accuracy: 0.5238 - val_loss: 0.2417 - val_binary_accuracy: 0.6000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.2574 - binary_accuracy: 0.4667 - val_loss: 0.2953 - val_binary_accuracy: 0.4290\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.2682 - binary_accuracy: 0.5214 - val_loss: 0.2411 - val_binary_accuracy: 0.6000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.2705 - binary_accuracy: 0.4667 - val_loss: 0.3147 - val_binary_accuracy: 0.4216\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.2799 - binary_accuracy: 0.5229 - val_loss: 0.2408 - val_binary_accuracy: 0.6000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.2610 - binary_accuracy: 0.4667 - val_loss: 0.2963 - val_binary_accuracy: 0.4280\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.2688 - binary_accuracy: 0.5216 - val_loss: 0.2406 - val_binary_accuracy: 0.6000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.2640 - binary_accuracy: 0.4667 - val_loss: 0.2997 - val_binary_accuracy: 0.4270\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.2707 - binary_accuracy: 0.5218 - val_loss: 0.2407 - val_binary_accuracy: 0.6000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.2623 - binary_accuracy: 0.4667 - val_loss: 0.2954 - val_binary_accuracy: 0.4280\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.2682 - binary_accuracy: 0.5216 - val_loss: 0.2407 - val_binary_accuracy: 0.6000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.2622 - binary_accuracy: 0.4667 - val_loss: 0.2946 - val_binary_accuracy: 0.4280\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.2676 - binary_accuracy: 0.5216 - val_loss: 0.2408 - val_binary_accuracy: 0.6000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.2619 - binary_accuracy: 0.4667 - val_loss: 0.2938 - val_binary_accuracy: 0.4290\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.2672 - binary_accuracy: 0.5214 - val_loss: 0.2408 - val_binary_accuracy: 0.6000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.2618 - binary_accuracy: 0.4667 - val_loss: 0.2934 - val_binary_accuracy: 0.4280\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.2669 - binary_accuracy: 0.5216 - val_loss: 0.2408 - val_binary_accuracy: 0.6000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.2617 - binary_accuracy: 0.4667 - val_loss: 0.2932 - val_binary_accuracy: 0.4280\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.2668 - binary_accuracy: 0.5216 - val_loss: 0.2408 - val_binary_accuracy: 0.6000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.2617 - binary_accuracy: 0.4667 - val_loss: 0.2931 - val_binary_accuracy: 0.4280\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.2667 - binary_accuracy: 0.5216 - val_loss: 0.2409 - val_binary_accuracy: 0.6000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.2617 - binary_accuracy: 0.4667 - val_loss: 0.2931 - val_binary_accuracy: 0.4280\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.2666 - binary_accuracy: 0.5216 - val_loss: 0.2409 - val_binary_accuracy: 0.6000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.2616 - binary_accuracy: 0.4667 - val_loss: 0.2931 - val_binary_accuracy: 0.4280\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.2666 - binary_accuracy: 0.5216 - val_loss: 0.2409 - val_binary_accuracy: 0.6000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.2616 - binary_accuracy: 0.4667 - val_loss: 0.2931 - val_binary_accuracy: 0.4270\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.2666 - binary_accuracy: 0.5218 - val_loss: 0.2409 - val_binary_accuracy: 0.6000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.2616 - binary_accuracy: 0.4667 - val_loss: 0.2931 - val_binary_accuracy: 0.4270\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.2666 - binary_accuracy: 0.5218 - val_loss: 0.2409 - val_binary_accuracy: 0.6000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.2616 - binary_accuracy: 0.4667 - val_loss: 0.2931 - val_binary_accuracy: 0.4270\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.2665 - binary_accuracy: 0.5218 - val_loss: 0.2409 - val_binary_accuracy: 0.6000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.2616 - binary_accuracy: 0.4667 - val_loss: 0.2932 - val_binary_accuracy: 0.4270\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.2665 - binary_accuracy: 0.5218 - val_loss: 0.2409 - val_binary_accuracy: 0.6000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.2616 - binary_accuracy: 0.4667 - val_loss: 0.2932 - val_binary_accuracy: 0.4258\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.2665 - binary_accuracy: 0.5220 - val_loss: 0.2409 - val_binary_accuracy: 0.6000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.2615 - binary_accuracy: 0.4667 - val_loss: 0.2932 - val_binary_accuracy: 0.4258\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.2665 - binary_accuracy: 0.5220 - val_loss: 0.2410 - val_binary_accuracy: 0.6000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.2615 - binary_accuracy: 0.4667 - val_loss: 0.2932 - val_binary_accuracy: 0.4258\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.2664 - binary_accuracy: 0.5220 - val_loss: 0.2410 - val_binary_accuracy: 0.6000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.2615 - binary_accuracy: 0.4667 - val_loss: 0.2932 - val_binary_accuracy: 0.4258\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.2664 - binary_accuracy: 0.5220 - val_loss: 0.2410 - val_binary_accuracy: 0.6000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.2615 - binary_accuracy: 0.4667 - val_loss: 0.2932 - val_binary_accuracy: 0.4248\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.2664 - binary_accuracy: 0.5222 - val_loss: 0.2410 - val_binary_accuracy: 0.6000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.2615 - binary_accuracy: 0.4667 - val_loss: 0.2933 - val_binary_accuracy: 0.4248\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.2664 - binary_accuracy: 0.5222 - val_loss: 0.2410 - val_binary_accuracy: 0.6000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.2615 - binary_accuracy: 0.4667 - val_loss: 0.2933 - val_binary_accuracy: 0.4248\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.2663 - binary_accuracy: 0.5222 - val_loss: 0.2410 - val_binary_accuracy: 0.6000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.2615 - binary_accuracy: 0.4667 - val_loss: 0.2933 - val_binary_accuracy: 0.4248\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.2663 - binary_accuracy: 0.5222 - val_loss: 0.2410 - val_binary_accuracy: 0.6000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.2614 - binary_accuracy: 0.4667 - val_loss: 0.2933 - val_binary_accuracy: 0.4237\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.2663 - binary_accuracy: 0.5225 - val_loss: 0.2411 - val_binary_accuracy: 0.6000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.2614 - binary_accuracy: 0.4667 - val_loss: 0.2933 - val_binary_accuracy: 0.4237\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.2663 - binary_accuracy: 0.5225 - val_loss: 0.2411 - val_binary_accuracy: 0.6000\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 142ms/step - loss: 0.2614 - binary_accuracy: 0.4667 - val_loss: 0.2933 - val_binary_accuracy: 0.4237\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.2662 - binary_accuracy: 0.5225 - val_loss: 0.2411 - val_binary_accuracy: 0.6000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.2614 - binary_accuracy: 0.4667 - val_loss: 0.2934 - val_binary_accuracy: 0.4227\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.2662 - binary_accuracy: 0.5227 - val_loss: 0.2411 - val_binary_accuracy: 0.6000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.2614 - binary_accuracy: 0.4667 - val_loss: 0.2934 - val_binary_accuracy: 0.4227\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.2662 - binary_accuracy: 0.5227 - val_loss: 0.2411 - val_binary_accuracy: 0.6000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.2614 - binary_accuracy: 0.4667 - val_loss: 0.2934 - val_binary_accuracy: 0.4227\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.2662 - binary_accuracy: 0.5227 - val_loss: 0.2411 - val_binary_accuracy: 0.6000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.2614 - binary_accuracy: 0.4667 - val_loss: 0.2934 - val_binary_accuracy: 0.4227\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.2662 - binary_accuracy: 0.5227 - val_loss: 0.2411 - val_binary_accuracy: 0.6000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2411 - binary_accuracy: 0.6000\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_52_input'), name='dense_52_input', description=\"created by layer 'dense_52_input'\"), but it was called on an input with incompatible shape (None, 100, 100, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_52_input'), name='dense_52_input', description=\"created by layer 'dense_52_input'\"), but it was called on an input with incompatible shape (None, 100, 100, 1).\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4760 - binary_accuracy: 0.4667WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_52_input'), name='dense_52_input', description=\"created by layer 'dense_52_input'\"), but it was called on an input with incompatible shape (None, 100, 100, 1).\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4760 - binary_accuracy: 0.4667 - val_loss: 0.3078 - val_binary_accuracy: 0.5960\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3980 - binary_accuracy: 0.4710 - val_loss: 0.4317 - val_binary_accuracy: 0.4000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3529 - binary_accuracy: 0.5333 - val_loss: 0.2528 - val_binary_accuracy: 0.5934\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.3009 - binary_accuracy: 0.4720 - val_loss: 0.4670 - val_binary_accuracy: 0.4000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3755 - binary_accuracy: 0.5333 - val_loss: 0.3954 - val_binary_accuracy: 0.4000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3289 - binary_accuracy: 0.5333 - val_loss: 0.2445 - val_binary_accuracy: 0.5912\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.2760 - binary_accuracy: 0.4726 - val_loss: 0.4228 - val_binary_accuracy: 0.4000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3471 - binary_accuracy: 0.5333 - val_loss: 0.2850 - val_binary_accuracy: 0.4000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.2588 - binary_accuracy: 0.5333 - val_loss: 0.2597 - val_binary_accuracy: 0.5952\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.3165 - binary_accuracy: 0.4714 - val_loss: 0.3798 - val_binary_accuracy: 0.4000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3184 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5860\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.2571 - binary_accuracy: 0.4743 - val_loss: 0.3421 - val_binary_accuracy: 0.4000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.2933 - binary_accuracy: 0.5333 - val_loss: 0.2496 - val_binary_accuracy: 0.5934\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.2927 - binary_accuracy: 0.4720 - val_loss: 0.3716 - val_binary_accuracy: 0.4000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3130 - binary_accuracy: 0.5333 - val_loss: 0.2449 - val_binary_accuracy: 0.5831\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.2546 - binary_accuracy: 0.4753 - val_loss: 0.3155 - val_binary_accuracy: 0.4000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.2762 - binary_accuracy: 0.5333 - val_loss: 0.2507 - val_binary_accuracy: 0.5934\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.2957 - binary_accuracy: 0.4720 - val_loss: 0.3570 - val_binary_accuracy: 0.4000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3032 - binary_accuracy: 0.5333 - val_loss: 0.2432 - val_binary_accuracy: 0.5873\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.2605 - binary_accuracy: 0.4739 - val_loss: 0.3311 - val_binary_accuracy: 0.4000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.2861 - binary_accuracy: 0.5333 - val_loss: 0.2452 - val_binary_accuracy: 0.5925\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.2790 - binary_accuracy: 0.4723 - val_loss: 0.3509 - val_binary_accuracy: 0.4000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.2991 - binary_accuracy: 0.5333 - val_loss: 0.2431 - val_binary_accuracy: 0.5879\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.2614 - binary_accuracy: 0.4737 - val_loss: 0.3284 - val_binary_accuracy: 0.4000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.2843 - binary_accuracy: 0.5333 - val_loss: 0.2446 - val_binary_accuracy: 0.5912\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.2764 - binary_accuracy: 0.4726 - val_loss: 0.3451 - val_binary_accuracy: 0.4000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.2953 - binary_accuracy: 0.5333 - val_loss: 0.2430 - val_binary_accuracy: 0.5885\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.2632 - binary_accuracy: 0.4734 - val_loss: 0.3292 - val_binary_accuracy: 0.4000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.2848 - binary_accuracy: 0.5333 - val_loss: 0.2440 - val_binary_accuracy: 0.5912\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.2734 - binary_accuracy: 0.4726 - val_loss: 0.3405 - val_binary_accuracy: 0.4000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.2922 - binary_accuracy: 0.5333 - val_loss: 0.2430 - val_binary_accuracy: 0.5885\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.2650 - binary_accuracy: 0.4734 - val_loss: 0.3302 - val_binary_accuracy: 0.4000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.2855 - binary_accuracy: 0.5333 - val_loss: 0.2436 - val_binary_accuracy: 0.5899\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.2712 - binary_accuracy: 0.4728 - val_loss: 0.3370 - val_binary_accuracy: 0.4000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.2899 - binary_accuracy: 0.5333 - val_loss: 0.2431 - val_binary_accuracy: 0.5892\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.2663 - binary_accuracy: 0.4731 - val_loss: 0.3308 - val_binary_accuracy: 0.4000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.2859 - binary_accuracy: 0.5333 - val_loss: 0.2434 - val_binary_accuracy: 0.5899\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.2698 - binary_accuracy: 0.4728 - val_loss: 0.3346 - val_binary_accuracy: 0.4000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.2883 - binary_accuracy: 0.5333 - val_loss: 0.2431 - val_binary_accuracy: 0.5892\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.2672 - binary_accuracy: 0.4731 - val_loss: 0.3311 - val_binary_accuracy: 0.4000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.2861 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5892\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.2691 - binary_accuracy: 0.4731 - val_loss: 0.3331 - val_binary_accuracy: 0.4000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.2873 - binary_accuracy: 0.5333 - val_loss: 0.2432 - val_binary_accuracy: 0.5892\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.2677 - binary_accuracy: 0.4731 - val_loss: 0.3312 - val_binary_accuracy: 0.4000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.2861 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5892\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.2687 - binary_accuracy: 0.4731 - val_loss: 0.3322 - val_binary_accuracy: 0.4000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.2867 - binary_accuracy: 0.5333 - val_loss: 0.2432 - val_binary_accuracy: 0.5892\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.2680 - binary_accuracy: 0.4731 - val_loss: 0.3312 - val_binary_accuracy: 0.4000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.2861 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5892\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.2684 - binary_accuracy: 0.4731 - val_loss: 0.3316 - val_binary_accuracy: 0.4000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.2864 - binary_accuracy: 0.5333 - val_loss: 0.2432 - val_binary_accuracy: 0.5892\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.2681 - binary_accuracy: 0.4731 - val_loss: 0.3312 - val_binary_accuracy: 0.4000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.2861 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5892\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.2683 - binary_accuracy: 0.4731 - val_loss: 0.3313 - val_binary_accuracy: 0.4000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.2862 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5892\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.2682 - binary_accuracy: 0.4731 - val_loss: 0.3311 - val_binary_accuracy: 0.4000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.2860 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5892\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.2683 - binary_accuracy: 0.4731 - val_loss: 0.3312 - val_binary_accuracy: 0.4000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.2861 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5885\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.2682 - binary_accuracy: 0.4734 - val_loss: 0.3310 - val_binary_accuracy: 0.4000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.2860 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5885\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.2683 - binary_accuracy: 0.4734 - val_loss: 0.3310 - val_binary_accuracy: 0.4000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.2860 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5885\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.2682 - binary_accuracy: 0.4734 - val_loss: 0.3310 - val_binary_accuracy: 0.4000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.2859 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5885\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.2682 - binary_accuracy: 0.4734 - val_loss: 0.3310 - val_binary_accuracy: 0.4000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.2859 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5885\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.2682 - binary_accuracy: 0.4734 - val_loss: 0.3309 - val_binary_accuracy: 0.4000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.2859 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5885\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.2682 - binary_accuracy: 0.4734 - val_loss: 0.3309 - val_binary_accuracy: 0.4000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.2859 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5885\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.2682 - binary_accuracy: 0.4734 - val_loss: 0.3309 - val_binary_accuracy: 0.4000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.2859 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5885\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.2682 - binary_accuracy: 0.4734 - val_loss: 0.3309 - val_binary_accuracy: 0.4000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.2858 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5885\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.2682 - binary_accuracy: 0.4734 - val_loss: 0.3309 - val_binary_accuracy: 0.4000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.2858 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5885\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.2682 - binary_accuracy: 0.4734 - val_loss: 0.3309 - val_binary_accuracy: 0.4000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.2858 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5885\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.2682 - binary_accuracy: 0.4734 - val_loss: 0.3308 - val_binary_accuracy: 0.4000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.2858 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5885\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.2682 - binary_accuracy: 0.4734 - val_loss: 0.3308 - val_binary_accuracy: 0.4000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.2858 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5885\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.2682 - binary_accuracy: 0.4734 - val_loss: 0.3308 - val_binary_accuracy: 0.4000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.2858 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5885\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.2683 - binary_accuracy: 0.4734 - val_loss: 0.3308 - val_binary_accuracy: 0.4000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.2858 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5885\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 209ms/step - loss: 0.2683 - binary_accuracy: 0.4734 - val_loss: 0.3308 - val_binary_accuracy: 0.4000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.2858 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5879\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.2683 - binary_accuracy: 0.4737 - val_loss: 0.3308 - val_binary_accuracy: 0.4000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.2858 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5879\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.2683 - binary_accuracy: 0.4737 - val_loss: 0.3308 - val_binary_accuracy: 0.4000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.2857 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5879\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.2683 - binary_accuracy: 0.4737 - val_loss: 0.3308 - val_binary_accuracy: 0.4000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.2857 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5879\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.2683 - binary_accuracy: 0.4737 - val_loss: 0.3308 - val_binary_accuracy: 0.4000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.2857 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5879\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.2683 - binary_accuracy: 0.4737 - val_loss: 0.3307 - val_binary_accuracy: 0.4000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.2857 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5879\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.2683 - binary_accuracy: 0.4737 - val_loss: 0.3307 - val_binary_accuracy: 0.4000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3307 - binary_accuracy: 0.4000\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_54_input'), name='dense_54_input', description=\"created by layer 'dense_54_input'\"), but it was called on an input with incompatible shape (None, 50, 50, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_54_input'), name='dense_54_input', description=\"created by layer 'dense_54_input'\"), but it was called on an input with incompatible shape (None, 50, 50, 1).\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5047 - binary_accuracy: 0.4667WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_54_input'), name='dense_54_input', description=\"created by layer 'dense_54_input'\"), but it was called on an input with incompatible shape (None, 50, 50, 1).\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5047 - binary_accuracy: 0.4667 - val_loss: 0.3890 - val_binary_accuracy: 0.5998\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5037 - binary_accuracy: 0.4670 - val_loss: 0.3884 - val_binary_accuracy: 0.5998\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5028 - binary_accuracy: 0.4670 - val_loss: 0.3878 - val_binary_accuracy: 0.5998\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5019 - binary_accuracy: 0.4670 - val_loss: 0.3873 - val_binary_accuracy: 0.5998\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5010 - binary_accuracy: 0.4670 - val_loss: 0.3866 - val_binary_accuracy: 0.5998\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5000 - binary_accuracy: 0.4670 - val_loss: 0.3858 - val_binary_accuracy: 0.5998\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4989 - binary_accuracy: 0.4670 - val_loss: 0.3850 - val_binary_accuracy: 0.5998\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4976 - binary_accuracy: 0.4670 - val_loss: 0.3839 - val_binary_accuracy: 0.5998\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4962 - binary_accuracy: 0.4670 - val_loss: 0.3827 - val_binary_accuracy: 0.5998\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4944 - binary_accuracy: 0.4670 - val_loss: 0.3811 - val_binary_accuracy: 0.5998\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4923 - binary_accuracy: 0.4670 - val_loss: 0.3790 - val_binary_accuracy: 0.5998\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4897 - binary_accuracy: 0.4670 - val_loss: 0.3762 - val_binary_accuracy: 0.5998\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4862 - binary_accuracy: 0.4670 - val_loss: 0.3722 - val_binary_accuracy: 0.5961\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4814 - binary_accuracy: 0.4709 - val_loss: 0.3662 - val_binary_accuracy: 0.5961\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4742 - binary_accuracy: 0.4709 - val_loss: 0.3562 - val_binary_accuracy: 0.5953\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4620 - binary_accuracy: 0.4713 - val_loss: 0.3367 - val_binary_accuracy: 0.5946\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4373 - binary_accuracy: 0.4717 - val_loss: 0.2901 - val_binary_accuracy: 0.5911\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3701 - binary_accuracy: 0.4725 - val_loss: 0.2572 - val_binary_accuracy: 0.4000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2489 - binary_accuracy: 0.5333 - val_loss: 0.2568 - val_binary_accuracy: 0.4000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2489 - binary_accuracy: 0.5333 - val_loss: 0.2580 - val_binary_accuracy: 0.4000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2489 - binary_accuracy: 0.5333 - val_loss: 0.2539 - val_binary_accuracy: 0.4000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2492 - binary_accuracy: 0.5333 - val_loss: 0.2742 - val_binary_accuracy: 0.4000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2530 - binary_accuracy: 0.5333 - val_loss: 0.2483 - val_binary_accuracy: 0.5839\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2863 - binary_accuracy: 0.4751 - val_loss: 0.3315 - val_binary_accuracy: 0.4000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2851 - binary_accuracy: 0.5333 - val_loss: 0.2454 - val_binary_accuracy: 0.5599\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2559 - binary_accuracy: 0.4816 - val_loss: 0.2883 - val_binary_accuracy: 0.4000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2594 - binary_accuracy: 0.5333 - val_loss: 0.2447 - val_binary_accuracy: 0.5656\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2583 - binary_accuracy: 0.4798 - val_loss: 0.2885 - val_binary_accuracy: 0.4000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2595 - binary_accuracy: 0.5333 - val_loss: 0.2452 - val_binary_accuracy: 0.5615\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2565 - binary_accuracy: 0.4811 - val_loss: 0.2834 - val_binary_accuracy: 0.4000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2570 - binary_accuracy: 0.5333 - val_loss: 0.2458 - val_binary_accuracy: 0.5561\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2551 - binary_accuracy: 0.4825 - val_loss: 0.2808 - val_binary_accuracy: 0.4000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2557 - binary_accuracy: 0.5333 - val_loss: 0.2460 - val_binary_accuracy: 0.5544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2547 - binary_accuracy: 0.4830 - val_loss: 0.2802 - val_binary_accuracy: 0.4000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2555 - binary_accuracy: 0.5333 - val_loss: 0.2460 - val_binary_accuracy: 0.5544\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2547 - binary_accuracy: 0.4830 - val_loss: 0.2807 - val_binary_accuracy: 0.4000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2557 - binary_accuracy: 0.5333 - val_loss: 0.2459 - val_binary_accuracy: 0.5561\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2550 - binary_accuracy: 0.4825 - val_loss: 0.2813 - val_binary_accuracy: 0.4000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2560 - binary_accuracy: 0.5333 - val_loss: 0.2458 - val_binary_accuracy: 0.5561\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2551 - binary_accuracy: 0.4825 - val_loss: 0.2817 - val_binary_accuracy: 0.4000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2561 - binary_accuracy: 0.5333 - val_loss: 0.2458 - val_binary_accuracy: 0.5561\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2552 - binary_accuracy: 0.4825 - val_loss: 0.2816 - val_binary_accuracy: 0.4000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2561 - binary_accuracy: 0.5333 - val_loss: 0.2458 - val_binary_accuracy: 0.5561\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2551 - binary_accuracy: 0.4825 - val_loss: 0.2815 - val_binary_accuracy: 0.4000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2561 - binary_accuracy: 0.5333 - val_loss: 0.2458 - val_binary_accuracy: 0.5561\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2551 - binary_accuracy: 0.4825 - val_loss: 0.2814 - val_binary_accuracy: 0.4000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2560 - binary_accuracy: 0.5333 - val_loss: 0.2458 - val_binary_accuracy: 0.5561\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2551 - binary_accuracy: 0.4825 - val_loss: 0.2814 - val_binary_accuracy: 0.4000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2560 - binary_accuracy: 0.5333 - val_loss: 0.2458 - val_binary_accuracy: 0.5561\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2551 - binary_accuracy: 0.4825 - val_loss: 0.2814 - val_binary_accuracy: 0.4000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2560 - binary_accuracy: 0.5333 - val_loss: 0.2458 - val_binary_accuracy: 0.5561\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2551 - binary_accuracy: 0.4825 - val_loss: 0.2814 - val_binary_accuracy: 0.4000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2560 - binary_accuracy: 0.5333 - val_loss: 0.2458 - val_binary_accuracy: 0.5561\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.2551 - binary_accuracy: 0.4825 - val_loss: 0.2814 - val_binary_accuracy: 0.4000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2560 - binary_accuracy: 0.5333 - val_loss: 0.2458 - val_binary_accuracy: 0.5561\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2551 - binary_accuracy: 0.4825 - val_loss: 0.2814 - val_binary_accuracy: 0.4000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2560 - binary_accuracy: 0.5333 - val_loss: 0.2458 - val_binary_accuracy: 0.5561\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2551 - binary_accuracy: 0.4825 - val_loss: 0.2814 - val_binary_accuracy: 0.4000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2560 - binary_accuracy: 0.5333 - val_loss: 0.2458 - val_binary_accuracy: 0.5561\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2551 - binary_accuracy: 0.4825 - val_loss: 0.2814 - val_binary_accuracy: 0.4000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2560 - binary_accuracy: 0.5333 - val_loss: 0.2458 - val_binary_accuracy: 0.5552\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2551 - binary_accuracy: 0.4828 - val_loss: 0.2814 - val_binary_accuracy: 0.4000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2560 - binary_accuracy: 0.5333 - val_loss: 0.2458 - val_binary_accuracy: 0.5552\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2551 - binary_accuracy: 0.4828 - val_loss: 0.2814 - val_binary_accuracy: 0.4000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2560 - binary_accuracy: 0.5333 - val_loss: 0.2458 - val_binary_accuracy: 0.5552\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2551 - binary_accuracy: 0.4828 - val_loss: 0.2815 - val_binary_accuracy: 0.4000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2560 - binary_accuracy: 0.5333 - val_loss: 0.2458 - val_binary_accuracy: 0.5552\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2551 - binary_accuracy: 0.4828 - val_loss: 0.2815 - val_binary_accuracy: 0.4000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2560 - binary_accuracy: 0.5333 - val_loss: 0.2458 - val_binary_accuracy: 0.5552\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2551 - binary_accuracy: 0.4828 - val_loss: 0.2815 - val_binary_accuracy: 0.4000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2560 - binary_accuracy: 0.5333 - val_loss: 0.2458 - val_binary_accuracy: 0.5552\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2551 - binary_accuracy: 0.4828 - val_loss: 0.2815 - val_binary_accuracy: 0.4000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2560 - binary_accuracy: 0.5333 - val_loss: 0.2458 - val_binary_accuracy: 0.5552\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2551 - binary_accuracy: 0.4828 - val_loss: 0.2815 - val_binary_accuracy: 0.4000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2560 - binary_accuracy: 0.5333 - val_loss: 0.2459 - val_binary_accuracy: 0.5552\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2551 - binary_accuracy: 0.4828 - val_loss: 0.2815 - val_binary_accuracy: 0.4000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2560 - binary_accuracy: 0.5333 - val_loss: 0.2459 - val_binary_accuracy: 0.5552\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2551 - binary_accuracy: 0.4828 - val_loss: 0.2815 - val_binary_accuracy: 0.4000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2560 - binary_accuracy: 0.5333 - val_loss: 0.2459 - val_binary_accuracy: 0.5552\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2551 - binary_accuracy: 0.4828 - val_loss: 0.2815 - val_binary_accuracy: 0.4000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2560 - binary_accuracy: 0.5333 - val_loss: 0.2459 - val_binary_accuracy: 0.5552\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2551 - binary_accuracy: 0.4828 - val_loss: 0.2815 - val_binary_accuracy: 0.4000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2560 - binary_accuracy: 0.5333 - val_loss: 0.2459 - val_binary_accuracy: 0.5552\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2551 - binary_accuracy: 0.4828 - val_loss: 0.2815 - val_binary_accuracy: 0.4000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2560 - binary_accuracy: 0.5333 - val_loss: 0.2459 - val_binary_accuracy: 0.5552\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2551 - binary_accuracy: 0.4828 - val_loss: 0.2815 - val_binary_accuracy: 0.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2560 - binary_accuracy: 0.5333 - val_loss: 0.2459 - val_binary_accuracy: 0.5552\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2551 - binary_accuracy: 0.4828 - val_loss: 0.2815 - val_binary_accuracy: 0.4000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2560 - binary_accuracy: 0.5333 - val_loss: 0.2459 - val_binary_accuracy: 0.5552\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2551 - binary_accuracy: 0.4828 - val_loss: 0.2815 - val_binary_accuracy: 0.4000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2560 - binary_accuracy: 0.5333 - val_loss: 0.2459 - val_binary_accuracy: 0.5552\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2551 - binary_accuracy: 0.4828 - val_loss: 0.2815 - val_binary_accuracy: 0.4000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2560 - binary_accuracy: 0.5333 - val_loss: 0.2459 - val_binary_accuracy: 0.5552\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2551 - binary_accuracy: 0.4828 - val_loss: 0.2815 - val_binary_accuracy: 0.4000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2560 - binary_accuracy: 0.5333 - val_loss: 0.2459 - val_binary_accuracy: 0.5552\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2551 - binary_accuracy: 0.4828 - val_loss: 0.2815 - val_binary_accuracy: 0.4000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2560 - binary_accuracy: 0.5333 - val_loss: 0.2459 - val_binary_accuracy: 0.5552\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2551 - binary_accuracy: 0.4828 - val_loss: 0.2815 - val_binary_accuracy: 0.4000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2560 - binary_accuracy: 0.5333 - val_loss: 0.2459 - val_binary_accuracy: 0.5552\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2551 - binary_accuracy: 0.4828 - val_loss: 0.2815 - val_binary_accuracy: 0.4000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2815 - binary_accuracy: 0.4000\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 50, 50, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 50, 50, 1).\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5078 - binary_accuracy: 0.4667WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 50, 50, 1).\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5078 - binary_accuracy: 0.4667 - val_loss: 0.3910 - val_binary_accuracy: 0.5998\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5071 - binary_accuracy: 0.4670 - val_loss: 0.3907 - val_binary_accuracy: 0.5998\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5065 - binary_accuracy: 0.4670 - val_loss: 0.3903 - val_binary_accuracy: 0.5998\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5059 - binary_accuracy: 0.4670 - val_loss: 0.3900 - val_binary_accuracy: 0.5998\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5053 - binary_accuracy: 0.4670 - val_loss: 0.3897 - val_binary_accuracy: 0.5998\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5048 - binary_accuracy: 0.4670 - val_loss: 0.3893 - val_binary_accuracy: 0.5998\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5042 - binary_accuracy: 0.4670 - val_loss: 0.3890 - val_binary_accuracy: 0.5998\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5036 - binary_accuracy: 0.4670 - val_loss: 0.3885 - val_binary_accuracy: 0.5998\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5029 - binary_accuracy: 0.4670 - val_loss: 0.3881 - val_binary_accuracy: 0.5998\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5021 - binary_accuracy: 0.4670 - val_loss: 0.3876 - val_binary_accuracy: 0.5998\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5013 - binary_accuracy: 0.4670 - val_loss: 0.3870 - val_binary_accuracy: 0.5998\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5004 - binary_accuracy: 0.4670 - val_loss: 0.3863 - val_binary_accuracy: 0.5998\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4994 - binary_accuracy: 0.4670 - val_loss: 0.3855 - val_binary_accuracy: 0.5998\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4982 - binary_accuracy: 0.4670 - val_loss: 0.3845 - val_binary_accuracy: 0.5998\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4968 - binary_accuracy: 0.4670 - val_loss: 0.3833 - val_binary_accuracy: 0.5998\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4951 - binary_accuracy: 0.4670 - val_loss: 0.3817 - val_binary_accuracy: 0.5998\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4930 - binary_accuracy: 0.4670 - val_loss: 0.3796 - val_binary_accuracy: 0.5961\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4903 - binary_accuracy: 0.4709 - val_loss: 0.3767 - val_binary_accuracy: 0.5961\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4867 - binary_accuracy: 0.4709 - val_loss: 0.3724 - val_binary_accuracy: 0.5961\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4815 - binary_accuracy: 0.4709 - val_loss: 0.3655 - val_binary_accuracy: 0.5953\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4731 - binary_accuracy: 0.4713 - val_loss: 0.3531 - val_binary_accuracy: 0.5946\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4580 - binary_accuracy: 0.4717 - val_loss: 0.3256 - val_binary_accuracy: 0.5924\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4221 - binary_accuracy: 0.4722 - val_loss: 0.2563 - val_binary_accuracy: 0.5844\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3065 - binary_accuracy: 0.4748 - val_loss: 0.3525 - val_binary_accuracy: 0.4000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2986 - binary_accuracy: 0.5333 - val_loss: 0.2458 - val_binary_accuracy: 0.5536\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2561 - binary_accuracy: 0.4833 - val_loss: 0.3005 - val_binary_accuracy: 0.4000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2657 - binary_accuracy: 0.5333 - val_loss: 0.2445 - val_binary_accuracy: 0.5706\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2656 - binary_accuracy: 0.4787 - val_loss: 0.3030 - val_binary_accuracy: 0.4000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2671 - binary_accuracy: 0.5333 - val_loss: 0.2450 - val_binary_accuracy: 0.5607\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2587 - binary_accuracy: 0.4813 - val_loss: 0.2894 - val_binary_accuracy: 0.4000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2597 - binary_accuracy: 0.5333 - val_loss: 0.2455 - val_binary_accuracy: 0.5552\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2568 - binary_accuracy: 0.4828 - val_loss: 0.2856 - val_binary_accuracy: 0.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2577 - binary_accuracy: 0.5333 - val_loss: 0.2458 - val_binary_accuracy: 0.5536\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2561 - binary_accuracy: 0.4833 - val_loss: 0.2844 - val_binary_accuracy: 0.4000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2571 - binary_accuracy: 0.5333 - val_loss: 0.2459 - val_binary_accuracy: 0.5525\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2560 - binary_accuracy: 0.4835 - val_loss: 0.2845 - val_binary_accuracy: 0.4000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2572 - binary_accuracy: 0.5333 - val_loss: 0.2458 - val_binary_accuracy: 0.5536\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2561 - binary_accuracy: 0.4833 - val_loss: 0.2850 - val_binary_accuracy: 0.4000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2574 - binary_accuracy: 0.5333 - val_loss: 0.2457 - val_binary_accuracy: 0.5536\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2563 - binary_accuracy: 0.4833 - val_loss: 0.2853 - val_binary_accuracy: 0.4000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2576 - binary_accuracy: 0.5333 - val_loss: 0.2457 - val_binary_accuracy: 0.5544\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2563 - binary_accuracy: 0.4830 - val_loss: 0.2854 - val_binary_accuracy: 0.4000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2576 - binary_accuracy: 0.5333 - val_loss: 0.2457 - val_binary_accuracy: 0.5544\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2563 - binary_accuracy: 0.4830 - val_loss: 0.2853 - val_binary_accuracy: 0.4000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2576 - binary_accuracy: 0.5333 - val_loss: 0.2457 - val_binary_accuracy: 0.5544\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2563 - binary_accuracy: 0.4830 - val_loss: 0.2852 - val_binary_accuracy: 0.4000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2576 - binary_accuracy: 0.5333 - val_loss: 0.2457 - val_binary_accuracy: 0.5536\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2563 - binary_accuracy: 0.4833 - val_loss: 0.2852 - val_binary_accuracy: 0.4000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2575 - binary_accuracy: 0.5333 - val_loss: 0.2457 - val_binary_accuracy: 0.5536\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2563 - binary_accuracy: 0.4833 - val_loss: 0.2852 - val_binary_accuracy: 0.4000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2575 - binary_accuracy: 0.5333 - val_loss: 0.2457 - val_binary_accuracy: 0.5536\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2563 - binary_accuracy: 0.4833 - val_loss: 0.2852 - val_binary_accuracy: 0.4000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2575 - binary_accuracy: 0.5333 - val_loss: 0.2457 - val_binary_accuracy: 0.5536\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2563 - binary_accuracy: 0.4833 - val_loss: 0.2852 - val_binary_accuracy: 0.4000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2575 - binary_accuracy: 0.5333 - val_loss: 0.2457 - val_binary_accuracy: 0.5536\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2563 - binary_accuracy: 0.4833 - val_loss: 0.2852 - val_binary_accuracy: 0.4000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2575 - binary_accuracy: 0.5333 - val_loss: 0.2457 - val_binary_accuracy: 0.5536\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2563 - binary_accuracy: 0.4833 - val_loss: 0.2852 - val_binary_accuracy: 0.4000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2575 - binary_accuracy: 0.5333 - val_loss: 0.2457 - val_binary_accuracy: 0.5536\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2563 - binary_accuracy: 0.4833 - val_loss: 0.2852 - val_binary_accuracy: 0.4000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2575 - binary_accuracy: 0.5333 - val_loss: 0.2457 - val_binary_accuracy: 0.5536\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2563 - binary_accuracy: 0.4833 - val_loss: 0.2852 - val_binary_accuracy: 0.4000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2575 - binary_accuracy: 0.5333 - val_loss: 0.2457 - val_binary_accuracy: 0.5536\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2563 - binary_accuracy: 0.4833 - val_loss: 0.2852 - val_binary_accuracy: 0.4000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2575 - binary_accuracy: 0.5333 - val_loss: 0.2457 - val_binary_accuracy: 0.5536\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2563 - binary_accuracy: 0.4833 - val_loss: 0.2852 - val_binary_accuracy: 0.4000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2575 - binary_accuracy: 0.5333 - val_loss: 0.2457 - val_binary_accuracy: 0.5536\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2563 - binary_accuracy: 0.4833 - val_loss: 0.2852 - val_binary_accuracy: 0.4000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2575 - binary_accuracy: 0.5333 - val_loss: 0.2457 - val_binary_accuracy: 0.5536\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2563 - binary_accuracy: 0.4833 - val_loss: 0.2852 - val_binary_accuracy: 0.4000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2575 - binary_accuracy: 0.5333 - val_loss: 0.2457 - val_binary_accuracy: 0.5536\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2563 - binary_accuracy: 0.4833 - val_loss: 0.2852 - val_binary_accuracy: 0.4000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2575 - binary_accuracy: 0.5333 - val_loss: 0.2457 - val_binary_accuracy: 0.5536\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2563 - binary_accuracy: 0.4833 - val_loss: 0.2852 - val_binary_accuracy: 0.4000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2575 - binary_accuracy: 0.5333 - val_loss: 0.2457 - val_binary_accuracy: 0.5536\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2563 - binary_accuracy: 0.4833 - val_loss: 0.2852 - val_binary_accuracy: 0.4000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2575 - binary_accuracy: 0.5333 - val_loss: 0.2457 - val_binary_accuracy: 0.5536\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2563 - binary_accuracy: 0.4833 - val_loss: 0.2852 - val_binary_accuracy: 0.4000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2575 - binary_accuracy: 0.5333 - val_loss: 0.2457 - val_binary_accuracy: 0.5536\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2563 - binary_accuracy: 0.4833 - val_loss: 0.2852 - val_binary_accuracy: 0.4000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2575 - binary_accuracy: 0.5333 - val_loss: 0.2457 - val_binary_accuracy: 0.5544\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2563 - binary_accuracy: 0.4830 - val_loss: 0.2852 - val_binary_accuracy: 0.4000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2575 - binary_accuracy: 0.5333 - val_loss: 0.2457 - val_binary_accuracy: 0.5544\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2563 - binary_accuracy: 0.4830 - val_loss: 0.2852 - val_binary_accuracy: 0.4000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2575 - binary_accuracy: 0.5333 - val_loss: 0.2457 - val_binary_accuracy: 0.5544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2563 - binary_accuracy: 0.4830 - val_loss: 0.2852 - val_binary_accuracy: 0.4000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2575 - binary_accuracy: 0.5333 - val_loss: 0.2457 - val_binary_accuracy: 0.5544\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2563 - binary_accuracy: 0.4830 - val_loss: 0.2852 - val_binary_accuracy: 0.4000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2575 - binary_accuracy: 0.5333 - val_loss: 0.2457 - val_binary_accuracy: 0.5544\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.2563 - binary_accuracy: 0.4830 - val_loss: 0.2852 - val_binary_accuracy: 0.4000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2575 - binary_accuracy: 0.5333 - val_loss: 0.2457 - val_binary_accuracy: 0.5544\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2563 - binary_accuracy: 0.4830 - val_loss: 0.2852 - val_binary_accuracy: 0.4000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2575 - binary_accuracy: 0.5333 - val_loss: 0.2457 - val_binary_accuracy: 0.5544\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2563 - binary_accuracy: 0.4830 - val_loss: 0.2852 - val_binary_accuracy: 0.4000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2575 - binary_accuracy: 0.5333 - val_loss: 0.2457 - val_binary_accuracy: 0.5544\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2563 - binary_accuracy: 0.4830 - val_loss: 0.2852 - val_binary_accuracy: 0.4000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2575 - binary_accuracy: 0.5333 - val_loss: 0.2457 - val_binary_accuracy: 0.5544\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2563 - binary_accuracy: 0.4830 - val_loss: 0.2852 - val_binary_accuracy: 0.4000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2575 - binary_accuracy: 0.5333 - val_loss: 0.2457 - val_binary_accuracy: 0.5544\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2563 - binary_accuracy: 0.4830 - val_loss: 0.2852 - val_binary_accuracy: 0.4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2852 - binary_accuracy: 0.4000\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_58_input'), name='dense_58_input', description=\"created by layer 'dense_58_input'\"), but it was called on an input with incompatible shape (None, 50, 50, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_58_input'), name='dense_58_input', description=\"created by layer 'dense_58_input'\"), but it was called on an input with incompatible shape (None, 50, 50, 1).\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4458 - binary_accuracy: 0.5330WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_58_input'), name='dense_58_input', description=\"created by layer 'dense_58_input'\"), but it was called on an input with incompatible shape (None, 50, 50, 1).\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4458 - binary_accuracy: 0.5330 - val_loss: 0.5827 - val_binary_accuracy: 0.4002\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4452 - binary_accuracy: 0.5330 - val_loss: 0.5820 - val_binary_accuracy: 0.4002\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4447 - binary_accuracy: 0.5330 - val_loss: 0.5813 - val_binary_accuracy: 0.4002\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4443 - binary_accuracy: 0.5330 - val_loss: 0.5807 - val_binary_accuracy: 0.4002\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4439 - binary_accuracy: 0.5330 - val_loss: 0.5801 - val_binary_accuracy: 0.4002\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4434 - binary_accuracy: 0.5330 - val_loss: 0.5794 - val_binary_accuracy: 0.4002\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4429 - binary_accuracy: 0.5330 - val_loss: 0.5787 - val_binary_accuracy: 0.4002\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4425 - binary_accuracy: 0.5330 - val_loss: 0.5779 - val_binary_accuracy: 0.4002\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4419 - binary_accuracy: 0.5330 - val_loss: 0.5770 - val_binary_accuracy: 0.4002\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4414 - binary_accuracy: 0.5330 - val_loss: 0.5761 - val_binary_accuracy: 0.4002\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4408 - binary_accuracy: 0.5330 - val_loss: 0.5751 - val_binary_accuracy: 0.4002\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4401 - binary_accuracy: 0.5330 - val_loss: 0.5739 - val_binary_accuracy: 0.4002\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4393 - binary_accuracy: 0.5330 - val_loss: 0.5725 - val_binary_accuracy: 0.4002\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4384 - binary_accuracy: 0.5330 - val_loss: 0.5709 - val_binary_accuracy: 0.4002\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4374 - binary_accuracy: 0.5330 - val_loss: 0.5689 - val_binary_accuracy: 0.4002\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4362 - binary_accuracy: 0.5330 - val_loss: 0.5665 - val_binary_accuracy: 0.4002\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4348 - binary_accuracy: 0.5330 - val_loss: 0.5635 - val_binary_accuracy: 0.4039\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4330 - binary_accuracy: 0.5291 - val_loss: 0.5596 - val_binary_accuracy: 0.4039\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4308 - binary_accuracy: 0.5291 - val_loss: 0.5544 - val_binary_accuracy: 0.4039\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4277 - binary_accuracy: 0.5291 - val_loss: 0.5468 - val_binary_accuracy: 0.4039\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4235 - binary_accuracy: 0.5291 - val_loss: 0.5354 - val_binary_accuracy: 0.4047\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4170 - binary_accuracy: 0.5287 - val_loss: 0.5160 - val_binary_accuracy: 0.4054\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4060 - binary_accuracy: 0.5283 - val_loss: 0.4774 - val_binary_accuracy: 0.4067\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3832 - binary_accuracy: 0.5280 - val_loss: 0.3814 - val_binary_accuracy: 0.4123\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3220 - binary_accuracy: 0.5264 - val_loss: 0.2417 - val_binary_accuracy: 0.6000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2588 - binary_accuracy: 0.4667 - val_loss: 0.3293 - val_binary_accuracy: 0.4156\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2877 - binary_accuracy: 0.5252 - val_loss: 0.2412 - val_binary_accuracy: 0.6000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2621 - binary_accuracy: 0.4667 - val_loss: 0.3001 - val_binary_accuracy: 0.4187\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2696 - binary_accuracy: 0.5238 - val_loss: 0.2416 - val_binary_accuracy: 0.6000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2593 - binary_accuracy: 0.4667 - val_loss: 0.2847 - val_binary_accuracy: 0.4221\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2610 - binary_accuracy: 0.5228 - val_loss: 0.2423 - val_binary_accuracy: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2569 - binary_accuracy: 0.4667 - val_loss: 0.2780 - val_binary_accuracy: 0.4265\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2577 - binary_accuracy: 0.5219 - val_loss: 0.2429 - val_binary_accuracy: 0.6000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2556 - binary_accuracy: 0.4667 - val_loss: 0.2754 - val_binary_accuracy: 0.4276\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2565 - binary_accuracy: 0.5217 - val_loss: 0.2431 - val_binary_accuracy: 0.6000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2552 - binary_accuracy: 0.4667 - val_loss: 0.2750 - val_binary_accuracy: 0.4276\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2563 - binary_accuracy: 0.5217 - val_loss: 0.2430 - val_binary_accuracy: 0.6000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2553 - binary_accuracy: 0.4667 - val_loss: 0.2757 - val_binary_accuracy: 0.4265\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2565 - binary_accuracy: 0.5219 - val_loss: 0.2429 - val_binary_accuracy: 0.6000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2556 - binary_accuracy: 0.4667 - val_loss: 0.2765 - val_binary_accuracy: 0.4254\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2569 - binary_accuracy: 0.5221 - val_loss: 0.2428 - val_binary_accuracy: 0.6000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2557 - binary_accuracy: 0.4667 - val_loss: 0.2768 - val_binary_accuracy: 0.4254\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2570 - binary_accuracy: 0.5221 - val_loss: 0.2428 - val_binary_accuracy: 0.6000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2557 - binary_accuracy: 0.4667 - val_loss: 0.2767 - val_binary_accuracy: 0.4254\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2569 - binary_accuracy: 0.5221 - val_loss: 0.2429 - val_binary_accuracy: 0.6000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2557 - binary_accuracy: 0.4667 - val_loss: 0.2766 - val_binary_accuracy: 0.4244\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2568 - binary_accuracy: 0.5224 - val_loss: 0.2429 - val_binary_accuracy: 0.6000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2556 - binary_accuracy: 0.4667 - val_loss: 0.2765 - val_binary_accuracy: 0.4244\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2568 - binary_accuracy: 0.5224 - val_loss: 0.2430 - val_binary_accuracy: 0.6000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2556 - binary_accuracy: 0.4667 - val_loss: 0.2765 - val_binary_accuracy: 0.4244\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2567 - binary_accuracy: 0.5224 - val_loss: 0.2430 - val_binary_accuracy: 0.6000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2556 - binary_accuracy: 0.4667 - val_loss: 0.2766 - val_binary_accuracy: 0.4232\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2568 - binary_accuracy: 0.5226 - val_loss: 0.2430 - val_binary_accuracy: 0.6000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2556 - binary_accuracy: 0.4667 - val_loss: 0.2766 - val_binary_accuracy: 0.4232\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2568 - binary_accuracy: 0.5226 - val_loss: 0.2430 - val_binary_accuracy: 0.6000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2556 - binary_accuracy: 0.4667 - val_loss: 0.2767 - val_binary_accuracy: 0.4232\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2567 - binary_accuracy: 0.5226 - val_loss: 0.2430 - val_binary_accuracy: 0.6000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2555 - binary_accuracy: 0.4667 - val_loss: 0.2767 - val_binary_accuracy: 0.4221\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2567 - binary_accuracy: 0.5228 - val_loss: 0.2430 - val_binary_accuracy: 0.6000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2555 - binary_accuracy: 0.4667 - val_loss: 0.2767 - val_binary_accuracy: 0.4221\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2567 - binary_accuracy: 0.5228 - val_loss: 0.2430 - val_binary_accuracy: 0.6000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2555 - binary_accuracy: 0.4667 - val_loss: 0.2767 - val_binary_accuracy: 0.4221\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2567 - binary_accuracy: 0.5228 - val_loss: 0.2431 - val_binary_accuracy: 0.6000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2555 - binary_accuracy: 0.4667 - val_loss: 0.2767 - val_binary_accuracy: 0.4210\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2567 - binary_accuracy: 0.5230 - val_loss: 0.2431 - val_binary_accuracy: 0.6000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2555 - binary_accuracy: 0.4667 - val_loss: 0.2767 - val_binary_accuracy: 0.4210\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2567 - binary_accuracy: 0.5230 - val_loss: 0.2431 - val_binary_accuracy: 0.6000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2555 - binary_accuracy: 0.4667 - val_loss: 0.2768 - val_binary_accuracy: 0.4210\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2567 - binary_accuracy: 0.5230 - val_loss: 0.2431 - val_binary_accuracy: 0.6000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2555 - binary_accuracy: 0.4667 - val_loss: 0.2768 - val_binary_accuracy: 0.4203\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2566 - binary_accuracy: 0.5232 - val_loss: 0.2431 - val_binary_accuracy: 0.6000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2555 - binary_accuracy: 0.4667 - val_loss: 0.2768 - val_binary_accuracy: 0.4203\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2566 - binary_accuracy: 0.5232 - val_loss: 0.2431 - val_binary_accuracy: 0.6000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2555 - binary_accuracy: 0.4667 - val_loss: 0.2768 - val_binary_accuracy: 0.4203\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2566 - binary_accuracy: 0.5232 - val_loss: 0.2432 - val_binary_accuracy: 0.6000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2554 - binary_accuracy: 0.4667 - val_loss: 0.2769 - val_binary_accuracy: 0.4198\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2566 - binary_accuracy: 0.5234 - val_loss: 0.2432 - val_binary_accuracy: 0.6000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2554 - binary_accuracy: 0.4667 - val_loss: 0.2769 - val_binary_accuracy: 0.4198\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2566 - binary_accuracy: 0.5234 - val_loss: 0.2432 - val_binary_accuracy: 0.6000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2554 - binary_accuracy: 0.4667 - val_loss: 0.2769 - val_binary_accuracy: 0.4198\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2566 - binary_accuracy: 0.5234 - val_loss: 0.2432 - val_binary_accuracy: 0.6000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2554 - binary_accuracy: 0.4667 - val_loss: 0.2769 - val_binary_accuracy: 0.4193\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2566 - binary_accuracy: 0.5236 - val_loss: 0.2432 - val_binary_accuracy: 0.6000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2554 - binary_accuracy: 0.4667 - val_loss: 0.2769 - val_binary_accuracy: 0.4193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2565 - binary_accuracy: 0.5236 - val_loss: 0.2432 - val_binary_accuracy: 0.6000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2554 - binary_accuracy: 0.4667 - val_loss: 0.2770 - val_binary_accuracy: 0.4193\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2565 - binary_accuracy: 0.5236 - val_loss: 0.2433 - val_binary_accuracy: 0.6000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2554 - binary_accuracy: 0.4667 - val_loss: 0.2770 - val_binary_accuracy: 0.4187\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2565 - binary_accuracy: 0.5238 - val_loss: 0.2433 - val_binary_accuracy: 0.6000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2554 - binary_accuracy: 0.4667 - val_loss: 0.2770 - val_binary_accuracy: 0.4187\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2565 - binary_accuracy: 0.5238 - val_loss: 0.2433 - val_binary_accuracy: 0.6000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2554 - binary_accuracy: 0.4667 - val_loss: 0.2770 - val_binary_accuracy: 0.4187\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2565 - binary_accuracy: 0.5238 - val_loss: 0.2433 - val_binary_accuracy: 0.6000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2554 - binary_accuracy: 0.4667 - val_loss: 0.2770 - val_binary_accuracy: 0.4182\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2565 - binary_accuracy: 0.5241 - val_loss: 0.2433 - val_binary_accuracy: 0.6000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2553 - binary_accuracy: 0.4667 - val_loss: 0.2771 - val_binary_accuracy: 0.4182\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2565 - binary_accuracy: 0.5241 - val_loss: 0.2433 - val_binary_accuracy: 0.6000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2553 - binary_accuracy: 0.4667 - val_loss: 0.2771 - val_binary_accuracy: 0.4182\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2565 - binary_accuracy: 0.5241 - val_loss: 0.2433 - val_binary_accuracy: 0.6000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2553 - binary_accuracy: 0.4667 - val_loss: 0.2771 - val_binary_accuracy: 0.4177\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2771 - binary_accuracy: 0.4177\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_60_input'), name='dense_60_input', description=\"created by layer 'dense_60_input'\"), but it was called on an input with incompatible shape (None, 50, 50, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_60_input'), name='dense_60_input', description=\"created by layer 'dense_60_input'\"), but it was called on an input with incompatible shape (None, 50, 50, 1).\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5017 - binary_accuracy: 0.4667WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_60_input'), name='dense_60_input', description=\"created by layer 'dense_60_input'\"), but it was called on an input with incompatible shape (None, 50, 50, 1).\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5017 - binary_accuracy: 0.4667 - val_loss: 0.3849 - val_binary_accuracy: 0.5998\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4976 - binary_accuracy: 0.4670 - val_loss: 0.3804 - val_binary_accuracy: 0.5998\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4917 - binary_accuracy: 0.4670 - val_loss: 0.3709 - val_binary_accuracy: 0.5998\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4800 - binary_accuracy: 0.4670 - val_loss: 0.3399 - val_binary_accuracy: 0.5953\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4417 - binary_accuracy: 0.4713 - val_loss: 0.2805 - val_binary_accuracy: 0.4000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2560 - binary_accuracy: 0.5333 - val_loss: 0.3343 - val_binary_accuracy: 0.5953\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4344 - binary_accuracy: 0.4713 - val_loss: 0.2685 - val_binary_accuracy: 0.5900\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3329 - binary_accuracy: 0.4727 - val_loss: 0.4492 - val_binary_accuracy: 0.4000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3637 - binary_accuracy: 0.5333 - val_loss: 0.3230 - val_binary_accuracy: 0.4000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2801 - binary_accuracy: 0.5333 - val_loss: 0.2839 - val_binary_accuracy: 0.5911\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3603 - binary_accuracy: 0.4725 - val_loss: 0.3052 - val_binary_accuracy: 0.4000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2691 - binary_accuracy: 0.5333 - val_loss: 0.2658 - val_binary_accuracy: 0.5891\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.3278 - binary_accuracy: 0.4730 - val_loss: 0.3491 - val_binary_accuracy: 0.4000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2970 - binary_accuracy: 0.5333 - val_loss: 0.2474 - val_binary_accuracy: 0.5849\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2842 - binary_accuracy: 0.4747 - val_loss: 0.3688 - val_binary_accuracy: 0.4000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3102 - binary_accuracy: 0.5333 - val_loss: 0.2450 - val_binary_accuracy: 0.5667\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2562 - binary_accuracy: 0.4796 - val_loss: 0.3217 - val_binary_accuracy: 0.4000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2792 - binary_accuracy: 0.5333 - val_loss: 0.2490 - val_binary_accuracy: 0.5858\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2892 - binary_accuracy: 0.4742 - val_loss: 0.3528 - val_binary_accuracy: 0.4000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2995 - binary_accuracy: 0.5333 - val_loss: 0.2438 - val_binary_accuracy: 0.5779\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2617 - binary_accuracy: 0.4772 - val_loss: 0.3299 - val_binary_accuracy: 0.4000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2844 - binary_accuracy: 0.5333 - val_loss: 0.2452 - val_binary_accuracy: 0.5839\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2758 - binary_accuracy: 0.4751 - val_loss: 0.3430 - val_binary_accuracy: 0.4000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2930 - binary_accuracy: 0.5333 - val_loss: 0.2437 - val_binary_accuracy: 0.5802\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2644 - binary_accuracy: 0.4766 - val_loss: 0.3292 - val_binary_accuracy: 0.4000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2840 - binary_accuracy: 0.5333 - val_loss: 0.2444 - val_binary_accuracy: 0.5829\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2717 - binary_accuracy: 0.4755 - val_loss: 0.3356 - val_binary_accuracy: 0.4000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2881 - binary_accuracy: 0.5333 - val_loss: 0.2438 - val_binary_accuracy: 0.5813\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2665 - binary_accuracy: 0.4762 - val_loss: 0.3287 - val_binary_accuracy: 0.4000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2837 - binary_accuracy: 0.5333 - val_loss: 0.2441 - val_binary_accuracy: 0.5823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2695 - binary_accuracy: 0.4757 - val_loss: 0.3309 - val_binary_accuracy: 0.4000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2851 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5813\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2675 - binary_accuracy: 0.4762 - val_loss: 0.3279 - val_binary_accuracy: 0.4000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2831 - binary_accuracy: 0.5333 - val_loss: 0.2440 - val_binary_accuracy: 0.5818\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2686 - binary_accuracy: 0.4759 - val_loss: 0.3283 - val_binary_accuracy: 0.4000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2834 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2679 - binary_accuracy: 0.4759 - val_loss: 0.3271 - val_binary_accuracy: 0.4000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2826 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2682 - binary_accuracy: 0.4759 - val_loss: 0.3270 - val_binary_accuracy: 0.4000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2826 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2680 - binary_accuracy: 0.4759 - val_loss: 0.3265 - val_binary_accuracy: 0.4000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2822 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2681 - binary_accuracy: 0.4759 - val_loss: 0.3263 - val_binary_accuracy: 0.4000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2821 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.2680 - binary_accuracy: 0.4759 - val_loss: 0.3261 - val_binary_accuracy: 0.4000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2820 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2680 - binary_accuracy: 0.4759 - val_loss: 0.3260 - val_binary_accuracy: 0.4000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2819 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2680 - binary_accuracy: 0.4759 - val_loss: 0.3258 - val_binary_accuracy: 0.4000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2818 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2680 - binary_accuracy: 0.4759 - val_loss: 0.3258 - val_binary_accuracy: 0.4000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2818 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2680 - binary_accuracy: 0.4759 - val_loss: 0.3257 - val_binary_accuracy: 0.4000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2817 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2680 - binary_accuracy: 0.4759 - val_loss: 0.3256 - val_binary_accuracy: 0.4000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2817 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.2680 - binary_accuracy: 0.4759 - val_loss: 0.3256 - val_binary_accuracy: 0.4000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2817 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2680 - binary_accuracy: 0.4759 - val_loss: 0.3256 - val_binary_accuracy: 0.4000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2816 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2679 - binary_accuracy: 0.4759 - val_loss: 0.3255 - val_binary_accuracy: 0.4000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2816 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2679 - binary_accuracy: 0.4759 - val_loss: 0.3255 - val_binary_accuracy: 0.4000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2816 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2679 - binary_accuracy: 0.4759 - val_loss: 0.3255 - val_binary_accuracy: 0.4000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2816 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2679 - binary_accuracy: 0.4759 - val_loss: 0.3255 - val_binary_accuracy: 0.4000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2816 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.2679 - binary_accuracy: 0.4759 - val_loss: 0.3254 - val_binary_accuracy: 0.4000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2816 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2679 - binary_accuracy: 0.4759 - val_loss: 0.3254 - val_binary_accuracy: 0.4000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2816 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2679 - binary_accuracy: 0.4759 - val_loss: 0.3254 - val_binary_accuracy: 0.4000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2815 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2679 - binary_accuracy: 0.4759 - val_loss: 0.3254 - val_binary_accuracy: 0.4000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2815 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2679 - binary_accuracy: 0.4759 - val_loss: 0.3254 - val_binary_accuracy: 0.4000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2815 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2679 - binary_accuracy: 0.4759 - val_loss: 0.3254 - val_binary_accuracy: 0.4000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.2815 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2679 - binary_accuracy: 0.4759 - val_loss: 0.3253 - val_binary_accuracy: 0.4000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2815 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2679 - binary_accuracy: 0.4759 - val_loss: 0.3253 - val_binary_accuracy: 0.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2815 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2679 - binary_accuracy: 0.4759 - val_loss: 0.3253 - val_binary_accuracy: 0.4000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2815 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2679 - binary_accuracy: 0.4759 - val_loss: 0.3253 - val_binary_accuracy: 0.4000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2815 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2679 - binary_accuracy: 0.4759 - val_loss: 0.3253 - val_binary_accuracy: 0.4000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2815 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.2679 - binary_accuracy: 0.4759 - val_loss: 0.3253 - val_binary_accuracy: 0.4000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2815 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2679 - binary_accuracy: 0.4759 - val_loss: 0.3253 - val_binary_accuracy: 0.4000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2815 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2679 - binary_accuracy: 0.4759 - val_loss: 0.3253 - val_binary_accuracy: 0.4000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2815 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2679 - binary_accuracy: 0.4759 - val_loss: 0.3252 - val_binary_accuracy: 0.4000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2814 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2679 - binary_accuracy: 0.4759 - val_loss: 0.3252 - val_binary_accuracy: 0.4000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2814 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5818\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2439 - binary_accuracy: 0.5818\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_62_input'), name='dense_62_input', description=\"created by layer 'dense_62_input'\"), but it was called on an input with incompatible shape (None, 25, 25, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_62_input'), name='dense_62_input', description=\"created by layer 'dense_62_input'\"), but it was called on an input with incompatible shape (None, 25, 25, 1).\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4256 - binary_accuracy: 0.5329WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_62_input'), name='dense_62_input', description=\"created by layer 'dense_62_input'\"), but it was called on an input with incompatible shape (None, 25, 25, 1).\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4256 - binary_accuracy: 0.5329 - val_loss: 0.5472 - val_binary_accuracy: 0.4004\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4230 - binary_accuracy: 0.5329 - val_loss: 0.5430 - val_binary_accuracy: 0.4004\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4206 - binary_accuracy: 0.5329 - val_loss: 0.5386 - val_binary_accuracy: 0.4004\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4180 - binary_accuracy: 0.5329 - val_loss: 0.5338 - val_binary_accuracy: 0.4004\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4153 - binary_accuracy: 0.5329 - val_loss: 0.5285 - val_binary_accuracy: 0.4004\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4123 - binary_accuracy: 0.5329 - val_loss: 0.5224 - val_binary_accuracy: 0.4004\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4088 - binary_accuracy: 0.5329 - val_loss: 0.5153 - val_binary_accuracy: 0.4004\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4047 - binary_accuracy: 0.5329 - val_loss: 0.5069 - val_binary_accuracy: 0.4004\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3998 - binary_accuracy: 0.5329 - val_loss: 0.4967 - val_binary_accuracy: 0.4042\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3937 - binary_accuracy: 0.5288 - val_loss: 0.4840 - val_binary_accuracy: 0.4042\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3861 - binary_accuracy: 0.5288 - val_loss: 0.4678 - val_binary_accuracy: 0.4042\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3763 - binary_accuracy: 0.5288 - val_loss: 0.4467 - val_binary_accuracy: 0.4049\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3631 - binary_accuracy: 0.5284 - val_loss: 0.4188 - val_binary_accuracy: 0.4049\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3452 - binary_accuracy: 0.5284 - val_loss: 0.3824 - val_binary_accuracy: 0.4055\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3212 - binary_accuracy: 0.5280 - val_loss: 0.3382 - val_binary_accuracy: 0.4092\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2920 - binary_accuracy: 0.5272 - val_loss: 0.2947 - val_binary_accuracy: 0.4126\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2651 - binary_accuracy: 0.5262 - val_loss: 0.2662 - val_binary_accuracy: 0.4188\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2518 - binary_accuracy: 0.5238 - val_loss: 0.2563 - val_binary_accuracy: 0.4343\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2496 - binary_accuracy: 0.5199 - val_loss: 0.2545 - val_binary_accuracy: 0.4416\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2495 - binary_accuracy: 0.5179 - val_loss: 0.2543 - val_binary_accuracy: 0.4428\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2495 - binary_accuracy: 0.5177 - val_loss: 0.2543 - val_binary_accuracy: 0.4428\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2495 - binary_accuracy: 0.5177 - val_loss: 0.2543 - val_binary_accuracy: 0.4428\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2495 - binary_accuracy: 0.5177 - val_loss: 0.2543 - val_binary_accuracy: 0.4416\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2495 - binary_accuracy: 0.5179 - val_loss: 0.2543 - val_binary_accuracy: 0.4416\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2495 - binary_accuracy: 0.5179 - val_loss: 0.2543 - val_binary_accuracy: 0.4416\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2495 - binary_accuracy: 0.5179 - val_loss: 0.2543 - val_binary_accuracy: 0.4406\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2495 - binary_accuracy: 0.5182 - val_loss: 0.2543 - val_binary_accuracy: 0.4406\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2495 - binary_accuracy: 0.5182 - val_loss: 0.2544 - val_binary_accuracy: 0.4406\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2495 - binary_accuracy: 0.5182 - val_loss: 0.2544 - val_binary_accuracy: 0.4400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2495 - binary_accuracy: 0.5184 - val_loss: 0.2544 - val_binary_accuracy: 0.4400\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2495 - binary_accuracy: 0.5184 - val_loss: 0.2544 - val_binary_accuracy: 0.4391\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2495 - binary_accuracy: 0.5186 - val_loss: 0.2544 - val_binary_accuracy: 0.4391\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2495 - binary_accuracy: 0.5186 - val_loss: 0.2544 - val_binary_accuracy: 0.4383\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2495 - binary_accuracy: 0.5189 - val_loss: 0.2544 - val_binary_accuracy: 0.4383\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2495 - binary_accuracy: 0.5189 - val_loss: 0.2544 - val_binary_accuracy: 0.4374\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2495 - binary_accuracy: 0.5192 - val_loss: 0.2544 - val_binary_accuracy: 0.4374\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2495 - binary_accuracy: 0.5192 - val_loss: 0.2545 - val_binary_accuracy: 0.4364\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2495 - binary_accuracy: 0.5194 - val_loss: 0.2545 - val_binary_accuracy: 0.4355\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2495 - binary_accuracy: 0.5197 - val_loss: 0.2545 - val_binary_accuracy: 0.4355\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2494 - binary_accuracy: 0.5197 - val_loss: 0.2545 - val_binary_accuracy: 0.4343\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2494 - binary_accuracy: 0.5199 - val_loss: 0.2545 - val_binary_accuracy: 0.4334\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2494 - binary_accuracy: 0.5202 - val_loss: 0.2545 - val_binary_accuracy: 0.4334\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2494 - binary_accuracy: 0.5202 - val_loss: 0.2545 - val_binary_accuracy: 0.4323\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2494 - binary_accuracy: 0.5204 - val_loss: 0.2546 - val_binary_accuracy: 0.4314\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2494 - binary_accuracy: 0.5206 - val_loss: 0.2546 - val_binary_accuracy: 0.4307\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2494 - binary_accuracy: 0.5208 - val_loss: 0.2545 - val_binary_accuracy: 0.4307\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2494 - binary_accuracy: 0.5208 - val_loss: 0.2548 - val_binary_accuracy: 0.4289\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2494 - binary_accuracy: 0.5212 - val_loss: 0.2541 - val_binary_accuracy: 0.4307\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2494 - binary_accuracy: 0.5208 - val_loss: 0.2565 - val_binary_accuracy: 0.4210\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2495 - binary_accuracy: 0.5230 - val_loss: 0.2491 - val_binary_accuracy: 0.6000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2503 - binary_accuracy: 0.4667 - val_loss: 0.2770 - val_binary_accuracy: 0.4111\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2557 - binary_accuracy: 0.5267 - val_loss: 0.2445 - val_binary_accuracy: 0.6000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2541 - binary_accuracy: 0.4667 - val_loss: 0.2661 - val_binary_accuracy: 0.4133\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2514 - binary_accuracy: 0.5261 - val_loss: 0.2501 - val_binary_accuracy: 0.5002\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2500 - binary_accuracy: 0.5021 - val_loss: 0.2585 - val_binary_accuracy: 0.4172\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2496 - binary_accuracy: 0.5244 - val_loss: 0.2524 - val_binary_accuracy: 0.4383\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2495 - binary_accuracy: 0.5189 - val_loss: 0.2569 - val_binary_accuracy: 0.4182\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2494 - binary_accuracy: 0.5240 - val_loss: 0.2530 - val_binary_accuracy: 0.4314\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2494 - binary_accuracy: 0.5206 - val_loss: 0.2566 - val_binary_accuracy: 0.4182\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2494 - binary_accuracy: 0.5240 - val_loss: 0.2529 - val_binary_accuracy: 0.4307\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2494 - binary_accuracy: 0.5208 - val_loss: 0.2572 - val_binary_accuracy: 0.4172\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2495 - binary_accuracy: 0.5244 - val_loss: 0.2521 - val_binary_accuracy: 0.4374\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2495 - binary_accuracy: 0.5192 - val_loss: 0.2591 - val_binary_accuracy: 0.4150\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2497 - binary_accuracy: 0.5254 - val_loss: 0.2499 - val_binary_accuracy: 0.5098\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2500 - binary_accuracy: 0.4988 - val_loss: 0.2636 - val_binary_accuracy: 0.4118\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2506 - binary_accuracy: 0.5265 - val_loss: 0.2475 - val_binary_accuracy: 0.6000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2512 - binary_accuracy: 0.4667 - val_loss: 0.2662 - val_binary_accuracy: 0.4104\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2514 - binary_accuracy: 0.5270 - val_loss: 0.2482 - val_binary_accuracy: 0.6000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2507 - binary_accuracy: 0.4667 - val_loss: 0.2627 - val_binary_accuracy: 0.4111\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2504 - binary_accuracy: 0.5267 - val_loss: 0.2501 - val_binary_accuracy: 0.4977\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2500 - binary_accuracy: 0.5029 - val_loss: 0.2602 - val_binary_accuracy: 0.4118\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2498 - binary_accuracy: 0.5265 - val_loss: 0.2510 - val_binary_accuracy: 0.4447\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2497 - binary_accuracy: 0.5171 - val_loss: 0.2594 - val_binary_accuracy: 0.4118\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2497 - binary_accuracy: 0.5265 - val_loss: 0.2512 - val_binary_accuracy: 0.4391\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2497 - binary_accuracy: 0.5186 - val_loss: 0.2598 - val_binary_accuracy: 0.4111\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2497 - binary_accuracy: 0.5267 - val_loss: 0.2506 - val_binary_accuracy: 0.4534\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2498 - binary_accuracy: 0.5145 - val_loss: 0.2612 - val_binary_accuracy: 0.4092\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2500 - binary_accuracy: 0.5272 - val_loss: 0.2496 - val_binary_accuracy: 0.6000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2501 - binary_accuracy: 0.4667 - val_loss: 0.2629 - val_binary_accuracy: 0.4076\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2504 - binary_accuracy: 0.5275 - val_loss: 0.2490 - val_binary_accuracy: 0.6000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2504 - binary_accuracy: 0.4667 - val_loss: 0.2633 - val_binary_accuracy: 0.4066\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2504 - binary_accuracy: 0.5277 - val_loss: 0.2493 - val_binary_accuracy: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2503 - binary_accuracy: 0.4667 - val_loss: 0.2622 - val_binary_accuracy: 0.4055\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2502 - binary_accuracy: 0.5280 - val_loss: 0.2500 - val_binary_accuracy: 0.5059\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2500 - binary_accuracy: 0.5002 - val_loss: 0.2612 - val_binary_accuracy: 0.4055\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2499 - binary_accuracy: 0.5280 - val_loss: 0.2504 - val_binary_accuracy: 0.4435\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2499 - binary_accuracy: 0.5174 - val_loss: 0.2609 - val_binary_accuracy: 0.4049\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2499 - binary_accuracy: 0.5284 - val_loss: 0.2504 - val_binary_accuracy: 0.4364\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2499 - binary_accuracy: 0.5194 - val_loss: 0.2612 - val_binary_accuracy: 0.4042\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2499 - binary_accuracy: 0.5288 - val_loss: 0.2502 - val_binary_accuracy: 0.4545\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2499 - binary_accuracy: 0.5143 - val_loss: 0.2619 - val_binary_accuracy: 0.4004\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2500 - binary_accuracy: 0.5329 - val_loss: 0.2498 - val_binary_accuracy: 0.6000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2501 - binary_accuracy: 0.4667 - val_loss: 0.2624 - val_binary_accuracy: 0.4000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2502 - binary_accuracy: 0.5333 - val_loss: 0.2497 - val_binary_accuracy: 0.6000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2501 - binary_accuracy: 0.4667 - val_loss: 0.2624 - val_binary_accuracy: 0.4000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2502 - binary_accuracy: 0.5333 - val_loss: 0.2498 - val_binary_accuracy: 0.5996\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.2501 - binary_accuracy: 0.4671 - val_loss: 0.2620 - val_binary_accuracy: 0.4000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2501 - binary_accuracy: 0.5333 - val_loss: 0.2501 - val_binary_accuracy: 0.4000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2500 - binary_accuracy: 0.5333 - val_loss: 0.2617 - val_binary_accuracy: 0.4000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2500 - binary_accuracy: 0.5333 - val_loss: 0.2503 - val_binary_accuracy: 0.4000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2503 - binary_accuracy: 0.4000\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_64_input'), name='dense_64_input', description=\"created by layer 'dense_64_input'\"), but it was called on an input with incompatible shape (None, 25, 25, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_64_input'), name='dense_64_input', description=\"created by layer 'dense_64_input'\"), but it was called on an input with incompatible shape (None, 25, 25, 1).\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4272 - binary_accuracy: 0.5329WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_64_input'), name='dense_64_input', description=\"created by layer 'dense_64_input'\"), but it was called on an input with incompatible shape (None, 25, 25, 1).\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4272 - binary_accuracy: 0.5329 - val_loss: 0.5330 - val_binary_accuracy: 0.4004\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4148 - binary_accuracy: 0.5329 - val_loss: 0.4809 - val_binary_accuracy: 0.4004\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3842 - binary_accuracy: 0.5329 - val_loss: 0.2908 - val_binary_accuracy: 0.4104\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2627 - binary_accuracy: 0.5270 - val_loss: 0.3011 - val_binary_accuracy: 0.6000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3883 - binary_accuracy: 0.4667 - val_loss: 0.2490 - val_binary_accuracy: 0.6000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2503 - binary_accuracy: 0.4667 - val_loss: 0.2945 - val_binary_accuracy: 0.4092\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2647 - binary_accuracy: 0.5272 - val_loss: 0.2628 - val_binary_accuracy: 0.6000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3237 - binary_accuracy: 0.4667 - val_loss: 0.3236 - val_binary_accuracy: 0.4055\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2821 - binary_accuracy: 0.5280 - val_loss: 0.2432 - val_binary_accuracy: 0.6000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2727 - binary_accuracy: 0.4667 - val_loss: 0.3248 - val_binary_accuracy: 0.4055\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2829 - binary_accuracy: 0.5280 - val_loss: 0.2424 - val_binary_accuracy: 0.6000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2605 - binary_accuracy: 0.4667 - val_loss: 0.3014 - val_binary_accuracy: 0.4076\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2686 - binary_accuracy: 0.5275 - val_loss: 0.2422 - val_binary_accuracy: 0.6000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2638 - binary_accuracy: 0.4667 - val_loss: 0.3024 - val_binary_accuracy: 0.4066\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2691 - binary_accuracy: 0.5277 - val_loss: 0.2423 - val_binary_accuracy: 0.6000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2614 - binary_accuracy: 0.4667 - val_loss: 0.2966 - val_binary_accuracy: 0.4076\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2657 - binary_accuracy: 0.5275 - val_loss: 0.2424 - val_binary_accuracy: 0.6000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2608 - binary_accuracy: 0.4667 - val_loss: 0.2947 - val_binary_accuracy: 0.4076\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2647 - binary_accuracy: 0.5275 - val_loss: 0.2425 - val_binary_accuracy: 0.6000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2604 - binary_accuracy: 0.4667 - val_loss: 0.2937 - val_binary_accuracy: 0.4076\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2641 - binary_accuracy: 0.5275 - val_loss: 0.2425 - val_binary_accuracy: 0.6000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2602 - binary_accuracy: 0.4667 - val_loss: 0.2932 - val_binary_accuracy: 0.4066\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2638 - binary_accuracy: 0.5277 - val_loss: 0.2425 - val_binary_accuracy: 0.6000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2602 - binary_accuracy: 0.4667 - val_loss: 0.2930 - val_binary_accuracy: 0.4066\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2637 - binary_accuracy: 0.5277 - val_loss: 0.2425 - val_binary_accuracy: 0.6000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2930 - val_binary_accuracy: 0.4066\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2637 - binary_accuracy: 0.5277 - val_loss: 0.2425 - val_binary_accuracy: 0.6000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2930 - val_binary_accuracy: 0.4066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2636 - binary_accuracy: 0.5277 - val_loss: 0.2426 - val_binary_accuracy: 0.6000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2930 - val_binary_accuracy: 0.4066\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2636 - binary_accuracy: 0.5277 - val_loss: 0.2426 - val_binary_accuracy: 0.6000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2930 - val_binary_accuracy: 0.4066\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2636 - binary_accuracy: 0.5277 - val_loss: 0.2426 - val_binary_accuracy: 0.6000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2930 - val_binary_accuracy: 0.4055\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2636 - binary_accuracy: 0.5280 - val_loss: 0.2426 - val_binary_accuracy: 0.6000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2930 - val_binary_accuracy: 0.4055\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2636 - binary_accuracy: 0.5280 - val_loss: 0.2426 - val_binary_accuracy: 0.6000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2930 - val_binary_accuracy: 0.4055\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2636 - binary_accuracy: 0.5280 - val_loss: 0.2426 - val_binary_accuracy: 0.6000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2930 - val_binary_accuracy: 0.4055\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2636 - binary_accuracy: 0.5280 - val_loss: 0.2426 - val_binary_accuracy: 0.6000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2930 - val_binary_accuracy: 0.4055\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2636 - binary_accuracy: 0.5280 - val_loss: 0.2426 - val_binary_accuracy: 0.6000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2931 - val_binary_accuracy: 0.4055\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2636 - binary_accuracy: 0.5280 - val_loss: 0.2426 - val_binary_accuracy: 0.6000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2931 - val_binary_accuracy: 0.4049\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2636 - binary_accuracy: 0.5284 - val_loss: 0.2426 - val_binary_accuracy: 0.6000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2931 - val_binary_accuracy: 0.4049\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2636 - binary_accuracy: 0.5284 - val_loss: 0.2427 - val_binary_accuracy: 0.6000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2931 - val_binary_accuracy: 0.4049\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2636 - binary_accuracy: 0.5284 - val_loss: 0.2427 - val_binary_accuracy: 0.6000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2931 - val_binary_accuracy: 0.4049\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2636 - binary_accuracy: 0.5284 - val_loss: 0.2427 - val_binary_accuracy: 0.6000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2931 - val_binary_accuracy: 0.4049\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2636 - binary_accuracy: 0.5284 - val_loss: 0.2427 - val_binary_accuracy: 0.6000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2931 - val_binary_accuracy: 0.4049\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2636 - binary_accuracy: 0.5284 - val_loss: 0.2427 - val_binary_accuracy: 0.6000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2931 - val_binary_accuracy: 0.4042\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2636 - binary_accuracy: 0.5288 - val_loss: 0.2427 - val_binary_accuracy: 0.6000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2932 - val_binary_accuracy: 0.4042\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2635 - binary_accuracy: 0.5288 - val_loss: 0.2427 - val_binary_accuracy: 0.6000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2932 - val_binary_accuracy: 0.4042\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2635 - binary_accuracy: 0.5288 - val_loss: 0.2427 - val_binary_accuracy: 0.6000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2932 - val_binary_accuracy: 0.4042\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2635 - binary_accuracy: 0.5288 - val_loss: 0.2427 - val_binary_accuracy: 0.6000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2932 - val_binary_accuracy: 0.4042\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2635 - binary_accuracy: 0.5288 - val_loss: 0.2427 - val_binary_accuracy: 0.6000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2932 - val_binary_accuracy: 0.4004\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2635 - binary_accuracy: 0.5329 - val_loss: 0.2428 - val_binary_accuracy: 0.6000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2932 - val_binary_accuracy: 0.4004\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2635 - binary_accuracy: 0.5329 - val_loss: 0.2428 - val_binary_accuracy: 0.6000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2932 - val_binary_accuracy: 0.4004\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2635 - binary_accuracy: 0.5329 - val_loss: 0.2428 - val_binary_accuracy: 0.6000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2932 - val_binary_accuracy: 0.4004\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2635 - binary_accuracy: 0.5329 - val_loss: 0.2428 - val_binary_accuracy: 0.6000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2932 - val_binary_accuracy: 0.4004\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2635 - binary_accuracy: 0.5329 - val_loss: 0.2428 - val_binary_accuracy: 0.6000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2933 - val_binary_accuracy: 0.4004\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2635 - binary_accuracy: 0.5329 - val_loss: 0.2428 - val_binary_accuracy: 0.6000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2933 - val_binary_accuracy: 0.4000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2635 - binary_accuracy: 0.5333 - val_loss: 0.2428 - val_binary_accuracy: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2933 - val_binary_accuracy: 0.4000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2635 - binary_accuracy: 0.5333 - val_loss: 0.2428 - val_binary_accuracy: 0.6000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2933 - val_binary_accuracy: 0.4000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2635 - binary_accuracy: 0.5333 - val_loss: 0.2428 - val_binary_accuracy: 0.6000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2933 - val_binary_accuracy: 0.4000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2635 - binary_accuracy: 0.5333 - val_loss: 0.2428 - val_binary_accuracy: 0.6000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2933 - val_binary_accuracy: 0.4000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2635 - binary_accuracy: 0.5333 - val_loss: 0.2428 - val_binary_accuracy: 0.6000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2601 - binary_accuracy: 0.4667 - val_loss: 0.2933 - val_binary_accuracy: 0.4000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2635 - binary_accuracy: 0.5333 - val_loss: 0.2429 - val_binary_accuracy: 0.5996\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2601 - binary_accuracy: 0.4671 - val_loss: 0.2933 - val_binary_accuracy: 0.4000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2635 - binary_accuracy: 0.5333 - val_loss: 0.2429 - val_binary_accuracy: 0.5996\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2601 - binary_accuracy: 0.4671 - val_loss: 0.2933 - val_binary_accuracy: 0.4000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2635 - binary_accuracy: 0.5333 - val_loss: 0.2429 - val_binary_accuracy: 0.5996\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2601 - binary_accuracy: 0.4671 - val_loss: 0.2933 - val_binary_accuracy: 0.4000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2635 - binary_accuracy: 0.5333 - val_loss: 0.2429 - val_binary_accuracy: 0.5996\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2601 - binary_accuracy: 0.4671 - val_loss: 0.2934 - val_binary_accuracy: 0.4000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2635 - binary_accuracy: 0.5333 - val_loss: 0.2429 - val_binary_accuracy: 0.5958\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2601 - binary_accuracy: 0.4712 - val_loss: 0.2934 - val_binary_accuracy: 0.4000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2934 - binary_accuracy: 0.4000\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_66_input'), name='dense_66_input', description=\"created by layer 'dense_66_input'\"), but it was called on an input with incompatible shape (None, 25, 25, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_66_input'), name='dense_66_input', description=\"created by layer 'dense_66_input'\"), but it was called on an input with incompatible shape (None, 25, 25, 1).\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4375 - binary_accuracy: 0.5329WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_66_input'), name='dense_66_input', description=\"created by layer 'dense_66_input'\"), but it was called on an input with incompatible shape (None, 25, 25, 1).\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4375 - binary_accuracy: 0.5329 - val_loss: 0.5645 - val_binary_accuracy: 0.4004\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4331 - binary_accuracy: 0.5329 - val_loss: 0.5528 - val_binary_accuracy: 0.4004\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4263 - binary_accuracy: 0.5329 - val_loss: 0.5270 - val_binary_accuracy: 0.4004\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4115 - binary_accuracy: 0.5329 - val_loss: 0.4331 - val_binary_accuracy: 0.4055\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3546 - binary_accuracy: 0.5280 - val_loss: 0.2663 - val_binary_accuracy: 0.6000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3309 - binary_accuracy: 0.4667 - val_loss: 0.4185 - val_binary_accuracy: 0.4055\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3451 - binary_accuracy: 0.5280 - val_loss: 0.2761 - val_binary_accuracy: 0.4166\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2557 - binary_accuracy: 0.5247 - val_loss: 0.2539 - val_binary_accuracy: 0.6000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3054 - binary_accuracy: 0.4667 - val_loss: 0.3774 - val_binary_accuracy: 0.4066\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3180 - binary_accuracy: 0.5277 - val_loss: 0.2477 - val_binary_accuracy: 0.6000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2510 - binary_accuracy: 0.4667 - val_loss: 0.2829 - val_binary_accuracy: 0.4144\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2589 - binary_accuracy: 0.5256 - val_loss: 0.2471 - val_binary_accuracy: 0.6000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2882 - binary_accuracy: 0.4667 - val_loss: 0.3565 - val_binary_accuracy: 0.4076\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3041 - binary_accuracy: 0.5275 - val_loss: 0.2436 - val_binary_accuracy: 0.6000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2551 - binary_accuracy: 0.4667 - val_loss: 0.3032 - val_binary_accuracy: 0.4118\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2701 - binary_accuracy: 0.5265 - val_loss: 0.2447 - val_binary_accuracy: 0.6000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2806 - binary_accuracy: 0.4667 - val_loss: 0.3363 - val_binary_accuracy: 0.4092\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2908 - binary_accuracy: 0.5272 - val_loss: 0.2422 - val_binary_accuracy: 0.6000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2600 - binary_accuracy: 0.4667 - val_loss: 0.3094 - val_binary_accuracy: 0.4111\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2737 - binary_accuracy: 0.5267 - val_loss: 0.2425 - val_binary_accuracy: 0.6000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2701 - binary_accuracy: 0.4667 - val_loss: 0.3211 - val_binary_accuracy: 0.4104\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2810 - binary_accuracy: 0.5270 - val_loss: 0.2420 - val_binary_accuracy: 0.6000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2633 - binary_accuracy: 0.4667 - val_loss: 0.3102 - val_binary_accuracy: 0.4111\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2741 - binary_accuracy: 0.5267 - val_loss: 0.2420 - val_binary_accuracy: 0.6000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2660 - binary_accuracy: 0.4667 - val_loss: 0.3123 - val_binary_accuracy: 0.4104\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2754 - binary_accuracy: 0.5270 - val_loss: 0.2420 - val_binary_accuracy: 0.6000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2644 - binary_accuracy: 0.4667 - val_loss: 0.3090 - val_binary_accuracy: 0.4104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2734 - binary_accuracy: 0.5270 - val_loss: 0.2420 - val_binary_accuracy: 0.6000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2647 - binary_accuracy: 0.4667 - val_loss: 0.3087 - val_binary_accuracy: 0.4104\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2732 - binary_accuracy: 0.5270 - val_loss: 0.2420 - val_binary_accuracy: 0.6000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2644 - binary_accuracy: 0.4667 - val_loss: 0.3078 - val_binary_accuracy: 0.4104\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2726 - binary_accuracy: 0.5270 - val_loss: 0.2420 - val_binary_accuracy: 0.6000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2643 - binary_accuracy: 0.4667 - val_loss: 0.3074 - val_binary_accuracy: 0.4104\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2724 - binary_accuracy: 0.5270 - val_loss: 0.2420 - val_binary_accuracy: 0.6000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2642 - binary_accuracy: 0.4667 - val_loss: 0.3071 - val_binary_accuracy: 0.4104\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2722 - binary_accuracy: 0.5270 - val_loss: 0.2420 - val_binary_accuracy: 0.6000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2642 - binary_accuracy: 0.4667 - val_loss: 0.3069 - val_binary_accuracy: 0.4104\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2721 - binary_accuracy: 0.5270 - val_loss: 0.2421 - val_binary_accuracy: 0.6000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2642 - binary_accuracy: 0.4667 - val_loss: 0.3068 - val_binary_accuracy: 0.4104\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2720 - binary_accuracy: 0.5270 - val_loss: 0.2421 - val_binary_accuracy: 0.6000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2641 - binary_accuracy: 0.4667 - val_loss: 0.3068 - val_binary_accuracy: 0.4104\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2720 - binary_accuracy: 0.5270 - val_loss: 0.2421 - val_binary_accuracy: 0.6000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2641 - binary_accuracy: 0.4667 - val_loss: 0.3067 - val_binary_accuracy: 0.4092\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2719 - binary_accuracy: 0.5272 - val_loss: 0.2421 - val_binary_accuracy: 0.6000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2641 - binary_accuracy: 0.4667 - val_loss: 0.3067 - val_binary_accuracy: 0.4092\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2719 - binary_accuracy: 0.5272 - val_loss: 0.2421 - val_binary_accuracy: 0.6000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2641 - binary_accuracy: 0.4667 - val_loss: 0.3067 - val_binary_accuracy: 0.4092\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2719 - binary_accuracy: 0.5272 - val_loss: 0.2421 - val_binary_accuracy: 0.6000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2641 - binary_accuracy: 0.4667 - val_loss: 0.3067 - val_binary_accuracy: 0.4092\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2719 - binary_accuracy: 0.5272 - val_loss: 0.2421 - val_binary_accuracy: 0.6000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2641 - binary_accuracy: 0.4667 - val_loss: 0.3067 - val_binary_accuracy: 0.4092\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2719 - binary_accuracy: 0.5272 - val_loss: 0.2421 - val_binary_accuracy: 0.6000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2641 - binary_accuracy: 0.4667 - val_loss: 0.3067 - val_binary_accuracy: 0.4092\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2718 - binary_accuracy: 0.5272 - val_loss: 0.2421 - val_binary_accuracy: 0.6000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2641 - binary_accuracy: 0.4667 - val_loss: 0.3067 - val_binary_accuracy: 0.4092\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2718 - binary_accuracy: 0.5272 - val_loss: 0.2421 - val_binary_accuracy: 0.6000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2641 - binary_accuracy: 0.4667 - val_loss: 0.3067 - val_binary_accuracy: 0.4076\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2718 - binary_accuracy: 0.5275 - val_loss: 0.2422 - val_binary_accuracy: 0.6000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2641 - binary_accuracy: 0.4667 - val_loss: 0.3067 - val_binary_accuracy: 0.4076\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2718 - binary_accuracy: 0.5275 - val_loss: 0.2422 - val_binary_accuracy: 0.6000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2641 - binary_accuracy: 0.4667 - val_loss: 0.3067 - val_binary_accuracy: 0.4076\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2718 - binary_accuracy: 0.5275 - val_loss: 0.2422 - val_binary_accuracy: 0.6000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2641 - binary_accuracy: 0.4667 - val_loss: 0.3067 - val_binary_accuracy: 0.4076\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2718 - binary_accuracy: 0.5275 - val_loss: 0.2422 - val_binary_accuracy: 0.6000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2641 - binary_accuracy: 0.4667 - val_loss: 0.3068 - val_binary_accuracy: 0.4076\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2718 - binary_accuracy: 0.5275 - val_loss: 0.2422 - val_binary_accuracy: 0.6000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2641 - binary_accuracy: 0.4667 - val_loss: 0.3068 - val_binary_accuracy: 0.4076\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2718 - binary_accuracy: 0.5275 - val_loss: 0.2422 - val_binary_accuracy: 0.6000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2641 - binary_accuracy: 0.4667 - val_loss: 0.3068 - val_binary_accuracy: 0.4076\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2718 - binary_accuracy: 0.5275 - val_loss: 0.2422 - val_binary_accuracy: 0.6000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2641 - binary_accuracy: 0.4667 - val_loss: 0.3068 - val_binary_accuracy: 0.4066\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2718 - binary_accuracy: 0.5277 - val_loss: 0.2422 - val_binary_accuracy: 0.6000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2641 - binary_accuracy: 0.4667 - val_loss: 0.3068 - val_binary_accuracy: 0.4066\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2717 - binary_accuracy: 0.5277 - val_loss: 0.2422 - val_binary_accuracy: 0.6000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2641 - binary_accuracy: 0.4667 - val_loss: 0.3068 - val_binary_accuracy: 0.4066\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2717 - binary_accuracy: 0.5277 - val_loss: 0.2422 - val_binary_accuracy: 0.6000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2641 - binary_accuracy: 0.4667 - val_loss: 0.3068 - val_binary_accuracy: 0.4066\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2717 - binary_accuracy: 0.5277 - val_loss: 0.2422 - val_binary_accuracy: 0.6000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2641 - binary_accuracy: 0.4667 - val_loss: 0.3068 - val_binary_accuracy: 0.4066\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2717 - binary_accuracy: 0.5277 - val_loss: 0.2423 - val_binary_accuracy: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2641 - binary_accuracy: 0.4667 - val_loss: 0.3068 - val_binary_accuracy: 0.4066\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2717 - binary_accuracy: 0.5277 - val_loss: 0.2423 - val_binary_accuracy: 0.6000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2641 - binary_accuracy: 0.4667 - val_loss: 0.3068 - val_binary_accuracy: 0.4066\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2717 - binary_accuracy: 0.5277 - val_loss: 0.2423 - val_binary_accuracy: 0.6000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2641 - binary_accuracy: 0.4667 - val_loss: 0.3068 - val_binary_accuracy: 0.4066\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2717 - binary_accuracy: 0.5277 - val_loss: 0.2423 - val_binary_accuracy: 0.6000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2641 - binary_accuracy: 0.4667 - val_loss: 0.3068 - val_binary_accuracy: 0.4055\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2717 - binary_accuracy: 0.5280 - val_loss: 0.2423 - val_binary_accuracy: 0.6000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2641 - binary_accuracy: 0.4667 - val_loss: 0.3069 - val_binary_accuracy: 0.4055\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2717 - binary_accuracy: 0.5280 - val_loss: 0.2423 - val_binary_accuracy: 0.6000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2641 - binary_accuracy: 0.4667 - val_loss: 0.3069 - val_binary_accuracy: 0.4055\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2717 - binary_accuracy: 0.5280 - val_loss: 0.2423 - val_binary_accuracy: 0.6000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2641 - binary_accuracy: 0.4667 - val_loss: 0.3069 - val_binary_accuracy: 0.4055\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2717 - binary_accuracy: 0.5280 - val_loss: 0.2423 - val_binary_accuracy: 0.6000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2641 - binary_accuracy: 0.4667 - val_loss: 0.3069 - val_binary_accuracy: 0.4055\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2717 - binary_accuracy: 0.5280 - val_loss: 0.2423 - val_binary_accuracy: 0.6000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2641 - binary_accuracy: 0.4667 - val_loss: 0.3069 - val_binary_accuracy: 0.4055\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2717 - binary_accuracy: 0.5280 - val_loss: 0.2423 - val_binary_accuracy: 0.6000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2641 - binary_accuracy: 0.4667 - val_loss: 0.3069 - val_binary_accuracy: 0.4055\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2716 - binary_accuracy: 0.5280 - val_loss: 0.2424 - val_binary_accuracy: 0.6000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2424 - binary_accuracy: 0.6000\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_68_input'), name='dense_68_input', description=\"created by layer 'dense_68_input'\"), but it was called on an input with incompatible shape (None, 25, 25, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_68_input'), name='dense_68_input', description=\"created by layer 'dense_68_input'\"), but it was called on an input with incompatible shape (None, 25, 25, 1).\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4894 - binary_accuracy: 0.4667WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_68_input'), name='dense_68_input', description=\"created by layer 'dense_68_input'\"), but it was called on an input with incompatible shape (None, 25, 25, 1).\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4894 - binary_accuracy: 0.4667 - val_loss: 0.3651 - val_binary_accuracy: 0.5996\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4724 - binary_accuracy: 0.4671 - val_loss: 0.3129 - val_binary_accuracy: 0.5958\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4047 - binary_accuracy: 0.4712 - val_loss: 0.3912 - val_binary_accuracy: 0.4000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3258 - binary_accuracy: 0.5333 - val_loss: 0.2877 - val_binary_accuracy: 0.5951\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3666 - binary_accuracy: 0.4716 - val_loss: 0.3508 - val_binary_accuracy: 0.4000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2987 - binary_accuracy: 0.5333 - val_loss: 0.2697 - val_binary_accuracy: 0.5934\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3355 - binary_accuracy: 0.4723 - val_loss: 0.3547 - val_binary_accuracy: 0.4000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3013 - binary_accuracy: 0.5333 - val_loss: 0.2477 - val_binary_accuracy: 0.5889\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2864 - binary_accuracy: 0.4733 - val_loss: 0.3757 - val_binary_accuracy: 0.4000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3153 - binary_accuracy: 0.5333 - val_loss: 0.2466 - val_binary_accuracy: 0.5657\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2525 - binary_accuracy: 0.4800 - val_loss: 0.3029 - val_binary_accuracy: 0.4000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.2682 - binary_accuracy: 0.5333 - val_loss: 0.2511 - val_binary_accuracy: 0.5908\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2960 - binary_accuracy: 0.4728 - val_loss: 0.3535 - val_binary_accuracy: 0.4000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3005 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5834\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2611 - binary_accuracy: 0.4753 - val_loss: 0.3289 - val_binary_accuracy: 0.4000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2843 - binary_accuracy: 0.5333 - val_loss: 0.2447 - val_binary_accuracy: 0.5874\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2757 - binary_accuracy: 0.4738 - val_loss: 0.3421 - val_binary_accuracy: 0.4000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2929 - binary_accuracy: 0.5333 - val_loss: 0.2432 - val_binary_accuracy: 0.5844\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2632 - binary_accuracy: 0.4749 - val_loss: 0.3253 - val_binary_accuracy: 0.4000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2820 - binary_accuracy: 0.5333 - val_loss: 0.2439 - val_binary_accuracy: 0.5867\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2716 - binary_accuracy: 0.4739 - val_loss: 0.3328 - val_binary_accuracy: 0.4000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2868 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5850\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2655 - binary_accuracy: 0.4746 - val_loss: 0.3243 - val_binary_accuracy: 0.4000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2813 - binary_accuracy: 0.5333 - val_loss: 0.2435 - val_binary_accuracy: 0.5864\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2689 - binary_accuracy: 0.4742 - val_loss: 0.3268 - val_binary_accuracy: 0.4000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2829 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2667 - binary_accuracy: 0.4744 - val_loss: 0.3232 - val_binary_accuracy: 0.4000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2807 - binary_accuracy: 0.5333 - val_loss: 0.2434 - val_binary_accuracy: 0.5856\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2677 - binary_accuracy: 0.4744 - val_loss: 0.3236 - val_binary_accuracy: 0.4000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2809 - binary_accuracy: 0.5333 - val_loss: 0.2434 - val_binary_accuracy: 0.5856\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2670 - binary_accuracy: 0.4744 - val_loss: 0.3222 - val_binary_accuracy: 0.4000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2800 - binary_accuracy: 0.5333 - val_loss: 0.2434 - val_binary_accuracy: 0.5856\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2673 - binary_accuracy: 0.4744 - val_loss: 0.3221 - val_binary_accuracy: 0.4000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2799 - binary_accuracy: 0.5333 - val_loss: 0.2434 - val_binary_accuracy: 0.5856\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2671 - binary_accuracy: 0.4744 - val_loss: 0.3215 - val_binary_accuracy: 0.4000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2796 - binary_accuracy: 0.5333 - val_loss: 0.2434 - val_binary_accuracy: 0.5856\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2671 - binary_accuracy: 0.4744 - val_loss: 0.3213 - val_binary_accuracy: 0.4000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2794 - binary_accuracy: 0.5333 - val_loss: 0.2434 - val_binary_accuracy: 0.5856\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2671 - binary_accuracy: 0.4744 - val_loss: 0.3211 - val_binary_accuracy: 0.4000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2793 - binary_accuracy: 0.5333 - val_loss: 0.2434 - val_binary_accuracy: 0.5856\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2671 - binary_accuracy: 0.4744 - val_loss: 0.3209 - val_binary_accuracy: 0.4000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2792 - binary_accuracy: 0.5333 - val_loss: 0.2434 - val_binary_accuracy: 0.5856\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2670 - binary_accuracy: 0.4744 - val_loss: 0.3208 - val_binary_accuracy: 0.4000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2791 - binary_accuracy: 0.5333 - val_loss: 0.2434 - val_binary_accuracy: 0.5850\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2670 - binary_accuracy: 0.4746 - val_loss: 0.3207 - val_binary_accuracy: 0.4000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2790 - binary_accuracy: 0.5333 - val_loss: 0.2434 - val_binary_accuracy: 0.5850\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2670 - binary_accuracy: 0.4746 - val_loss: 0.3207 - val_binary_accuracy: 0.4000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2790 - binary_accuracy: 0.5333 - val_loss: 0.2434 - val_binary_accuracy: 0.5850\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2670 - binary_accuracy: 0.4746 - val_loss: 0.3206 - val_binary_accuracy: 0.4000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2790 - binary_accuracy: 0.5333 - val_loss: 0.2434 - val_binary_accuracy: 0.5850\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2670 - binary_accuracy: 0.4746 - val_loss: 0.3206 - val_binary_accuracy: 0.4000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2789 - binary_accuracy: 0.5333 - val_loss: 0.2434 - val_binary_accuracy: 0.5850\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2670 - binary_accuracy: 0.4746 - val_loss: 0.3206 - val_binary_accuracy: 0.4000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2789 - binary_accuracy: 0.5333 - val_loss: 0.2434 - val_binary_accuracy: 0.5850\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2670 - binary_accuracy: 0.4746 - val_loss: 0.3206 - val_binary_accuracy: 0.4000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2789 - binary_accuracy: 0.5333 - val_loss: 0.2434 - val_binary_accuracy: 0.5850\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2670 - binary_accuracy: 0.4746 - val_loss: 0.3205 - val_binary_accuracy: 0.4000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2789 - binary_accuracy: 0.5333 - val_loss: 0.2434 - val_binary_accuracy: 0.5850\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2670 - binary_accuracy: 0.4746 - val_loss: 0.3205 - val_binary_accuracy: 0.4000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2789 - binary_accuracy: 0.5333 - val_loss: 0.2434 - val_binary_accuracy: 0.5850\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2670 - binary_accuracy: 0.4746 - val_loss: 0.3205 - val_binary_accuracy: 0.4000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2789 - binary_accuracy: 0.5333 - val_loss: 0.2434 - val_binary_accuracy: 0.5850\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2670 - binary_accuracy: 0.4746 - val_loss: 0.3205 - val_binary_accuracy: 0.4000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2789 - binary_accuracy: 0.5333 - val_loss: 0.2434 - val_binary_accuracy: 0.5850\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2670 - binary_accuracy: 0.4746 - val_loss: 0.3205 - val_binary_accuracy: 0.4000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2788 - binary_accuracy: 0.5333 - val_loss: 0.2434 - val_binary_accuracy: 0.5850\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2670 - binary_accuracy: 0.4746 - val_loss: 0.3205 - val_binary_accuracy: 0.4000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2788 - binary_accuracy: 0.5333 - val_loss: 0.2434 - val_binary_accuracy: 0.5850\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2670 - binary_accuracy: 0.4746 - val_loss: 0.3205 - val_binary_accuracy: 0.4000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2788 - binary_accuracy: 0.5333 - val_loss: 0.2434 - val_binary_accuracy: 0.5850\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2670 - binary_accuracy: 0.4746 - val_loss: 0.3205 - val_binary_accuracy: 0.4000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2788 - binary_accuracy: 0.5333 - val_loss: 0.2434 - val_binary_accuracy: 0.5850\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2670 - binary_accuracy: 0.4746 - val_loss: 0.3205 - val_binary_accuracy: 0.4000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2788 - binary_accuracy: 0.5333 - val_loss: 0.2434 - val_binary_accuracy: 0.5850\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2670 - binary_accuracy: 0.4746 - val_loss: 0.3204 - val_binary_accuracy: 0.4000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2788 - binary_accuracy: 0.5333 - val_loss: 0.2434 - val_binary_accuracy: 0.5844\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2670 - binary_accuracy: 0.4749 - val_loss: 0.3204 - val_binary_accuracy: 0.4000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2788 - binary_accuracy: 0.5333 - val_loss: 0.2435 - val_binary_accuracy: 0.5844\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2670 - binary_accuracy: 0.4749 - val_loss: 0.3204 - val_binary_accuracy: 0.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2788 - binary_accuracy: 0.5333 - val_loss: 0.2435 - val_binary_accuracy: 0.5844\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2670 - binary_accuracy: 0.4749 - val_loss: 0.3204 - val_binary_accuracy: 0.4000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2788 - binary_accuracy: 0.5333 - val_loss: 0.2435 - val_binary_accuracy: 0.5844\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2670 - binary_accuracy: 0.4749 - val_loss: 0.3204 - val_binary_accuracy: 0.4000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2788 - binary_accuracy: 0.5333 - val_loss: 0.2435 - val_binary_accuracy: 0.5844\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2670 - binary_accuracy: 0.4749 - val_loss: 0.3204 - val_binary_accuracy: 0.4000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2788 - binary_accuracy: 0.5333 - val_loss: 0.2435 - val_binary_accuracy: 0.5844\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2670 - binary_accuracy: 0.4749 - val_loss: 0.3204 - val_binary_accuracy: 0.4000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2788 - binary_accuracy: 0.5333 - val_loss: 0.2435 - val_binary_accuracy: 0.5844\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2670 - binary_accuracy: 0.4749 - val_loss: 0.3204 - val_binary_accuracy: 0.4000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2787 - binary_accuracy: 0.5333 - val_loss: 0.2435 - val_binary_accuracy: 0.5844\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2670 - binary_accuracy: 0.4749 - val_loss: 0.3204 - val_binary_accuracy: 0.4000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2787 - binary_accuracy: 0.5333 - val_loss: 0.2435 - val_binary_accuracy: 0.5844\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2670 - binary_accuracy: 0.4749 - val_loss: 0.3204 - val_binary_accuracy: 0.4000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2787 - binary_accuracy: 0.5333 - val_loss: 0.2435 - val_binary_accuracy: 0.5844\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2670 - binary_accuracy: 0.4749 - val_loss: 0.3204 - val_binary_accuracy: 0.4000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2787 - binary_accuracy: 0.5333 - val_loss: 0.2435 - val_binary_accuracy: 0.5844\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2670 - binary_accuracy: 0.4749 - val_loss: 0.3204 - val_binary_accuracy: 0.4000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2787 - binary_accuracy: 0.5333 - val_loss: 0.2435 - val_binary_accuracy: 0.5844\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2670 - binary_accuracy: 0.4749 - val_loss: 0.3204 - val_binary_accuracy: 0.4000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2787 - binary_accuracy: 0.5333 - val_loss: 0.2435 - val_binary_accuracy: 0.5844\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2435 - binary_accuracy: 0.5844\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_70_input'), name='dense_70_input', description=\"created by layer 'dense_70_input'\"), but it was called on an input with incompatible shape (None, 10, 10, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_70_input'), name='dense_70_input', description=\"created by layer 'dense_70_input'\"), but it was called on an input with incompatible shape (None, 10, 10, 1).\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4494 - binary_accuracy: 0.5328WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_70_input'), name='dense_70_input', description=\"created by layer 'dense_70_input'\"), but it was called on an input with incompatible shape (None, 10, 10, 1).\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4494 - binary_accuracy: 0.5328 - val_loss: 0.5875 - val_binary_accuracy: 0.4004\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4491 - binary_accuracy: 0.5328 - val_loss: 0.5873 - val_binary_accuracy: 0.4004\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4490 - binary_accuracy: 0.5328 - val_loss: 0.5870 - val_binary_accuracy: 0.4004\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4488 - binary_accuracy: 0.5328 - val_loss: 0.5868 - val_binary_accuracy: 0.4004\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4487 - binary_accuracy: 0.5328 - val_loss: 0.5866 - val_binary_accuracy: 0.4004\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4486 - binary_accuracy: 0.5328 - val_loss: 0.5865 - val_binary_accuracy: 0.4004\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4484 - binary_accuracy: 0.5328 - val_loss: 0.5863 - val_binary_accuracy: 0.4004\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4483 - binary_accuracy: 0.5328 - val_loss: 0.5861 - val_binary_accuracy: 0.4004\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4482 - binary_accuracy: 0.5328 - val_loss: 0.5859 - val_binary_accuracy: 0.4004\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4481 - binary_accuracy: 0.5328 - val_loss: 0.5857 - val_binary_accuracy: 0.4004\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4480 - binary_accuracy: 0.5328 - val_loss: 0.5856 - val_binary_accuracy: 0.4004\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4479 - binary_accuracy: 0.5328 - val_loss: 0.5854 - val_binary_accuracy: 0.4004\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4478 - binary_accuracy: 0.5328 - val_loss: 0.5852 - val_binary_accuracy: 0.4004\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4476 - binary_accuracy: 0.5328 - val_loss: 0.5851 - val_binary_accuracy: 0.4004\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4475 - binary_accuracy: 0.5328 - val_loss: 0.5849 - val_binary_accuracy: 0.4004\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4474 - binary_accuracy: 0.5328 - val_loss: 0.5847 - val_binary_accuracy: 0.4004\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4473 - binary_accuracy: 0.5328 - val_loss: 0.5845 - val_binary_accuracy: 0.4004\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4472 - binary_accuracy: 0.5328 - val_loss: 0.5843 - val_binary_accuracy: 0.4004\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4471 - binary_accuracy: 0.5328 - val_loss: 0.5842 - val_binary_accuracy: 0.4004\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4469 - binary_accuracy: 0.5328 - val_loss: 0.5840 - val_binary_accuracy: 0.4004\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4468 - binary_accuracy: 0.5328 - val_loss: 0.5838 - val_binary_accuracy: 0.4004\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4467 - binary_accuracy: 0.5328 - val_loss: 0.5836 - val_binary_accuracy: 0.4004\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4466 - binary_accuracy: 0.5328 - val_loss: 0.5834 - val_binary_accuracy: 0.4004\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4464 - binary_accuracy: 0.5328 - val_loss: 0.5832 - val_binary_accuracy: 0.4004\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4463 - binary_accuracy: 0.5328 - val_loss: 0.5830 - val_binary_accuracy: 0.4004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4461 - binary_accuracy: 0.5328 - val_loss: 0.5828 - val_binary_accuracy: 0.4004\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4460 - binary_accuracy: 0.5328 - val_loss: 0.5826 - val_binary_accuracy: 0.4004\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4458 - binary_accuracy: 0.5328 - val_loss: 0.5823 - val_binary_accuracy: 0.4004\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4457 - binary_accuracy: 0.5328 - val_loss: 0.5821 - val_binary_accuracy: 0.4004\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4455 - binary_accuracy: 0.5328 - val_loss: 0.5819 - val_binary_accuracy: 0.4004\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4454 - binary_accuracy: 0.5328 - val_loss: 0.5816 - val_binary_accuracy: 0.4004\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4452 - binary_accuracy: 0.5328 - val_loss: 0.5814 - val_binary_accuracy: 0.4004\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4450 - binary_accuracy: 0.5328 - val_loss: 0.5811 - val_binary_accuracy: 0.4004\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4448 - binary_accuracy: 0.5328 - val_loss: 0.5809 - val_binary_accuracy: 0.4004\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4446 - binary_accuracy: 0.5328 - val_loss: 0.5806 - val_binary_accuracy: 0.4004\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4444 - binary_accuracy: 0.5328 - val_loss: 0.5803 - val_binary_accuracy: 0.4004\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4442 - binary_accuracy: 0.5328 - val_loss: 0.5800 - val_binary_accuracy: 0.4004\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4440 - binary_accuracy: 0.5328 - val_loss: 0.5797 - val_binary_accuracy: 0.4004\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4438 - binary_accuracy: 0.5328 - val_loss: 0.5794 - val_binary_accuracy: 0.4004\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4435 - binary_accuracy: 0.5328 - val_loss: 0.5791 - val_binary_accuracy: 0.4004\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4433 - binary_accuracy: 0.5328 - val_loss: 0.5787 - val_binary_accuracy: 0.4004\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4430 - binary_accuracy: 0.5328 - val_loss: 0.5783 - val_binary_accuracy: 0.4004\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4427 - binary_accuracy: 0.5328 - val_loss: 0.5779 - val_binary_accuracy: 0.4004\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4424 - binary_accuracy: 0.5328 - val_loss: 0.5775 - val_binary_accuracy: 0.4004\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4421 - binary_accuracy: 0.5328 - val_loss: 0.5770 - val_binary_accuracy: 0.4004\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4417 - binary_accuracy: 0.5328 - val_loss: 0.5765 - val_binary_accuracy: 0.4040\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4413 - binary_accuracy: 0.5291 - val_loss: 0.5760 - val_binary_accuracy: 0.4040\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4409 - binary_accuracy: 0.5291 - val_loss: 0.5754 - val_binary_accuracy: 0.4040\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4405 - binary_accuracy: 0.5291 - val_loss: 0.5748 - val_binary_accuracy: 0.4040\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4400 - binary_accuracy: 0.5291 - val_loss: 0.5740 - val_binary_accuracy: 0.4040\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4395 - binary_accuracy: 0.5291 - val_loss: 0.5732 - val_binary_accuracy: 0.4040\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4389 - binary_accuracy: 0.5291 - val_loss: 0.5723 - val_binary_accuracy: 0.4040\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4383 - binary_accuracy: 0.5291 - val_loss: 0.5713 - val_binary_accuracy: 0.4040\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4375 - binary_accuracy: 0.5291 - val_loss: 0.5701 - val_binary_accuracy: 0.4040\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4367 - binary_accuracy: 0.5291 - val_loss: 0.5687 - val_binary_accuracy: 0.4040\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4358 - binary_accuracy: 0.5291 - val_loss: 0.5671 - val_binary_accuracy: 0.4040\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4348 - binary_accuracy: 0.5291 - val_loss: 0.5651 - val_binary_accuracy: 0.4052\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4335 - binary_accuracy: 0.5287 - val_loss: 0.5628 - val_binary_accuracy: 0.4052\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4321 - binary_accuracy: 0.5287 - val_loss: 0.5599 - val_binary_accuracy: 0.4052\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4304 - binary_accuracy: 0.5287 - val_loss: 0.5562 - val_binary_accuracy: 0.4052\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4283 - binary_accuracy: 0.5287 - val_loss: 0.5516 - val_binary_accuracy: 0.4056\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4256 - binary_accuracy: 0.5284 - val_loss: 0.5455 - val_binary_accuracy: 0.4056\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4221 - binary_accuracy: 0.5284 - val_loss: 0.5376 - val_binary_accuracy: 0.4080\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4177 - binary_accuracy: 0.5280 - val_loss: 0.5268 - val_binary_accuracy: 0.4080\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4115 - binary_accuracy: 0.5280 - val_loss: 0.5104 - val_binary_accuracy: 0.4104\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4019 - binary_accuracy: 0.5274 - val_loss: 0.4833 - val_binary_accuracy: 0.4124\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3856 - binary_accuracy: 0.5269 - val_loss: 0.4310 - val_binary_accuracy: 0.4144\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3530 - binary_accuracy: 0.5258 - val_loss: 0.3239 - val_binary_accuracy: 0.4216\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2847 - binary_accuracy: 0.5221 - val_loss: 0.2404 - val_binary_accuracy: 0.6000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2640 - binary_accuracy: 0.4667 - val_loss: 0.2929 - val_binary_accuracy: 0.4368\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2666 - binary_accuracy: 0.5197 - val_loss: 0.2423 - val_binary_accuracy: 0.6000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2562 - binary_accuracy: 0.4667 - val_loss: 0.2712 - val_binary_accuracy: 0.4480\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2561 - binary_accuracy: 0.5161 - val_loss: 0.2436 - val_binary_accuracy: 0.6000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2545 - binary_accuracy: 0.4667 - val_loss: 0.2673 - val_binary_accuracy: 0.4520\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2546 - binary_accuracy: 0.5151 - val_loss: 0.2441 - val_binary_accuracy: 0.6000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2539 - binary_accuracy: 0.4667 - val_loss: 0.2667 - val_binary_accuracy: 0.4528\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2543 - binary_accuracy: 0.5148 - val_loss: 0.2439 - val_binary_accuracy: 0.6000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2541 - binary_accuracy: 0.4667 - val_loss: 0.2680 - val_binary_accuracy: 0.4504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2548 - binary_accuracy: 0.5156 - val_loss: 0.2434 - val_binary_accuracy: 0.6000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2546 - binary_accuracy: 0.4667 - val_loss: 0.2699 - val_binary_accuracy: 0.4480\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2554 - binary_accuracy: 0.5161 - val_loss: 0.2431 - val_binary_accuracy: 0.6000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2550 - binary_accuracy: 0.4667 - val_loss: 0.2709 - val_binary_accuracy: 0.4476\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2558 - binary_accuracy: 0.5164 - val_loss: 0.2431 - val_binary_accuracy: 0.6000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2550 - binary_accuracy: 0.4667 - val_loss: 0.2706 - val_binary_accuracy: 0.4476\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2556 - binary_accuracy: 0.5164 - val_loss: 0.2433 - val_binary_accuracy: 0.6000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2548 - binary_accuracy: 0.4667 - val_loss: 0.2698 - val_binary_accuracy: 0.4476\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2553 - binary_accuracy: 0.5164 - val_loss: 0.2434 - val_binary_accuracy: 0.6000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2545 - binary_accuracy: 0.4667 - val_loss: 0.2694 - val_binary_accuracy: 0.4480\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2551 - binary_accuracy: 0.5161 - val_loss: 0.2435 - val_binary_accuracy: 0.6000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2545 - binary_accuracy: 0.4667 - val_loss: 0.2694 - val_binary_accuracy: 0.4476\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2551 - binary_accuracy: 0.5164 - val_loss: 0.2435 - val_binary_accuracy: 0.6000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2545 - binary_accuracy: 0.4667 - val_loss: 0.2697 - val_binary_accuracy: 0.4476\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2551 - binary_accuracy: 0.5164 - val_loss: 0.2434 - val_binary_accuracy: 0.6000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2545 - binary_accuracy: 0.4667 - val_loss: 0.2699 - val_binary_accuracy: 0.4456\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2552 - binary_accuracy: 0.5166 - val_loss: 0.2434 - val_binary_accuracy: 0.6000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2545 - binary_accuracy: 0.4667 - val_loss: 0.2700 - val_binary_accuracy: 0.4448\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2552 - binary_accuracy: 0.5169 - val_loss: 0.2434 - val_binary_accuracy: 0.6000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2545 - binary_accuracy: 0.4667 - val_loss: 0.2700 - val_binary_accuracy: 0.4448\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2551 - binary_accuracy: 0.5169 - val_loss: 0.2435 - val_binary_accuracy: 0.6000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2545 - binary_accuracy: 0.4667 - val_loss: 0.2699 - val_binary_accuracy: 0.4448\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2699 - binary_accuracy: 0.4448\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_72_input'), name='dense_72_input', description=\"created by layer 'dense_72_input'\"), but it was called on an input with incompatible shape (None, 10, 10, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_72_input'), name='dense_72_input', description=\"created by layer 'dense_72_input'\"), but it was called on an input with incompatible shape (None, 10, 10, 1).\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4323 - binary_accuracy: 0.4667WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_72_input'), name='dense_72_input', description=\"created by layer 'dense_72_input'\"), but it was called on an input with incompatible shape (None, 10, 10, 1).\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4323 - binary_accuracy: 0.4667 - val_loss: 0.3297 - val_binary_accuracy: 0.5996\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4259 - binary_accuracy: 0.4672 - val_loss: 0.3257 - val_binary_accuracy: 0.5996\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4203 - binary_accuracy: 0.4672 - val_loss: 0.3219 - val_binary_accuracy: 0.5996\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4150 - binary_accuracy: 0.4672 - val_loss: 0.3182 - val_binary_accuracy: 0.5996\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4098 - binary_accuracy: 0.4672 - val_loss: 0.3145 - val_binary_accuracy: 0.5996\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4045 - binary_accuracy: 0.4672 - val_loss: 0.3108 - val_binary_accuracy: 0.5960\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3990 - binary_accuracy: 0.4709 - val_loss: 0.3069 - val_binary_accuracy: 0.5960\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3934 - binary_accuracy: 0.4709 - val_loss: 0.3029 - val_binary_accuracy: 0.5960\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3875 - binary_accuracy: 0.4709 - val_loss: 0.2989 - val_binary_accuracy: 0.5960\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3813 - binary_accuracy: 0.4709 - val_loss: 0.2947 - val_binary_accuracy: 0.5960\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3749 - binary_accuracy: 0.4709 - val_loss: 0.2904 - val_binary_accuracy: 0.5948\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3681 - binary_accuracy: 0.4713 - val_loss: 0.2861 - val_binary_accuracy: 0.5948\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3613 - binary_accuracy: 0.4713 - val_loss: 0.2818 - val_binary_accuracy: 0.5948\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3544 - binary_accuracy: 0.4713 - val_loss: 0.2775 - val_binary_accuracy: 0.5944\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3471 - binary_accuracy: 0.4716 - val_loss: 0.2733 - val_binary_accuracy: 0.5944\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3397 - binary_accuracy: 0.4716 - val_loss: 0.2691 - val_binary_accuracy: 0.5944\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3322 - binary_accuracy: 0.4716 - val_loss: 0.2650 - val_binary_accuracy: 0.5920\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3245 - binary_accuracy: 0.4720 - val_loss: 0.2611 - val_binary_accuracy: 0.5920\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3169 - binary_accuracy: 0.4720 - val_loss: 0.2574 - val_binary_accuracy: 0.5912\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3093 - binary_accuracy: 0.4724 - val_loss: 0.2541 - val_binary_accuracy: 0.5896\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3019 - binary_accuracy: 0.4726 - val_loss: 0.2511 - val_binary_accuracy: 0.5884\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2948 - binary_accuracy: 0.4728 - val_loss: 0.2486 - val_binary_accuracy: 0.5876\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2882 - binary_accuracy: 0.4731 - val_loss: 0.2466 - val_binary_accuracy: 0.5868\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2820 - binary_accuracy: 0.4735 - val_loss: 0.2450 - val_binary_accuracy: 0.5864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2763 - binary_accuracy: 0.4740 - val_loss: 0.2440 - val_binary_accuracy: 0.5856\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2713 - binary_accuracy: 0.4742 - val_loss: 0.2434 - val_binary_accuracy: 0.5852\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2669 - binary_accuracy: 0.4746 - val_loss: 0.2433 - val_binary_accuracy: 0.5844\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2632 - binary_accuracy: 0.4752 - val_loss: 0.2435 - val_binary_accuracy: 0.5828\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2600 - binary_accuracy: 0.4761 - val_loss: 0.2440 - val_binary_accuracy: 0.5812\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2575 - binary_accuracy: 0.4772 - val_loss: 0.2448 - val_binary_accuracy: 0.5752\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2554 - binary_accuracy: 0.4785 - val_loss: 0.2457 - val_binary_accuracy: 0.5656\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2537 - binary_accuracy: 0.4801 - val_loss: 0.2468 - val_binary_accuracy: 0.5584\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2524 - binary_accuracy: 0.4821 - val_loss: 0.2478 - val_binary_accuracy: 0.5480\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2514 - binary_accuracy: 0.4849 - val_loss: 0.2489 - val_binary_accuracy: 0.5280\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2507 - binary_accuracy: 0.4904 - val_loss: 0.2500 - val_binary_accuracy: 0.5052\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2502 - binary_accuracy: 0.4984 - val_loss: 0.2510 - val_binary_accuracy: 0.4528\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2498 - binary_accuracy: 0.5124 - val_loss: 0.2519 - val_binary_accuracy: 0.4000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2495 - binary_accuracy: 0.5333 - val_loss: 0.2527 - val_binary_accuracy: 0.4000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2493 - binary_accuracy: 0.5333 - val_loss: 0.2534 - val_binary_accuracy: 0.4000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2492 - binary_accuracy: 0.5333 - val_loss: 0.2540 - val_binary_accuracy: 0.4000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2491 - binary_accuracy: 0.5333 - val_loss: 0.2545 - val_binary_accuracy: 0.4000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2491 - binary_accuracy: 0.5333 - val_loss: 0.2550 - val_binary_accuracy: 0.4000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2553 - val_binary_accuracy: 0.4000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2556 - val_binary_accuracy: 0.4000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2558 - val_binary_accuracy: 0.4000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2560 - val_binary_accuracy: 0.4000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2561 - val_binary_accuracy: 0.4000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2562 - val_binary_accuracy: 0.4000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2563 - val_binary_accuracy: 0.4000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2563 - val_binary_accuracy: 0.4000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2563 - val_binary_accuracy: 0.4000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2564 - val_binary_accuracy: 0.4000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2564 - val_binary_accuracy: 0.4000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2564 - val_binary_accuracy: 0.4000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2564 - val_binary_accuracy: 0.4000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2564 - val_binary_accuracy: 0.4000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2564 - val_binary_accuracy: 0.4000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2564 - val_binary_accuracy: 0.4000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2564 - val_binary_accuracy: 0.4000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2564 - val_binary_accuracy: 0.4000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2564 - val_binary_accuracy: 0.4000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2564 - val_binary_accuracy: 0.4000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2564 - val_binary_accuracy: 0.4000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2564 - val_binary_accuracy: 0.4000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2564 - val_binary_accuracy: 0.4000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2564 - val_binary_accuracy: 0.4000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2564 - val_binary_accuracy: 0.4000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2565 - val_binary_accuracy: 0.4000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2565 - val_binary_accuracy: 0.4000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2565 - val_binary_accuracy: 0.4000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2565 - val_binary_accuracy: 0.4000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2565 - val_binary_accuracy: 0.4000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2565 - val_binary_accuracy: 0.4000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2565 - val_binary_accuracy: 0.4000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2565 - val_binary_accuracy: 0.4000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2565 - val_binary_accuracy: 0.4000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2565 - val_binary_accuracy: 0.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2565 - val_binary_accuracy: 0.4000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2565 - val_binary_accuracy: 0.4000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2566 - val_binary_accuracy: 0.4000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2566 - val_binary_accuracy: 0.4000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2566 - val_binary_accuracy: 0.4000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2566 - val_binary_accuracy: 0.4000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2566 - val_binary_accuracy: 0.4000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2566 - val_binary_accuracy: 0.4000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2566 - val_binary_accuracy: 0.4000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2566 - val_binary_accuracy: 0.4000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2489 - binary_accuracy: 0.5333 - val_loss: 0.2567 - val_binary_accuracy: 0.4000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2489 - binary_accuracy: 0.5333 - val_loss: 0.2567 - val_binary_accuracy: 0.4000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2489 - binary_accuracy: 0.5333 - val_loss: 0.2567 - val_binary_accuracy: 0.4000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2489 - binary_accuracy: 0.5333 - val_loss: 0.2567 - val_binary_accuracy: 0.4000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2489 - binary_accuracy: 0.5333 - val_loss: 0.2567 - val_binary_accuracy: 0.4000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2489 - binary_accuracy: 0.5333 - val_loss: 0.2567 - val_binary_accuracy: 0.4000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2489 - binary_accuracy: 0.5333 - val_loss: 0.2568 - val_binary_accuracy: 0.4000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2489 - binary_accuracy: 0.5333 - val_loss: 0.2567 - val_binary_accuracy: 0.4000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2489 - binary_accuracy: 0.5333 - val_loss: 0.2569 - val_binary_accuracy: 0.4000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2489 - binary_accuracy: 0.5333 - val_loss: 0.2563 - val_binary_accuracy: 0.4000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2489 - binary_accuracy: 0.5333 - val_loss: 0.2585 - val_binary_accuracy: 0.4000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2524 - val_binary_accuracy: 0.4024\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2494 - binary_accuracy: 0.5291 - val_loss: 0.2629 - val_binary_accuracy: 0.4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2629 - binary_accuracy: 0.4000\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_74_input'), name='dense_74_input', description=\"created by layer 'dense_74_input'\"), but it was called on an input with incompatible shape (None, 10, 10, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_74_input'), name='dense_74_input', description=\"created by layer 'dense_74_input'\"), but it was called on an input with incompatible shape (None, 10, 10, 1).\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5086 - binary_accuracy: 0.4667WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_74_input'), name='dense_74_input', description=\"created by layer 'dense_74_input'\"), but it was called on an input with incompatible shape (None, 10, 10, 1).\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5086 - binary_accuracy: 0.4667 - val_loss: 0.3908 - val_binary_accuracy: 0.5996\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5075 - binary_accuracy: 0.4672 - val_loss: 0.3903 - val_binary_accuracy: 0.5996\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5065 - binary_accuracy: 0.4672 - val_loss: 0.3899 - val_binary_accuracy: 0.5996\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5055 - binary_accuracy: 0.4672 - val_loss: 0.3893 - val_binary_accuracy: 0.5996\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5044 - binary_accuracy: 0.4672 - val_loss: 0.3887 - val_binary_accuracy: 0.5996\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5032 - binary_accuracy: 0.4672 - val_loss: 0.3880 - val_binary_accuracy: 0.5996\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5018 - binary_accuracy: 0.4672 - val_loss: 0.3870 - val_binary_accuracy: 0.5996\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5000 - binary_accuracy: 0.4672 - val_loss: 0.3856 - val_binary_accuracy: 0.5996\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4976 - binary_accuracy: 0.4672 - val_loss: 0.3835 - val_binary_accuracy: 0.5996\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4943 - binary_accuracy: 0.4672 - val_loss: 0.3796 - val_binary_accuracy: 0.5960\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4891 - binary_accuracy: 0.4709 - val_loss: 0.3720 - val_binary_accuracy: 0.5960\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4795 - binary_accuracy: 0.4709 - val_loss: 0.3516 - val_binary_accuracy: 0.5944\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4539 - binary_accuracy: 0.4716 - val_loss: 0.2555 - val_binary_accuracy: 0.5840\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3025 - binary_accuracy: 0.4754 - val_loss: 0.4807 - val_binary_accuracy: 0.4000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3812 - binary_accuracy: 0.5333 - val_loss: 0.4194 - val_binary_accuracy: 0.4000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3412 - binary_accuracy: 0.5333 - val_loss: 0.2463 - val_binary_accuracy: 0.5472\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2551 - binary_accuracy: 0.4852 - val_loss: 0.3827 - val_binary_accuracy: 0.4000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3169 - binary_accuracy: 0.5333 - val_loss: 0.2510 - val_binary_accuracy: 0.5828\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2915 - binary_accuracy: 0.4761 - val_loss: 0.4032 - val_binary_accuracy: 0.4000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3305 - binary_accuracy: 0.5333 - val_loss: 0.2571 - val_binary_accuracy: 0.4000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2489 - binary_accuracy: 0.5333 - val_loss: 0.2601 - val_binary_accuracy: 0.4000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2490 - binary_accuracy: 0.5333 - val_loss: 0.2515 - val_binary_accuracy: 0.4760\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2500 - binary_accuracy: 0.5056 - val_loss: 0.2937 - val_binary_accuracy: 0.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2614 - binary_accuracy: 0.5333 - val_loss: 0.2619 - val_binary_accuracy: 0.5852\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3165 - binary_accuracy: 0.4746 - val_loss: 0.3625 - val_binary_accuracy: 0.4000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3035 - binary_accuracy: 0.5333 - val_loss: 0.2453 - val_binary_accuracy: 0.5752\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2715 - binary_accuracy: 0.4785 - val_loss: 0.3623 - val_binary_accuracy: 0.4000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3033 - binary_accuracy: 0.5333 - val_loss: 0.2446 - val_binary_accuracy: 0.5632\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2627 - binary_accuracy: 0.4803 - val_loss: 0.3401 - val_binary_accuracy: 0.4000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2890 - binary_accuracy: 0.5333 - val_loss: 0.2459 - val_binary_accuracy: 0.5788\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2747 - binary_accuracy: 0.4776 - val_loss: 0.3461 - val_binary_accuracy: 0.4000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2928 - binary_accuracy: 0.5333 - val_loss: 0.2446 - val_binary_accuracy: 0.5680\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2652 - binary_accuracy: 0.4796 - val_loss: 0.3317 - val_binary_accuracy: 0.4000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2836 - binary_accuracy: 0.5333 - val_loss: 0.2451 - val_binary_accuracy: 0.5752\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2709 - binary_accuracy: 0.4785 - val_loss: 0.3338 - val_binary_accuracy: 0.4000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2849 - binary_accuracy: 0.5333 - val_loss: 0.2447 - val_binary_accuracy: 0.5708\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2672 - binary_accuracy: 0.4792 - val_loss: 0.3274 - val_binary_accuracy: 0.4000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2810 - binary_accuracy: 0.5333 - val_loss: 0.2448 - val_binary_accuracy: 0.5716\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2686 - binary_accuracy: 0.4787 - val_loss: 0.3268 - val_binary_accuracy: 0.4000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2806 - binary_accuracy: 0.5333 - val_loss: 0.2447 - val_binary_accuracy: 0.5716\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2677 - binary_accuracy: 0.4787 - val_loss: 0.3244 - val_binary_accuracy: 0.4000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2791 - binary_accuracy: 0.5333 - val_loss: 0.2447 - val_binary_accuracy: 0.5716\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2678 - binary_accuracy: 0.4787 - val_loss: 0.3235 - val_binary_accuracy: 0.4000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2786 - binary_accuracy: 0.5333 - val_loss: 0.2447 - val_binary_accuracy: 0.5716\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2675 - binary_accuracy: 0.4787 - val_loss: 0.3225 - val_binary_accuracy: 0.4000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2780 - binary_accuracy: 0.5333 - val_loss: 0.2447 - val_binary_accuracy: 0.5708\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2675 - binary_accuracy: 0.4792 - val_loss: 0.3220 - val_binary_accuracy: 0.4000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2776 - binary_accuracy: 0.5333 - val_loss: 0.2447 - val_binary_accuracy: 0.5708\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2674 - binary_accuracy: 0.4792 - val_loss: 0.3215 - val_binary_accuracy: 0.4000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2773 - binary_accuracy: 0.5333 - val_loss: 0.2447 - val_binary_accuracy: 0.5708\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2673 - binary_accuracy: 0.4792 - val_loss: 0.3212 - val_binary_accuracy: 0.4000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2772 - binary_accuracy: 0.5333 - val_loss: 0.2447 - val_binary_accuracy: 0.5708\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2673 - binary_accuracy: 0.4792 - val_loss: 0.3210 - val_binary_accuracy: 0.4000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2770 - binary_accuracy: 0.5333 - val_loss: 0.2446 - val_binary_accuracy: 0.5708\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2672 - binary_accuracy: 0.4792 - val_loss: 0.3208 - val_binary_accuracy: 0.4000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2769 - binary_accuracy: 0.5333 - val_loss: 0.2446 - val_binary_accuracy: 0.5708\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2672 - binary_accuracy: 0.4792 - val_loss: 0.3207 - val_binary_accuracy: 0.4000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2769 - binary_accuracy: 0.5333 - val_loss: 0.2446 - val_binary_accuracy: 0.5716\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2672 - binary_accuracy: 0.4787 - val_loss: 0.3207 - val_binary_accuracy: 0.4000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2768 - binary_accuracy: 0.5333 - val_loss: 0.2446 - val_binary_accuracy: 0.5716\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2672 - binary_accuracy: 0.4787 - val_loss: 0.3206 - val_binary_accuracy: 0.4000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2768 - binary_accuracy: 0.5333 - val_loss: 0.2446 - val_binary_accuracy: 0.5716\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2672 - binary_accuracy: 0.4787 - val_loss: 0.3206 - val_binary_accuracy: 0.4000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2768 - binary_accuracy: 0.5333 - val_loss: 0.2446 - val_binary_accuracy: 0.5716\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2672 - binary_accuracy: 0.4787 - val_loss: 0.3205 - val_binary_accuracy: 0.4000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2768 - binary_accuracy: 0.5333 - val_loss: 0.2446 - val_binary_accuracy: 0.5716\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2672 - binary_accuracy: 0.4787 - val_loss: 0.3205 - val_binary_accuracy: 0.4000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2768 - binary_accuracy: 0.5333 - val_loss: 0.2446 - val_binary_accuracy: 0.5716\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2672 - binary_accuracy: 0.4787 - val_loss: 0.3205 - val_binary_accuracy: 0.4000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2767 - binary_accuracy: 0.5333 - val_loss: 0.2446 - val_binary_accuracy: 0.5716\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2672 - binary_accuracy: 0.4787 - val_loss: 0.3205 - val_binary_accuracy: 0.4000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2767 - binary_accuracy: 0.5333 - val_loss: 0.2446 - val_binary_accuracy: 0.5716\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2671 - binary_accuracy: 0.4787 - val_loss: 0.3205 - val_binary_accuracy: 0.4000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2767 - binary_accuracy: 0.5333 - val_loss: 0.2446 - val_binary_accuracy: 0.5716\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2671 - binary_accuracy: 0.4787 - val_loss: 0.3205 - val_binary_accuracy: 0.4000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2767 - binary_accuracy: 0.5333 - val_loss: 0.2446 - val_binary_accuracy: 0.5716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2671 - binary_accuracy: 0.4787 - val_loss: 0.3205 - val_binary_accuracy: 0.4000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2767 - binary_accuracy: 0.5333 - val_loss: 0.2446 - val_binary_accuracy: 0.5716\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2671 - binary_accuracy: 0.4787 - val_loss: 0.3205 - val_binary_accuracy: 0.4000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2767 - binary_accuracy: 0.5333 - val_loss: 0.2446 - val_binary_accuracy: 0.5716\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2671 - binary_accuracy: 0.4787 - val_loss: 0.3204 - val_binary_accuracy: 0.4000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2767 - binary_accuracy: 0.5333 - val_loss: 0.2446 - val_binary_accuracy: 0.5716\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2671 - binary_accuracy: 0.4787 - val_loss: 0.3204 - val_binary_accuracy: 0.4000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2767 - binary_accuracy: 0.5333 - val_loss: 0.2446 - val_binary_accuracy: 0.5716\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2671 - binary_accuracy: 0.4787 - val_loss: 0.3204 - val_binary_accuracy: 0.4000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2767 - binary_accuracy: 0.5333 - val_loss: 0.2446 - val_binary_accuracy: 0.5716\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2671 - binary_accuracy: 0.4787 - val_loss: 0.3204 - val_binary_accuracy: 0.4000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2767 - binary_accuracy: 0.5333 - val_loss: 0.2446 - val_binary_accuracy: 0.5716\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2671 - binary_accuracy: 0.4787 - val_loss: 0.3204 - val_binary_accuracy: 0.4000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2767 - binary_accuracy: 0.5333 - val_loss: 0.2446 - val_binary_accuracy: 0.5716\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2671 - binary_accuracy: 0.4787 - val_loss: 0.3204 - val_binary_accuracy: 0.4000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2767 - binary_accuracy: 0.5333 - val_loss: 0.2446 - val_binary_accuracy: 0.5716\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2671 - binary_accuracy: 0.4787 - val_loss: 0.3204 - val_binary_accuracy: 0.4000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2767 - binary_accuracy: 0.5333 - val_loss: 0.2446 - val_binary_accuracy: 0.5716\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2671 - binary_accuracy: 0.4787 - val_loss: 0.3204 - val_binary_accuracy: 0.4000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2767 - binary_accuracy: 0.5333 - val_loss: 0.2446 - val_binary_accuracy: 0.5716\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2671 - binary_accuracy: 0.4787 - val_loss: 0.3204 - val_binary_accuracy: 0.4000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2767 - binary_accuracy: 0.5333 - val_loss: 0.2446 - val_binary_accuracy: 0.5716\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2671 - binary_accuracy: 0.4787 - val_loss: 0.3204 - val_binary_accuracy: 0.4000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2767 - binary_accuracy: 0.5333 - val_loss: 0.2446 - val_binary_accuracy: 0.5716\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2446 - binary_accuracy: 0.5716\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_76_input'), name='dense_76_input', description=\"created by layer 'dense_76_input'\"), but it was called on an input with incompatible shape (None, 10, 10, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_76_input'), name='dense_76_input', description=\"created by layer 'dense_76_input'\"), but it was called on an input with incompatible shape (None, 10, 10, 1).\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4293 - binary_accuracy: 0.5328WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_76_input'), name='dense_76_input', description=\"created by layer 'dense_76_input'\"), but it was called on an input with incompatible shape (None, 10, 10, 1).\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4293 - binary_accuracy: 0.5328 - val_loss: 0.5374 - val_binary_accuracy: 0.4004\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4168 - binary_accuracy: 0.5328 - val_loss: 0.4771 - val_binary_accuracy: 0.4040\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3802 - binary_accuracy: 0.5291 - val_loss: 0.2450 - val_binary_accuracy: 0.6000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2533 - binary_accuracy: 0.4667 - val_loss: 0.4562 - val_binary_accuracy: 0.4040\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3669 - binary_accuracy: 0.5291 - val_loss: 0.2820 - val_binary_accuracy: 0.4132\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2578 - binary_accuracy: 0.5262 - val_loss: 0.2932 - val_binary_accuracy: 0.6000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3736 - binary_accuracy: 0.4667 - val_loss: 0.2965 - val_binary_accuracy: 0.4116\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2652 - binary_accuracy: 0.5272 - val_loss: 0.2677 - val_binary_accuracy: 0.6000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3311 - binary_accuracy: 0.4667 - val_loss: 0.3356 - val_binary_accuracy: 0.4080\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2885 - binary_accuracy: 0.5280 - val_loss: 0.2450 - val_binary_accuracy: 0.6000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2802 - binary_accuracy: 0.4667 - val_loss: 0.3481 - val_binary_accuracy: 0.4056\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2965 - binary_accuracy: 0.5284 - val_loss: 0.2428 - val_binary_accuracy: 0.6000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2579 - binary_accuracy: 0.4667 - val_loss: 0.3096 - val_binary_accuracy: 0.4088\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2726 - binary_accuracy: 0.5276 - val_loss: 0.2432 - val_binary_accuracy: 0.6000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2730 - binary_accuracy: 0.4667 - val_loss: 0.3268 - val_binary_accuracy: 0.4080\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2830 - binary_accuracy: 0.5280 - val_loss: 0.2422 - val_binary_accuracy: 0.6000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2620 - binary_accuracy: 0.4667 - val_loss: 0.3094 - val_binary_accuracy: 0.4088\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2725 - binary_accuracy: 0.5276 - val_loss: 0.2423 - val_binary_accuracy: 0.6000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2660 - binary_accuracy: 0.4667 - val_loss: 0.3128 - val_binary_accuracy: 0.4080\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2744 - binary_accuracy: 0.5280 - val_loss: 0.2422 - val_binary_accuracy: 0.6000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2636 - binary_accuracy: 0.4667 - val_loss: 0.3077 - val_binary_accuracy: 0.4080\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2714 - binary_accuracy: 0.5280 - val_loss: 0.2422 - val_binary_accuracy: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2639 - binary_accuracy: 0.4667 - val_loss: 0.3070 - val_binary_accuracy: 0.4080\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2710 - binary_accuracy: 0.5280 - val_loss: 0.2422 - val_binary_accuracy: 0.6000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2634 - binary_accuracy: 0.4667 - val_loss: 0.3058 - val_binary_accuracy: 0.4080\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2703 - binary_accuracy: 0.5280 - val_loss: 0.2422 - val_binary_accuracy: 0.6000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2633 - binary_accuracy: 0.4667 - val_loss: 0.3052 - val_binary_accuracy: 0.4080\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2699 - binary_accuracy: 0.5280 - val_loss: 0.2422 - val_binary_accuracy: 0.6000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2632 - binary_accuracy: 0.4667 - val_loss: 0.3048 - val_binary_accuracy: 0.4080\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2697 - binary_accuracy: 0.5280 - val_loss: 0.2422 - val_binary_accuracy: 0.6000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2631 - binary_accuracy: 0.4667 - val_loss: 0.3046 - val_binary_accuracy: 0.4080\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2696 - binary_accuracy: 0.5280 - val_loss: 0.2422 - val_binary_accuracy: 0.6000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2631 - binary_accuracy: 0.4667 - val_loss: 0.3045 - val_binary_accuracy: 0.4080\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2695 - binary_accuracy: 0.5280 - val_loss: 0.2423 - val_binary_accuracy: 0.6000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2631 - binary_accuracy: 0.4667 - val_loss: 0.3044 - val_binary_accuracy: 0.4080\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2694 - binary_accuracy: 0.5280 - val_loss: 0.2423 - val_binary_accuracy: 0.6000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2631 - binary_accuracy: 0.4667 - val_loss: 0.3044 - val_binary_accuracy: 0.4080\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2694 - binary_accuracy: 0.5280 - val_loss: 0.2423 - val_binary_accuracy: 0.6000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2631 - binary_accuracy: 0.4667 - val_loss: 0.3043 - val_binary_accuracy: 0.4056\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2694 - binary_accuracy: 0.5284 - val_loss: 0.2423 - val_binary_accuracy: 0.6000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2631 - binary_accuracy: 0.4667 - val_loss: 0.3043 - val_binary_accuracy: 0.4056\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2694 - binary_accuracy: 0.5284 - val_loss: 0.2423 - val_binary_accuracy: 0.6000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2630 - binary_accuracy: 0.4667 - val_loss: 0.3043 - val_binary_accuracy: 0.4056\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2693 - binary_accuracy: 0.5284 - val_loss: 0.2423 - val_binary_accuracy: 0.6000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2630 - binary_accuracy: 0.4667 - val_loss: 0.3043 - val_binary_accuracy: 0.4056\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2693 - binary_accuracy: 0.5284 - val_loss: 0.2423 - val_binary_accuracy: 0.6000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2630 - binary_accuracy: 0.4667 - val_loss: 0.3043 - val_binary_accuracy: 0.4056\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2693 - binary_accuracy: 0.5284 - val_loss: 0.2423 - val_binary_accuracy: 0.6000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2630 - binary_accuracy: 0.4667 - val_loss: 0.3043 - val_binary_accuracy: 0.4056\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2693 - binary_accuracy: 0.5284 - val_loss: 0.2423 - val_binary_accuracy: 0.6000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2630 - binary_accuracy: 0.4667 - val_loss: 0.3043 - val_binary_accuracy: 0.4056\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2693 - binary_accuracy: 0.5284 - val_loss: 0.2423 - val_binary_accuracy: 0.6000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2630 - binary_accuracy: 0.4667 - val_loss: 0.3043 - val_binary_accuracy: 0.4052\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2693 - binary_accuracy: 0.5287 - val_loss: 0.2423 - val_binary_accuracy: 0.6000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2630 - binary_accuracy: 0.4667 - val_loss: 0.3043 - val_binary_accuracy: 0.4052\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2693 - binary_accuracy: 0.5287 - val_loss: 0.2424 - val_binary_accuracy: 0.6000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2630 - binary_accuracy: 0.4667 - val_loss: 0.3043 - val_binary_accuracy: 0.4052\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2693 - binary_accuracy: 0.5287 - val_loss: 0.2424 - val_binary_accuracy: 0.6000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2630 - binary_accuracy: 0.4667 - val_loss: 0.3043 - val_binary_accuracy: 0.4052\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2692 - binary_accuracy: 0.5287 - val_loss: 0.2424 - val_binary_accuracy: 0.6000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2630 - binary_accuracy: 0.4667 - val_loss: 0.3043 - val_binary_accuracy: 0.4052\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2692 - binary_accuracy: 0.5287 - val_loss: 0.2424 - val_binary_accuracy: 0.6000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2630 - binary_accuracy: 0.4667 - val_loss: 0.3043 - val_binary_accuracy: 0.4052\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2692 - binary_accuracy: 0.5287 - val_loss: 0.2424 - val_binary_accuracy: 0.6000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2630 - binary_accuracy: 0.4667 - val_loss: 0.3043 - val_binary_accuracy: 0.4052\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2692 - binary_accuracy: 0.5287 - val_loss: 0.2424 - val_binary_accuracy: 0.6000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2630 - binary_accuracy: 0.4667 - val_loss: 0.3043 - val_binary_accuracy: 0.4040\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2692 - binary_accuracy: 0.5291 - val_loss: 0.2424 - val_binary_accuracy: 0.6000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2630 - binary_accuracy: 0.4667 - val_loss: 0.3043 - val_binary_accuracy: 0.4040\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2692 - binary_accuracy: 0.5291 - val_loss: 0.2424 - val_binary_accuracy: 0.6000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2630 - binary_accuracy: 0.4667 - val_loss: 0.3043 - val_binary_accuracy: 0.4040\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2692 - binary_accuracy: 0.5291 - val_loss: 0.2424 - val_binary_accuracy: 0.6000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2630 - binary_accuracy: 0.4667 - val_loss: 0.3043 - val_binary_accuracy: 0.4040\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2692 - binary_accuracy: 0.5291 - val_loss: 0.2424 - val_binary_accuracy: 0.6000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2630 - binary_accuracy: 0.4667 - val_loss: 0.3043 - val_binary_accuracy: 0.4040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2692 - binary_accuracy: 0.5291 - val_loss: 0.2424 - val_binary_accuracy: 0.6000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2630 - binary_accuracy: 0.4667 - val_loss: 0.3043 - val_binary_accuracy: 0.4040\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2692 - binary_accuracy: 0.5291 - val_loss: 0.2424 - val_binary_accuracy: 0.6000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2630 - binary_accuracy: 0.4667 - val_loss: 0.3043 - val_binary_accuracy: 0.4040\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2692 - binary_accuracy: 0.5291 - val_loss: 0.2425 - val_binary_accuracy: 0.6000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2630 - binary_accuracy: 0.4667 - val_loss: 0.3043 - val_binary_accuracy: 0.4040\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2691 - binary_accuracy: 0.5291 - val_loss: 0.2425 - val_binary_accuracy: 0.6000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2630 - binary_accuracy: 0.4667 - val_loss: 0.3043 - val_binary_accuracy: 0.4004\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2691 - binary_accuracy: 0.5328 - val_loss: 0.2425 - val_binary_accuracy: 0.6000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2630 - binary_accuracy: 0.4667 - val_loss: 0.3043 - val_binary_accuracy: 0.4004\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2691 - binary_accuracy: 0.5328 - val_loss: 0.2425 - val_binary_accuracy: 0.6000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2630 - binary_accuracy: 0.4667 - val_loss: 0.3043 - val_binary_accuracy: 0.4004\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2691 - binary_accuracy: 0.5328 - val_loss: 0.2425 - val_binary_accuracy: 0.6000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2630 - binary_accuracy: 0.4667 - val_loss: 0.3043 - val_binary_accuracy: 0.4004\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2691 - binary_accuracy: 0.5328 - val_loss: 0.2425 - val_binary_accuracy: 0.6000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2630 - binary_accuracy: 0.4667 - val_loss: 0.3043 - val_binary_accuracy: 0.4004\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2691 - binary_accuracy: 0.5328 - val_loss: 0.2425 - val_binary_accuracy: 0.6000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2630 - binary_accuracy: 0.4667 - val_loss: 0.3043 - val_binary_accuracy: 0.4004\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2691 - binary_accuracy: 0.5328 - val_loss: 0.2425 - val_binary_accuracy: 0.6000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2630 - binary_accuracy: 0.4667 - val_loss: 0.3043 - val_binary_accuracy: 0.4004\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2691 - binary_accuracy: 0.5328 - val_loss: 0.2425 - val_binary_accuracy: 0.6000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2630 - binary_accuracy: 0.4667 - val_loss: 0.3043 - val_binary_accuracy: 0.4000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2691 - binary_accuracy: 0.5333 - val_loss: 0.2425 - val_binary_accuracy: 0.6000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2630 - binary_accuracy: 0.4667 - val_loss: 0.3043 - val_binary_accuracy: 0.4000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2691 - binary_accuracy: 0.5333 - val_loss: 0.2425 - val_binary_accuracy: 0.6000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2425 - binary_accuracy: 0.6000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Img size</th>\n",
       "      <th>Nodes Number</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Training time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.400001</td>\n",
       "      <td>0.273762</td>\n",
       "      <td>406.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.400001</td>\n",
       "      <td>0.293493</td>\n",
       "      <td>453.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.400001</td>\n",
       "      <td>0.286558</td>\n",
       "      <td>582.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.400001</td>\n",
       "      <td>0.325915</td>\n",
       "      <td>840.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.400001</td>\n",
       "      <td>0.272291</td>\n",
       "      <td>22.078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.449868</td>\n",
       "      <td>0.270145</td>\n",
       "      <td>24.140625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.599999</td>\n",
       "      <td>0.241136</td>\n",
       "      <td>29.578125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.400001</td>\n",
       "      <td>0.330732</td>\n",
       "      <td>37.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.400001</td>\n",
       "      <td>0.281493</td>\n",
       "      <td>10.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.400001</td>\n",
       "      <td>0.285206</td>\n",
       "      <td>11.078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.417697</td>\n",
       "      <td>0.277106</td>\n",
       "      <td>12.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.581839</td>\n",
       "      <td>0.243910</td>\n",
       "      <td>14.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.400001</td>\n",
       "      <td>0.250269</td>\n",
       "      <td>7.359375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.400001</td>\n",
       "      <td>0.293368</td>\n",
       "      <td>7.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.599999</td>\n",
       "      <td>0.242351</td>\n",
       "      <td>7.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.584447</td>\n",
       "      <td>0.243485</td>\n",
       "      <td>9.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.444800</td>\n",
       "      <td>0.269913</td>\n",
       "      <td>6.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.262937</td>\n",
       "      <td>6.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.571600</td>\n",
       "      <td>0.244559</td>\n",
       "      <td>6.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.242541</td>\n",
       "      <td>6.859375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Img size  Nodes Number  Accuracy      Loss  Training time\n",
       "1     500.0           8.0  0.400001  0.273762     406.796875\n",
       "1     500.0          16.0  0.400001  0.293493     453.187500\n",
       "1     500.0          32.0  0.400001  0.286558     582.625000\n",
       "1     500.0          64.0  0.400001  0.325915     840.093750\n",
       "1     100.0           8.0  0.400001  0.272291      22.078125\n",
       "1     100.0          16.0  0.449868  0.270145      24.140625\n",
       "1     100.0          32.0  0.599999  0.241136      29.578125\n",
       "1     100.0          64.0  0.400001  0.330732      37.843750\n",
       "1      50.0           8.0  0.400001  0.281493      10.656250\n",
       "1      50.0          16.0  0.400001  0.285206      11.078125\n",
       "1      50.0          32.0  0.417697  0.277106      12.656250\n",
       "1      50.0          64.0  0.581839  0.243910      14.390625\n",
       "1      25.0           8.0  0.400001  0.250269       7.359375\n",
       "1      25.0          16.0  0.400001  0.293368       7.500000\n",
       "1      25.0          32.0  0.599999  0.242351       7.687500\n",
       "1      25.0          64.0  0.584447  0.243485       9.046875\n",
       "1      10.0           8.0  0.444800  0.269913       6.593750\n",
       "1      10.0          16.0  0.400000  0.262937       6.859375\n",
       "1      10.0          32.0  0.571600  0.244559       6.687500\n",
       "1      10.0          64.0  0.600000  0.242541       6.859375"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38913d77",
   "metadata": {},
   "source": [
    "#### b. Multi layer neural network Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9d02df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_78_input'), name='dense_78_input', description=\"created by layer 'dense_78_input'\"), but it was called on an input with incompatible shape (None, 500, 500, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_78_input'), name='dense_78_input', description=\"created by layer 'dense_78_input'\"), but it was called on an input with incompatible shape (None, 500, 500, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_78_input'), name='dense_78_input', description=\"created by layer 'dense_78_input'\"), but it was called on an input with incompatible shape (None, 500, 500, 1).\n",
      "2/2 - 5s - loss: 0.4471 - binary_accuracy: 0.5329 - val_loss: 0.5834 - val_binary_accuracy: 0.4003 - 5s/epoch - 3s/step\n",
      "Epoch 2/100\n",
      "2/2 - 4s - loss: 0.4413 - binary_accuracy: 0.5336 - val_loss: 0.5818 - val_binary_accuracy: 0.4003 - 4s/epoch - 2s/step\n",
      "Epoch 3/100\n",
      "2/2 - 3s - loss: 0.4383 - binary_accuracy: 0.5333 - val_loss: 0.5799 - val_binary_accuracy: 0.4003 - 3s/epoch - 2s/step\n",
      "Epoch 4/100\n",
      "2/2 - 3s - loss: 0.4441 - binary_accuracy: 0.5329 - val_loss: 0.5771 - val_binary_accuracy: 0.4003 - 3s/epoch - 2s/step\n",
      "Epoch 5/100\n",
      "2/2 - 3s - loss: 0.4446 - binary_accuracy: 0.5327 - val_loss: 0.5727 - val_binary_accuracy: 0.4003 - 3s/epoch - 2s/step\n",
      "Epoch 6/100\n",
      "2/2 - 3s - loss: 0.4355 - binary_accuracy: 0.5333 - val_loss: 0.5645 - val_binary_accuracy: 0.4003 - 3s/epoch - 2s/step\n",
      "Epoch 7/100\n",
      "2/2 - 3s - loss: 0.4187 - binary_accuracy: 0.5342 - val_loss: 0.5501 - val_binary_accuracy: 0.4003 - 3s/epoch - 2s/step\n",
      "Epoch 8/100\n",
      "2/2 - 3s - loss: 0.4265 - binary_accuracy: 0.5155 - val_loss: 0.5198 - val_binary_accuracy: 0.4040 - 3s/epoch - 2s/step\n",
      "Epoch 9/100\n",
      "2/2 - 3s - loss: 0.3977 - binary_accuracy: 0.5335 - val_loss: 0.4081 - val_binary_accuracy: 0.4066 - 3s/epoch - 2s/step\n",
      "Epoch 10/100\n",
      "2/2 - 3s - loss: 0.2887 - binary_accuracy: 0.5248 - val_loss: 0.2694 - val_binary_accuracy: 0.6000 - 3s/epoch - 2s/step\n",
      "Epoch 11/100\n",
      "2/2 - 3s - loss: 0.3429 - binary_accuracy: 0.4667 - val_loss: 0.2810 - val_binary_accuracy: 0.6000 - 3s/epoch - 2s/step\n",
      "Epoch 12/100\n",
      "2/2 - 3s - loss: 0.3538 - binary_accuracy: 0.4667 - val_loss: 0.2424 - val_binary_accuracy: 0.6000 - 3s/epoch - 2s/step\n",
      "Epoch 13/100\n",
      "2/2 - 3s - loss: 0.2515 - binary_accuracy: 0.5292 - val_loss: 0.3535 - val_binary_accuracy: 0.4101 - 3s/epoch - 2s/step\n",
      "Epoch 14/100\n",
      "2/2 - 3s - loss: 0.3035 - binary_accuracy: 0.5411 - val_loss: 0.3574 - val_binary_accuracy: 0.4101 - 3s/epoch - 2s/step\n",
      "Epoch 15/100\n",
      "2/2 - 3s - loss: 0.3002 - binary_accuracy: 0.5291 - val_loss: 0.2757 - val_binary_accuracy: 0.4179 - 3s/epoch - 2s/step\n",
      "Epoch 16/100\n",
      "2/2 - 3s - loss: 0.2680 - binary_accuracy: 0.4667 - val_loss: 0.2486 - val_binary_accuracy: 0.6000 - 3s/epoch - 2s/step\n",
      "Epoch 17/100\n",
      "2/2 - 3s - loss: 0.2936 - binary_accuracy: 0.4667 - val_loss: 0.2422 - val_binary_accuracy: 0.6000 - 3s/epoch - 2s/step\n",
      "Epoch 18/100\n",
      "2/2 - 3s - loss: 0.2408 - binary_accuracy: 0.6081 - val_loss: 0.3191 - val_binary_accuracy: 0.4116 - 3s/epoch - 2s/step\n",
      "Epoch 19/100\n",
      "2/2 - 3s - loss: 0.2993 - binary_accuracy: 0.5180 - val_loss: 0.3752 - val_binary_accuracy: 0.4076 - 3s/epoch - 2s/step\n",
      "Epoch 20/100\n",
      "2/2 - 3s - loss: 0.3138 - binary_accuracy: 0.5251 - val_loss: 0.3259 - val_binary_accuracy: 0.4109 - 3s/epoch - 2s/step\n",
      "Epoch 21/100\n",
      "2/2 - 3s - loss: 0.2788 - binary_accuracy: 0.5280 - val_loss: 0.2441 - val_binary_accuracy: 0.6000 - 3s/epoch - 2s/step\n",
      "Epoch 22/100\n",
      "2/2 - 3s - loss: 0.2531 - binary_accuracy: 0.4667 - val_loss: 0.2448 - val_binary_accuracy: 0.6000 - 3s/epoch - 2s/step\n",
      "Epoch 23/100\n",
      "2/2 - 3s - loss: 0.2934 - binary_accuracy: 0.4667 - val_loss: 0.2479 - val_binary_accuracy: 0.6000 - 3s/epoch - 2s/step\n",
      "Epoch 24/100\n",
      "2/2 - 3s - loss: 0.2669 - binary_accuracy: 0.4179 - val_loss: 0.3455 - val_binary_accuracy: 0.4089 - 3s/epoch - 2s/step\n",
      "Epoch 25/100\n",
      "2/2 - 3s - loss: 0.2923 - binary_accuracy: 0.5436 - val_loss: 0.3587 - val_binary_accuracy: 0.4089 - 3s/epoch - 2s/step\n",
      "Epoch 26/100\n",
      "2/2 - 3s - loss: 0.2978 - binary_accuracy: 0.5472 - val_loss: 0.3221 - val_binary_accuracy: 0.4109 - 3s/epoch - 2s/step\n",
      "Epoch 27/100\n",
      "2/2 - 3s - loss: 0.2770 - binary_accuracy: 0.5295 - val_loss: 0.2549 - val_binary_accuracy: 0.4422 - 3s/epoch - 2s/step\n",
      "Epoch 28/100\n",
      "2/2 - 3s - loss: 0.2586 - binary_accuracy: 0.4667 - val_loss: 0.2419 - val_binary_accuracy: 0.6000 - 3s/epoch - 2s/step\n",
      "Epoch 29/100\n",
      "2/2 - 3s - loss: 0.2609 - binary_accuracy: 0.4667 - val_loss: 0.2530 - val_binary_accuracy: 0.4548 - 3s/epoch - 2s/step\n",
      "Epoch 30/100\n",
      "2/2 - 3s - loss: 0.2450 - binary_accuracy: 0.5456 - val_loss: 0.2962 - val_binary_accuracy: 0.4129 - 3s/epoch - 2s/step\n",
      "Epoch 31/100\n",
      "2/2 - 3s - loss: 0.2813 - binary_accuracy: 0.5128 - val_loss: 0.3155 - val_binary_accuracy: 0.4109 - 3s/epoch - 2s/step\n",
      "Epoch 32/100\n",
      "2/2 - 3s - loss: 0.2741 - binary_accuracy: 0.5247 - val_loss: 0.2579 - val_binary_accuracy: 0.4298 - 3s/epoch - 2s/step\n",
      "Epoch 33/100\n",
      "2/2 - 3s - loss: 0.2558 - binary_accuracy: 0.4667 - val_loss: 0.2420 - val_binary_accuracy: 0.6000 - 3s/epoch - 2s/step\n",
      "Epoch 34/100\n",
      "2/2 - 3s - loss: 0.2620 - binary_accuracy: 0.4667 - val_loss: 0.2479 - val_binary_accuracy: 0.6000 - 3s/epoch - 2s/step\n",
      "Epoch 35/100\n",
      "2/2 - 3s - loss: 0.2588 - binary_accuracy: 0.4105 - val_loss: 0.2836 - val_binary_accuracy: 0.4135 - 3s/epoch - 2s/step\n",
      "Epoch 36/100\n",
      "2/2 - 3s - loss: 0.2586 - binary_accuracy: 0.5308 - val_loss: 0.2710 - val_binary_accuracy: 0.4163 - 3s/epoch - 2s/step\n",
      "Epoch 37/100\n",
      "2/2 - 3s - loss: 0.2500 - binary_accuracy: 0.5276 - val_loss: 0.2482 - val_binary_accuracy: 0.6000 - 3s/epoch - 2s/step\n",
      "Epoch 38/100\n",
      "2/2 - 3s - loss: 0.2559 - binary_accuracy: 0.4667 - val_loss: 0.2425 - val_binary_accuracy: 0.6000 - 3s/epoch - 2s/step\n",
      "Epoch 39/100\n",
      "2/2 - 3s - loss: 0.2615 - binary_accuracy: 0.4462 - val_loss: 0.2547 - val_binary_accuracy: 0.4378 - 3s/epoch - 2s/step\n",
      "Epoch 40/100\n",
      "2/2 - 3s - loss: 0.2520 - binary_accuracy: 0.5262 - val_loss: 0.2668 - val_binary_accuracy: 0.4169 - 3s/epoch - 2s/step\n",
      "Epoch 41/100\n",
      "2/2 - 3s - loss: 0.2531 - binary_accuracy: 0.5231 - val_loss: 0.2540 - val_binary_accuracy: 0.4404 - 3s/epoch - 2s/step\n",
      "Epoch 42/100\n",
      "2/2 - 3s - loss: 0.2503 - binary_accuracy: 0.5206 - val_loss: 0.2490 - val_binary_accuracy: 0.5732 - 3s/epoch - 2s/step\n",
      "Epoch 43/100\n",
      "2/2 - 3s - loss: 0.2504 - binary_accuracy: 0.4695 - val_loss: 0.2461 - val_binary_accuracy: 0.6000 - 3s/epoch - 2s/step\n",
      "Epoch 44/100\n",
      "2/2 - 3s - loss: 0.2621 - binary_accuracy: 0.2890 - val_loss: 0.2436 - val_binary_accuracy: 0.6000 - 3s/epoch - 2s/step\n",
      "Epoch 45/100\n",
      "2/2 - 3s - loss: 0.2779 - binary_accuracy: 0.4667 - val_loss: 0.2430 - val_binary_accuracy: 0.6000 - 3s/epoch - 2s/step\n",
      "Epoch 46/100\n",
      "2/2 - 3s - loss: 0.2506 - binary_accuracy: 0.5250 - val_loss: 0.2861 - val_binary_accuracy: 0.4123 - 3s/epoch - 2s/step\n",
      "Epoch 47/100\n",
      "2/2 - 3s - loss: 0.2754 - binary_accuracy: 0.5678 - val_loss: 0.3227 - val_binary_accuracy: 0.4089 - 3s/epoch - 2s/step\n",
      "Epoch 48/100\n",
      "2/2 - 3s - loss: 0.2756 - binary_accuracy: 0.5313 - val_loss: 0.2658 - val_binary_accuracy: 0.4169 - 3s/epoch - 2s/step\n",
      "Epoch 49/100\n",
      "2/2 - 3s - loss: 0.2585 - binary_accuracy: 0.4667 - val_loss: 0.2425 - val_binary_accuracy: 0.6000 - 3s/epoch - 2s/step\n",
      "Epoch 50/100\n",
      "2/2 - 3s - loss: 0.2704 - binary_accuracy: 0.4667 - val_loss: 0.2424 - val_binary_accuracy: 0.6000 - 3s/epoch - 2s/step\n",
      "Epoch 51/100\n",
      "2/2 - 3s - loss: 0.2606 - binary_accuracy: 0.4524 - val_loss: 0.2532 - val_binary_accuracy: 0.4431 - 3s/epoch - 2s/step\n",
      "Epoch 52/100\n",
      "2/2 - 3s - loss: 0.2525 - binary_accuracy: 0.4543 - val_loss: 0.2690 - val_binary_accuracy: 0.4157 - 3s/epoch - 2s/step\n",
      "Epoch 53/100\n",
      "2/2 - 3s - loss: 0.2573 - binary_accuracy: 0.5521 - val_loss: 0.3010 - val_binary_accuracy: 0.4101 - 3s/epoch - 2s/step\n",
      "Epoch 54/100\n",
      "2/2 - 3s - loss: 0.2660 - binary_accuracy: 0.5441 - val_loss: 0.3303 - val_binary_accuracy: 0.4076 - 3s/epoch - 2s/step\n",
      "Epoch 55/100\n",
      "2/2 - 3s - loss: 0.2887 - binary_accuracy: 0.5435 - val_loss: 0.3117 - val_binary_accuracy: 0.4089 - 3s/epoch - 2s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "2/2 - 3s - loss: 0.2571 - binary_accuracy: 0.5933 - val_loss: 0.2477 - val_binary_accuracy: 0.6000 - 3s/epoch - 2s/step\n",
      "Epoch 57/100\n",
      "2/2 - 3s - loss: 0.2676 - binary_accuracy: 0.4667 - val_loss: 0.2569 - val_binary_accuracy: 0.6000 - 3s/epoch - 2s/step\n",
      "Epoch 58/100\n",
      "2/2 - 3s - loss: 0.3306 - binary_accuracy: 0.4667 - val_loss: 0.2512 - val_binary_accuracy: 0.6000 - 3s/epoch - 2s/step\n",
      "Epoch 59/100\n",
      "2/2 - 3s - loss: 0.2971 - binary_accuracy: 0.4667 - val_loss: 0.2633 - val_binary_accuracy: 0.4169 - 3s/epoch - 2s/step\n",
      "Epoch 60/100\n",
      "2/2 - 3s - loss: 0.2646 - binary_accuracy: 0.5265 - val_loss: 0.3210 - val_binary_accuracy: 0.4076 - 3s/epoch - 2s/step\n",
      "Epoch 61/100\n",
      "2/2 - 3s - loss: 0.2791 - binary_accuracy: 0.5675 - val_loss: 0.3070 - val_binary_accuracy: 0.4089 - 3s/epoch - 2s/step\n",
      "Epoch 62/100\n",
      "2/2 - 3s - loss: 0.2819 - binary_accuracy: 0.5361 - val_loss: 0.2516 - val_binary_accuracy: 0.4580 - 3s/epoch - 2s/step\n",
      "Epoch 63/100\n",
      "2/2 - 3s - loss: 0.2507 - binary_accuracy: 0.5134 - val_loss: 0.2434 - val_binary_accuracy: 0.6000 - 3s/epoch - 2s/step\n",
      "Epoch 64/100\n",
      "2/2 - 3s - loss: 0.2599 - binary_accuracy: 0.4667 - val_loss: 0.2421 - val_binary_accuracy: 0.6000 - 3s/epoch - 2s/step\n",
      "Epoch 65/100\n",
      "2/2 - 3s - loss: 0.2609 - binary_accuracy: 0.4667 - val_loss: 0.2522 - val_binary_accuracy: 0.4487 - 3s/epoch - 2s/step\n",
      "Epoch 66/100\n",
      "2/2 - 3s - loss: 0.2455 - binary_accuracy: 0.5320 - val_loss: 0.2876 - val_binary_accuracy: 0.4109 - 3s/epoch - 2s/step\n",
      "Epoch 67/100\n",
      "2/2 - 3s - loss: 0.2622 - binary_accuracy: 0.5321 - val_loss: 0.3113 - val_binary_accuracy: 0.4076 - 3s/epoch - 2s/step\n",
      "Epoch 68/100\n",
      "2/2 - 3s - loss: 0.2755 - binary_accuracy: 0.5173 - val_loss: 0.2745 - val_binary_accuracy: 0.4129 - 3s/epoch - 2s/step\n",
      "Epoch 69/100\n",
      "2/2 - 3s - loss: 0.2721 - binary_accuracy: 0.3526 - val_loss: 0.2454 - val_binary_accuracy: 0.6000 - 3s/epoch - 2s/step\n",
      "Epoch 70/100\n",
      "2/2 - 3s - loss: 0.2544 - binary_accuracy: 0.4212 - val_loss: 0.2496 - val_binary_accuracy: 0.5359 - 3s/epoch - 2s/step\n",
      "Epoch 71/100\n",
      "2/2 - 3s - loss: 0.2518 - binary_accuracy: 0.4681 - val_loss: 0.2516 - val_binary_accuracy: 0.4548 - 3s/epoch - 2s/step\n",
      "Epoch 72/100\n",
      "2/2 - 3s - loss: 0.2506 - binary_accuracy: 0.4667 - val_loss: 0.2511 - val_binary_accuracy: 0.4646 - 3s/epoch - 2s/step\n",
      "Epoch 73/100\n",
      "2/2 - 3s - loss: 0.2526 - binary_accuracy: 0.3803 - val_loss: 0.2661 - val_binary_accuracy: 0.4141 - 3s/epoch - 2s/step\n",
      "Epoch 74/100\n",
      "2/2 - 3s - loss: 0.2506 - binary_accuracy: 0.5124 - val_loss: 0.2950 - val_binary_accuracy: 0.4089 - 3s/epoch - 2s/step\n",
      "Epoch 75/100\n",
      "2/2 - 3s - loss: 0.2557 - binary_accuracy: 0.5490 - val_loss: 0.3088 - val_binary_accuracy: 0.4066 - 3s/epoch - 2s/step\n",
      "Epoch 76/100\n",
      "2/2 - 3s - loss: 0.2704 - binary_accuracy: 0.5321 - val_loss: 0.2895 - val_binary_accuracy: 0.4089 - 3s/epoch - 2s/step\n",
      "Epoch 77/100\n",
      "2/2 - 3s - loss: 0.2552 - binary_accuracy: 0.5304 - val_loss: 0.2483 - val_binary_accuracy: 0.6000 - 3s/epoch - 2s/step\n",
      "Epoch 78/100\n",
      "2/2 - 3s - loss: 0.2588 - binary_accuracy: 0.4667 - val_loss: 0.2427 - val_binary_accuracy: 0.6000 - 3s/epoch - 2s/step\n",
      "Epoch 79/100\n",
      "2/2 - 3s - loss: 0.2701 - binary_accuracy: 0.4667 - val_loss: 0.2446 - val_binary_accuracy: 0.6000 - 3s/epoch - 2s/step\n",
      "Epoch 80/100\n",
      "2/2 - 3s - loss: 0.2504 - binary_accuracy: 0.4667 - val_loss: 0.2673 - val_binary_accuracy: 0.4123 - 3s/epoch - 2s/step\n",
      "Epoch 81/100\n",
      "2/2 - 3s - loss: 0.2526 - binary_accuracy: 0.5307 - val_loss: 0.3052 - val_binary_accuracy: 0.4064 - 3s/epoch - 2s/step\n",
      "Epoch 82/100\n",
      "2/2 - 3s - loss: 0.2694 - binary_accuracy: 0.5329 - val_loss: 0.2942 - val_binary_accuracy: 0.4064 - 3s/epoch - 2s/step\n",
      "Epoch 83/100\n",
      "2/2 - 3s - loss: 0.2663 - binary_accuracy: 0.5172 - val_loss: 0.2528 - val_binary_accuracy: 0.4305 - 3s/epoch - 2s/step\n",
      "Epoch 84/100\n",
      "2/2 - 3s - loss: 0.2684 - binary_accuracy: 0.3628 - val_loss: 0.2455 - val_binary_accuracy: 0.5997 - 3s/epoch - 2s/step\n",
      "Epoch 85/100\n",
      "2/2 - 3s - loss: 0.2575 - binary_accuracy: 0.4103 - val_loss: 0.2710 - val_binary_accuracy: 0.4098 - 3s/epoch - 2s/step\n",
      "Epoch 86/100\n",
      "2/2 - 3s - loss: 0.2508 - binary_accuracy: 0.5452 - val_loss: 0.2797 - val_binary_accuracy: 0.4073 - 3s/epoch - 2s/step\n",
      "Epoch 87/100\n",
      "2/2 - 3s - loss: 0.2623 - binary_accuracy: 0.5401 - val_loss: 0.2648 - val_binary_accuracy: 0.4113 - 3s/epoch - 2s/step\n",
      "Epoch 88/100\n",
      "2/2 - 3s - loss: 0.2523 - binary_accuracy: 0.5181 - val_loss: 0.2604 - val_binary_accuracy: 0.4126 - 3s/epoch - 2s/step\n",
      "Epoch 89/100\n",
      "2/2 - 3s - loss: 0.2515 - binary_accuracy: 0.5137 - val_loss: 0.2484 - val_binary_accuracy: 0.5997 - 3s/epoch - 2s/step\n",
      "Epoch 90/100\n",
      "2/2 - 3s - loss: 0.2722 - binary_accuracy: 0.4658 - val_loss: 0.2575 - val_binary_accuracy: 0.4144 - 3s/epoch - 2s/step\n",
      "Epoch 91/100\n",
      "2/2 - 3s - loss: 0.2607 - binary_accuracy: 0.5278 - val_loss: 0.3113 - val_binary_accuracy: 0.4045 - 3s/epoch - 2s/step\n",
      "Epoch 92/100\n",
      "2/2 - 3s - loss: 0.2727 - binary_accuracy: 0.5329 - val_loss: 0.3000 - val_binary_accuracy: 0.4052 - 3s/epoch - 2s/step\n",
      "Epoch 93/100\n",
      "2/2 - 3s - loss: 0.2602 - binary_accuracy: 0.5214 - val_loss: 0.2497 - val_binary_accuracy: 0.5524 - 3s/epoch - 2s/step\n",
      "Epoch 94/100\n",
      "2/2 - 3s - loss: 0.2588 - binary_accuracy: 0.4670 - val_loss: 0.2440 - val_binary_accuracy: 0.5997 - 3s/epoch - 2s/step\n",
      "Epoch 95/100\n",
      "2/2 - 3s - loss: 0.2770 - binary_accuracy: 0.4668 - val_loss: 0.2431 - val_binary_accuracy: 0.5997 - 3s/epoch - 2s/step\n",
      "Epoch 96/100\n",
      "2/2 - 4s - loss: 0.2826 - binary_accuracy: 0.2880 - val_loss: 0.2738 - val_binary_accuracy: 0.4073 - 4s/epoch - 2s/step\n",
      "Epoch 97/100\n",
      "2/2 - 4s - loss: 0.2531 - binary_accuracy: 0.5323 - val_loss: 0.2677 - val_binary_accuracy: 0.4086 - 4s/epoch - 2s/step\n",
      "Epoch 98/100\n",
      "2/2 - 4s - loss: 0.2535 - binary_accuracy: 0.5192 - val_loss: 0.2484 - val_binary_accuracy: 0.5997 - 4s/epoch - 2s/step\n",
      "Epoch 99/100\n",
      "2/2 - 4s - loss: 0.2525 - binary_accuracy: 0.4670 - val_loss: 0.2468 - val_binary_accuracy: 0.5997 - 4s/epoch - 2s/step\n",
      "Epoch 100/100\n",
      "2/2 - 4s - loss: 0.2504 - binary_accuracy: 0.4671 - val_loss: 0.2592 - val_binary_accuracy: 0.4120 - 4s/epoch - 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x238862c21f0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2 layer\n",
    "\n",
    "training_data = []\n",
    "img_size=500\n",
    "\n",
    "def create_training_data():\n",
    "    for category in categories:\n",
    "        path = os.path.join(datadir,category)\n",
    "        class_num = categories.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n",
    "            num_array=cv2.resize(img_array,(img_size,img_size))\n",
    "            training_data.append([num_array,class_num])\n",
    "create_training_data()\n",
    "\n",
    "\n",
    "x=[]\n",
    "y=[]\n",
    "for features,label in training_data:\n",
    "    x.append(features)\n",
    "    y.append(label)\n",
    "x=np.asarray(x).reshape(-1,img_size,img_size,1)\n",
    "y=np.asarray(y)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=.25,random_state=42)\n",
    "\n",
    "model =Sequential()\n",
    "model.add(Dense(32,input_dim=1,activation='relu'))\n",
    "model.add(Dense(32,input_dim=1,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "             optimizer='adam',\n",
    "             metrics=['binary_accuracy'])\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=100,batch_size=10,verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d020ca16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 514ms/step - loss: 0.2592 - binary_accuracy: 0.4120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2592275142669678, 0.4119912087917328]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b5e58d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_81_input'), name='dense_81_input', description=\"created by layer 'dense_81_input'\"), but it was called on an input with incompatible shape (None, 500, 500, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_81_input'), name='dense_81_input', description=\"created by layer 'dense_81_input'\"), but it was called on an input with incompatible shape (None, 500, 500, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_81_input'), name='dense_81_input', description=\"created by layer 'dense_81_input'\"), but it was called on an input with incompatible shape (None, 500, 500, 1).\n",
      "2/2 - 6s - loss: 0.4868 - binary_accuracy: 0.4000 - val_loss: 0.3374 - val_binary_accuracy: 0.6000 - 6s/epoch - 3s/step\n",
      "Epoch 2/100\n",
      "2/2 - 5s - loss: 0.3943 - binary_accuracy: 0.4667 - val_loss: 0.5124 - val_binary_accuracy: 0.4000 - 5s/epoch - 2s/step\n",
      "Epoch 3/100\n",
      "2/2 - 4s - loss: 0.3974 - binary_accuracy: 0.5333 - val_loss: 0.4735 - val_binary_accuracy: 0.4000 - 4s/epoch - 2s/step\n",
      "Epoch 4/100\n",
      "2/2 - 5s - loss: 0.3601 - binary_accuracy: 0.5333 - val_loss: 0.2538 - val_binary_accuracy: 0.5962 - 5s/epoch - 3s/step\n",
      "Epoch 5/100\n",
      "2/2 - 5s - loss: 0.2995 - binary_accuracy: 0.5333 - val_loss: 0.3108 - val_binary_accuracy: 0.4000 - 5s/epoch - 3s/step\n",
      "Epoch 6/100\n",
      "2/2 - 5s - loss: 0.3360 - binary_accuracy: 0.4667 - val_loss: 0.2510 - val_binary_accuracy: 0.4000 - 5s/epoch - 2s/step\n",
      "Epoch 7/100\n",
      "2/2 - 5s - loss: 0.3004 - binary_accuracy: 0.5333 - val_loss: 0.2706 - val_binary_accuracy: 0.5997 - 5s/epoch - 3s/step\n",
      "Epoch 8/100\n",
      "2/2 - 7s - loss: 0.3096 - binary_accuracy: 0.5333 - val_loss: 0.2519 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 9/100\n",
      "2/2 - 10s - loss: 0.2526 - binary_accuracy: 0.4761 - val_loss: 0.4122 - val_binary_accuracy: 0.4000 - 10s/epoch - 5s/step\n",
      "Epoch 10/100\n",
      "2/2 - 7s - loss: 0.3989 - binary_accuracy: 0.3536 - val_loss: 0.4803 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 11/100\n",
      "2/2 - 8s - loss: 0.3800 - binary_accuracy: 0.5333 - val_loss: 0.4015 - val_binary_accuracy: 0.4000 - 8s/epoch - 4s/step\n",
      "Epoch 12/100\n",
      "2/2 - 5s - loss: 0.2919 - binary_accuracy: 0.5333 - val_loss: 0.3146 - val_binary_accuracy: 0.5997 - 5s/epoch - 3s/step\n",
      "Epoch 13/100\n",
      "2/2 - 6s - loss: 0.3827 - binary_accuracy: 0.4726 - val_loss: 0.3457 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 14/100\n",
      "2/2 - 6s - loss: 0.2589 - binary_accuracy: 0.5333 - val_loss: 0.2837 - val_binary_accuracy: 0.5960 - 6s/epoch - 3s/step\n",
      "Epoch 15/100\n",
      "2/2 - 5s - loss: 0.3694 - binary_accuracy: 0.4061 - val_loss: 0.2905 - val_binary_accuracy: 0.5960 - 5s/epoch - 2s/step\n",
      "Epoch 16/100\n",
      "2/2 - 4s - loss: 0.3222 - binary_accuracy: 0.4572 - val_loss: 0.4729 - val_binary_accuracy: 0.4000 - 4s/epoch - 2s/step\n",
      "Epoch 17/100\n",
      "2/2 - 6s - loss: 0.3722 - binary_accuracy: 0.5333 - val_loss: 0.3829 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 18/100\n",
      "2/2 - 6s - loss: 0.2840 - binary_accuracy: 0.5333 - val_loss: 0.2852 - val_binary_accuracy: 0.5960 - 6s/epoch - 3s/step\n",
      "Epoch 19/100\n",
      "2/2 - 7s - loss: 0.3060 - binary_accuracy: 0.4839 - val_loss: 0.4587 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 20/100\n",
      "2/2 - 7s - loss: 0.3649 - binary_accuracy: 0.5333 - val_loss: 0.3524 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 21/100\n",
      "2/2 - 5s - loss: 0.2986 - binary_accuracy: 0.4682 - val_loss: 0.4180 - val_binary_accuracy: 0.4000 - 5s/epoch - 3s/step\n",
      "Epoch 22/100\n",
      "2/2 - 5s - loss: 0.3236 - binary_accuracy: 0.5333 - val_loss: 0.2670 - val_binary_accuracy: 0.5960 - 5s/epoch - 2s/step\n",
      "Epoch 23/100\n",
      "2/2 - 5s - loss: 0.2725 - binary_accuracy: 0.4878 - val_loss: 0.4644 - val_binary_accuracy: 0.4000 - 5s/epoch - 2s/step\n",
      "Epoch 24/100\n",
      "2/2 - 5s - loss: 0.3698 - binary_accuracy: 0.5333 - val_loss: 0.3826 - val_binary_accuracy: 0.4000 - 5s/epoch - 3s/step\n",
      "Epoch 25/100\n",
      "2/2 - 5s - loss: 0.2904 - binary_accuracy: 0.5333 - val_loss: 0.2915 - val_binary_accuracy: 0.5997 - 5s/epoch - 3s/step\n",
      "Epoch 26/100\n",
      "2/2 - 5s - loss: 0.3327 - binary_accuracy: 0.4736 - val_loss: 0.4124 - val_binary_accuracy: 0.4000 - 5s/epoch - 2s/step\n",
      "Epoch 27/100\n",
      "2/2 - 5s - loss: 0.3205 - binary_accuracy: 0.5333 - val_loss: 0.2431 - val_binary_accuracy: 0.5891 - 5s/epoch - 2s/step\n",
      "Epoch 28/100\n",
      "2/2 - 5s - loss: 0.3059 - binary_accuracy: 0.4168 - val_loss: 0.2548 - val_binary_accuracy: 0.5953 - 5s/epoch - 2s/step\n",
      "Epoch 29/100\n",
      "2/2 - 5s - loss: 0.3426 - binary_accuracy: 0.4014 - val_loss: 0.2452 - val_binary_accuracy: 0.5859 - 5s/epoch - 2s/step\n",
      "Epoch 30/100\n",
      "2/2 - 5s - loss: 0.2893 - binary_accuracy: 0.4118 - val_loss: 0.2444 - val_binary_accuracy: 0.5945 - 5s/epoch - 2s/step\n",
      "Epoch 31/100\n",
      "2/2 - 5s - loss: 0.2695 - binary_accuracy: 0.5333 - val_loss: 0.2461 - val_binary_accuracy: 0.5837 - 5s/epoch - 2s/step\n",
      "Epoch 32/100\n",
      "2/2 - 6s - loss: 0.3078 - binary_accuracy: 0.4442 - val_loss: 0.4705 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 33/100\n",
      "2/2 - 5s - loss: 0.3735 - binary_accuracy: 0.5333 - val_loss: 0.4369 - val_binary_accuracy: 0.4000 - 5s/epoch - 3s/step\n",
      "Epoch 34/100\n",
      "2/2 - 4s - loss: 0.3502 - binary_accuracy: 0.5333 - val_loss: 0.2507 - val_binary_accuracy: 0.4000 - 4s/epoch - 2s/step\n",
      "Epoch 35/100\n",
      "2/2 - 4s - loss: 0.2502 - binary_accuracy: 0.4880 - val_loss: 0.3192 - val_binary_accuracy: 0.4000 - 4s/epoch - 2s/step\n",
      "Epoch 36/100\n",
      "2/2 - 5s - loss: 0.2537 - binary_accuracy: 0.5333 - val_loss: 0.2663 - val_binary_accuracy: 0.5960 - 5s/epoch - 2s/step\n",
      "Epoch 37/100\n",
      "2/2 - 5s - loss: 0.2912 - binary_accuracy: 0.5333 - val_loss: 0.2534 - val_binary_accuracy: 0.4000 - 5s/epoch - 2s/step\n",
      "Epoch 38/100\n",
      "2/2 - 4s - loss: 0.2532 - binary_accuracy: 0.4696 - val_loss: 0.3689 - val_binary_accuracy: 0.4000 - 4s/epoch - 2s/step\n",
      "Epoch 39/100\n",
      "2/2 - 4s - loss: 0.3113 - binary_accuracy: 0.4686 - val_loss: 0.3863 - val_binary_accuracy: 0.4000 - 4s/epoch - 2s/step\n",
      "Epoch 40/100\n",
      "2/2 - 4s - loss: 0.2840 - binary_accuracy: 0.5333 - val_loss: 0.2723 - val_binary_accuracy: 0.5960 - 4s/epoch - 2s/step\n",
      "Epoch 41/100\n",
      "2/2 - 4s - loss: 0.3046 - binary_accuracy: 0.5333 - val_loss: 0.2429 - val_binary_accuracy: 0.5899 - 4s/epoch - 2s/step\n",
      "Epoch 42/100\n",
      "2/2 - 4s - loss: 0.2588 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5911 - 4s/epoch - 2s/step\n",
      "Epoch 43/100\n",
      "2/2 - 4s - loss: 0.2520 - binary_accuracy: 0.4637 - val_loss: 0.5019 - val_binary_accuracy: 0.4000 - 4s/epoch - 2s/step\n",
      "Epoch 44/100\n",
      "2/2 - 4s - loss: 0.4000 - binary_accuracy: 0.5333 - val_loss: 0.4724 - val_binary_accuracy: 0.4000 - 4s/epoch - 2s/step\n",
      "Epoch 45/100\n",
      "2/2 - 5s - loss: 0.3751 - binary_accuracy: 0.5333 - val_loss: 0.3761 - val_binary_accuracy: 0.4000 - 5s/epoch - 3s/step\n",
      "Epoch 46/100\n",
      "2/2 - 5s - loss: 0.3851 - binary_accuracy: 0.3346 - val_loss: 0.4753 - val_binary_accuracy: 0.4000 - 5s/epoch - 3s/step\n",
      "Epoch 47/100\n",
      "2/2 - 4s - loss: 0.3684 - binary_accuracy: 0.5333 - val_loss: 0.4128 - val_binary_accuracy: 0.4000 - 4s/epoch - 2s/step\n",
      "Epoch 48/100\n",
      "2/2 - 4s - loss: 0.3127 - binary_accuracy: 0.5333 - val_loss: 0.2532 - val_binary_accuracy: 0.5997 - 4s/epoch - 2s/step\n",
      "Epoch 49/100\n",
      "2/2 - 5s - loss: 0.3446 - binary_accuracy: 0.4005 - val_loss: 0.2473 - val_binary_accuracy: 0.5877 - 5s/epoch - 2s/step\n",
      "Epoch 50/100\n",
      "2/2 - 5s - loss: 0.2794 - binary_accuracy: 0.4094 - val_loss: 0.2427 - val_binary_accuracy: 0.5960 - 5s/epoch - 2s/step\n",
      "Epoch 51/100\n",
      "2/2 - 4s - loss: 0.2651 - binary_accuracy: 0.4550 - val_loss: 0.4772 - val_binary_accuracy: 0.4000 - 4s/epoch - 2s/step\n",
      "Epoch 52/100\n",
      "2/2 - 4s - loss: 0.3815 - binary_accuracy: 0.5333 - val_loss: 0.4038 - val_binary_accuracy: 0.4000 - 4s/epoch - 2s/step\n",
      "Epoch 53/100\n",
      "2/2 - 4s - loss: 0.3166 - binary_accuracy: 0.5333 - val_loss: 0.2505 - val_binary_accuracy: 0.4000 - 4s/epoch - 2s/step\n",
      "Epoch 54/100\n",
      "2/2 - 4s - loss: 0.2835 - binary_accuracy: 0.5333 - val_loss: 0.2904 - val_binary_accuracy: 0.5997 - 4s/epoch - 2s/step\n",
      "Epoch 55/100\n",
      "2/2 - 5s - loss: 0.3312 - binary_accuracy: 0.4670 - val_loss: 0.3858 - val_binary_accuracy: 0.4000 - 5s/epoch - 2s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "2/2 - 5s - loss: 0.3506 - binary_accuracy: 0.3355 - val_loss: 0.4601 - val_binary_accuracy: 0.4000 - 5s/epoch - 2s/step\n",
      "Epoch 57/100\n",
      "2/2 - 5s - loss: 0.3640 - binary_accuracy: 0.5333 - val_loss: 0.3486 - val_binary_accuracy: 0.4000 - 5s/epoch - 2s/step\n",
      "Epoch 58/100\n",
      "2/2 - 5s - loss: 0.2660 - binary_accuracy: 0.5333 - val_loss: 0.2649 - val_binary_accuracy: 0.5997 - 5s/epoch - 2s/step\n",
      "Epoch 59/100\n",
      "2/2 - 5s - loss: 0.2680 - binary_accuracy: 0.4849 - val_loss: 0.4567 - val_binary_accuracy: 0.4000 - 5s/epoch - 2s/step\n",
      "Epoch 60/100\n",
      "2/2 - 4s - loss: 0.3678 - binary_accuracy: 0.5333 - val_loss: 0.3089 - val_binary_accuracy: 0.4000 - 4s/epoch - 2s/step\n",
      "Epoch 61/100\n",
      "2/2 - 4s - loss: 0.2506 - binary_accuracy: 0.5985 - val_loss: 0.2521 - val_binary_accuracy: 0.5997 - 4s/epoch - 2s/step\n",
      "Epoch 62/100\n",
      "2/2 - 4s - loss: 0.3456 - binary_accuracy: 0.4007 - val_loss: 0.2483 - val_binary_accuracy: 0.5924 - 4s/epoch - 2s/step\n",
      "Epoch 63/100\n",
      "2/2 - 5s - loss: 0.2858 - binary_accuracy: 0.4157 - val_loss: 0.2851 - val_binary_accuracy: 0.5997 - 5s/epoch - 2s/step\n",
      "Epoch 64/100\n",
      "2/2 - 4s - loss: 0.3467 - binary_accuracy: 0.4009 - val_loss: 0.2597 - val_binary_accuracy: 0.5997 - 4s/epoch - 2s/step\n",
      "Epoch 65/100\n",
      "2/2 - 4s - loss: 0.2860 - binary_accuracy: 0.5333 - val_loss: 0.2560 - val_binary_accuracy: 0.4000 - 4s/epoch - 2s/step\n",
      "Epoch 66/100\n",
      "2/2 - 4s - loss: 0.3259 - binary_accuracy: 0.3341 - val_loss: 0.4312 - val_binary_accuracy: 0.4000 - 4s/epoch - 2s/step\n",
      "Epoch 67/100\n",
      "2/2 - 4s - loss: 0.3416 - binary_accuracy: 0.5333 - val_loss: 0.2784 - val_binary_accuracy: 0.4000 - 4s/epoch - 2s/step\n",
      "Epoch 68/100\n",
      "2/2 - 4s - loss: 0.2768 - binary_accuracy: 0.4672 - val_loss: 0.3404 - val_binary_accuracy: 0.4000 - 4s/epoch - 2s/step\n",
      "Epoch 69/100\n",
      "2/2 - 5s - loss: 0.2926 - binary_accuracy: 0.4674 - val_loss: 0.3978 - val_binary_accuracy: 0.4000 - 5s/epoch - 3s/step\n",
      "Epoch 70/100\n",
      "2/2 - 5s - loss: 0.3139 - binary_accuracy: 0.5333 - val_loss: 0.2539 - val_binary_accuracy: 0.4000 - 5s/epoch - 2s/step\n",
      "Epoch 71/100\n",
      "2/2 - 4s - loss: 0.2531 - binary_accuracy: 0.4754 - val_loss: 0.3740 - val_binary_accuracy: 0.4000 - 4s/epoch - 2s/step\n",
      "Epoch 72/100\n",
      "2/2 - 4s - loss: 0.2972 - binary_accuracy: 0.5333 - val_loss: 0.3173 - val_binary_accuracy: 0.5997 - 4s/epoch - 2s/step\n",
      "Epoch 73/100\n",
      "2/2 - 5s - loss: 0.4095 - binary_accuracy: 0.4665 - val_loss: 0.2551 - val_binary_accuracy: 0.5960 - 5s/epoch - 2s/step\n",
      "Epoch 74/100\n",
      "2/2 - 4s - loss: 0.2795 - binary_accuracy: 0.5333 - val_loss: 0.2530 - val_binary_accuracy: 0.4000 - 4s/epoch - 2s/step\n",
      "Epoch 75/100\n",
      "2/2 - 4s - loss: 0.2521 - binary_accuracy: 0.4685 - val_loss: 0.3706 - val_binary_accuracy: 0.4000 - 4s/epoch - 2s/step\n",
      "Epoch 76/100\n",
      "2/2 - 5s - loss: 0.3711 - binary_accuracy: 0.3357 - val_loss: 0.4415 - val_binary_accuracy: 0.4000 - 5s/epoch - 2s/step\n",
      "Epoch 77/100\n",
      "2/2 - 5s - loss: 0.3589 - binary_accuracy: 0.5333 - val_loss: 0.3739 - val_binary_accuracy: 0.4000 - 5s/epoch - 2s/step\n",
      "Epoch 78/100\n",
      "2/2 - 4s - loss: 0.2875 - binary_accuracy: 0.5333 - val_loss: 0.3010 - val_binary_accuracy: 0.5997 - 4s/epoch - 2s/step\n",
      "Epoch 79/100\n",
      "2/2 - 4s - loss: 0.3801 - binary_accuracy: 0.4549 - val_loss: 0.2445 - val_binary_accuracy: 0.5877 - 4s/epoch - 2s/step\n",
      "Epoch 80/100\n",
      "2/2 - 4s - loss: 0.2783 - binary_accuracy: 0.4526 - val_loss: 0.4595 - val_binary_accuracy: 0.4000 - 4s/epoch - 2s/step\n",
      "Epoch 81/100\n",
      "2/2 - 4s - loss: 0.3623 - binary_accuracy: 0.5333 - val_loss: 0.3783 - val_binary_accuracy: 0.4000 - 4s/epoch - 2s/step\n",
      "Epoch 82/100\n",
      "2/2 - 4s - loss: 0.3021 - binary_accuracy: 0.5333 - val_loss: 0.2789 - val_binary_accuracy: 0.4000 - 4s/epoch - 2s/step\n",
      "Epoch 83/100\n",
      "2/2 - 4s - loss: 0.2724 - binary_accuracy: 0.4731 - val_loss: 0.3957 - val_binary_accuracy: 0.4000 - 4s/epoch - 2s/step\n",
      "Epoch 84/100\n",
      "2/2 - 4s - loss: 0.3196 - binary_accuracy: 0.5333 - val_loss: 0.2745 - val_binary_accuracy: 0.4000 - 4s/epoch - 2s/step\n",
      "Epoch 85/100\n",
      "2/2 - 4s - loss: 0.2467 - binary_accuracy: 0.5333 - val_loss: 0.2479 - val_binary_accuracy: 0.5953 - 4s/epoch - 2s/step\n",
      "Epoch 86/100\n",
      "2/2 - 4s - loss: 0.4091 - binary_accuracy: 0.2817 - val_loss: 0.2873 - val_binary_accuracy: 0.4000 - 4s/epoch - 2s/step\n",
      "Epoch 87/100\n",
      "2/2 - 4s - loss: 0.4292 - binary_accuracy: 0.2017 - val_loss: 0.2730 - val_binary_accuracy: 0.4000 - 4s/epoch - 2s/step\n",
      "Epoch 88/100\n",
      "2/2 - 4s - loss: 0.2664 - binary_accuracy: 0.4800 - val_loss: 0.2790 - val_binary_accuracy: 0.4000 - 4s/epoch - 2s/step\n",
      "Epoch 89/100\n",
      "2/2 - 4s - loss: 0.3366 - binary_accuracy: 0.3358 - val_loss: 0.3588 - val_binary_accuracy: 0.4000 - 4s/epoch - 2s/step\n",
      "Epoch 90/100\n",
      "2/2 - 5s - loss: 0.3039 - binary_accuracy: 0.4859 - val_loss: 0.2926 - val_binary_accuracy: 0.4000 - 5s/epoch - 2s/step\n",
      "Epoch 91/100\n",
      "2/2 - 5s - loss: 0.2789 - binary_accuracy: 0.4800 - val_loss: 0.3138 - val_binary_accuracy: 0.4000 - 5s/epoch - 2s/step\n",
      "Epoch 92/100\n",
      "2/2 - 5s - loss: 0.2566 - binary_accuracy: 0.5333 - val_loss: 0.2788 - val_binary_accuracy: 0.5960 - 5s/epoch - 2s/step\n",
      "Epoch 93/100\n",
      "2/2 - 4s - loss: 0.3159 - binary_accuracy: 0.4800 - val_loss: 0.4450 - val_binary_accuracy: 0.4000 - 4s/epoch - 2s/step\n",
      "Epoch 94/100\n",
      "2/2 - 5s - loss: 0.3584 - binary_accuracy: 0.5333 - val_loss: 0.3823 - val_binary_accuracy: 0.4000 - 5s/epoch - 2s/step\n",
      "Epoch 95/100\n",
      "2/2 - 4s - loss: 0.3024 - binary_accuracy: 0.5333 - val_loss: 0.2738 - val_binary_accuracy: 0.5960 - 4s/epoch - 2s/step\n",
      "Epoch 96/100\n",
      "2/2 - 4s - loss: 0.3075 - binary_accuracy: 0.4569 - val_loss: 0.4248 - val_binary_accuracy: 0.4000 - 4s/epoch - 2s/step\n",
      "Epoch 97/100\n",
      "2/2 - 5s - loss: 0.3384 - binary_accuracy: 0.5333 - val_loss: 0.3051 - val_binary_accuracy: 0.4000 - 5s/epoch - 2s/step\n",
      "Epoch 98/100\n",
      "2/2 - 5s - loss: 0.3387 - binary_accuracy: 0.3358 - val_loss: 0.3795 - val_binary_accuracy: 0.4000 - 5s/epoch - 2s/step\n",
      "Epoch 99/100\n",
      "2/2 - 5s - loss: 0.3021 - binary_accuracy: 0.5333 - val_loss: 0.2555 - val_binary_accuracy: 0.5945 - 5s/epoch - 2s/step\n",
      "Epoch 100/100\n",
      "2/2 - 5s - loss: 0.3238 - binary_accuracy: 0.4018 - val_loss: 0.2446 - val_binary_accuracy: 0.5924 - 5s/epoch - 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23886a0f820>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3 layer\n",
    "\n",
    "training_data = []\n",
    "img_size=500\n",
    "\n",
    "def create_training_data():\n",
    "    for category in categories:\n",
    "        path = os.path.join(datadir,category)\n",
    "        class_num = categories.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n",
    "            num_array=cv2.resize(img_array,(img_size,img_size))\n",
    "            training_data.append([num_array,class_num])\n",
    "create_training_data()\n",
    "\n",
    "\n",
    "x=[]\n",
    "y=[]\n",
    "for features,label in training_data:\n",
    "    x.append(features)\n",
    "    y.append(label)\n",
    "x=np.asarray(x).reshape(-1,img_size,img_size,1)\n",
    "y=np.asarray(y)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=.25,random_state=42)\n",
    "\n",
    "model =Sequential()\n",
    "model.add(Dense(32,input_dim=1,activation='relu'))\n",
    "model.add(Dense(32,input_dim=1,activation='relu'))\n",
    "model.add(Dense(32,input_dim=1,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "             metrics=['binary_accuracy'])\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=100,batch_size=10,verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69261628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 621ms/step - loss: 0.2446 - binary_accuracy: 0.5924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24455218017101288, 0.59244704246521]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48fcc942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_85_input'), name='dense_85_input', description=\"created by layer 'dense_85_input'\"), but it was called on an input with incompatible shape (None, 500, 500, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_85_input'), name='dense_85_input', description=\"created by layer 'dense_85_input'\"), but it was called on an input with incompatible shape (None, 500, 500, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_85_input'), name='dense_85_input', description=\"created by layer 'dense_85_input'\"), but it was called on an input with incompatible shape (None, 500, 500, 1).\n",
      "2/2 - 7s - loss: 0.5296 - binary_accuracy: 0.2667 - val_loss: 0.3473 - val_binary_accuracy: 0.6000 - 7s/epoch - 4s/step\n",
      "Epoch 2/100\n",
      "2/2 - 6s - loss: 0.4439 - binary_accuracy: 0.4665 - val_loss: 0.3265 - val_binary_accuracy: 0.6000 - 6s/epoch - 3s/step\n",
      "Epoch 3/100\n",
      "2/2 - 6s - loss: 0.4094 - binary_accuracy: 0.4662 - val_loss: 0.2451 - val_binary_accuracy: 0.5859 - 6s/epoch - 3s/step\n",
      "Epoch 4/100\n",
      "2/2 - 6s - loss: 0.3097 - binary_accuracy: 0.4463 - val_loss: 0.4877 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 5/100\n",
      "2/2 - 5s - loss: 0.3710 - binary_accuracy: 0.5333 - val_loss: 0.2958 - val_binary_accuracy: 0.4000 - 5s/epoch - 3s/step\n",
      "Epoch 6/100\n",
      "2/2 - 5s - loss: 0.3807 - binary_accuracy: 0.3333 - val_loss: 0.2432 - val_binary_accuracy: 0.5924 - 5s/epoch - 3s/step\n",
      "Epoch 7/100\n",
      "2/2 - 5s - loss: 0.2621 - binary_accuracy: 0.5333 - val_loss: 0.2471 - val_binary_accuracy: 0.5784 - 5s/epoch - 3s/step\n",
      "Epoch 8/100\n",
      "2/2 - 5s - loss: 0.2919 - binary_accuracy: 0.4164 - val_loss: 0.2428 - val_binary_accuracy: 0.5924 - 5s/epoch - 3s/step\n",
      "Epoch 9/100\n",
      "2/2 - 6s - loss: 0.2552 - binary_accuracy: 0.5333 - val_loss: 0.2474 - val_binary_accuracy: 0.5945 - 6s/epoch - 3s/step\n",
      "Epoch 10/100\n",
      "2/2 - 6s - loss: 0.2446 - binary_accuracy: 0.6522 - val_loss: 0.4932 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 11/100\n",
      "2/2 - 6s - loss: 0.3882 - binary_accuracy: 0.5333 - val_loss: 0.4477 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 12/100\n",
      "2/2 - 6s - loss: 0.3511 - binary_accuracy: 0.5333 - val_loss: 0.3646 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 13/100\n",
      "2/2 - 6s - loss: 0.3163 - binary_accuracy: 0.4677 - val_loss: 0.4241 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 14/100\n",
      "2/2 - 5s - loss: 0.3217 - binary_accuracy: 0.5333 - val_loss: 0.2800 - val_binary_accuracy: 0.5960 - 5s/epoch - 3s/step\n",
      "Epoch 15/100\n",
      "2/2 - 5s - loss: 0.3071 - binary_accuracy: 0.5333 - val_loss: 0.3322 - val_binary_accuracy: 0.4000 - 5s/epoch - 3s/step\n",
      "Epoch 16/100\n",
      "2/2 - 6s - loss: 0.3130 - binary_accuracy: 0.4784 - val_loss: 0.3529 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 17/100\n",
      "2/2 - 6s - loss: 0.3848 - binary_accuracy: 0.3354 - val_loss: 0.4461 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 18/100\n",
      "2/2 - 7s - loss: 0.3513 - binary_accuracy: 0.5333 - val_loss: 0.3022 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 19/100\n",
      "2/2 - 6s - loss: 0.2491 - binary_accuracy: 0.5860 - val_loss: 0.2539 - val_binary_accuracy: 0.5953 - 6s/epoch - 3s/step\n",
      "Epoch 20/100\n",
      "2/2 - 6s - loss: 0.2838 - binary_accuracy: 0.5333 - val_loss: 0.2670 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 21/100\n",
      "2/2 - 5s - loss: 0.2537 - binary_accuracy: 0.5333 - val_loss: 0.2813 - val_binary_accuracy: 0.5960 - 5s/epoch - 3s/step\n",
      "Epoch 22/100\n",
      "2/2 - 6s - loss: 0.4317 - binary_accuracy: 0.2804 - val_loss: 0.3029 - val_binary_accuracy: 0.5960 - 6s/epoch - 3s/step\n",
      "Epoch 23/100\n",
      "2/2 - 6s - loss: 0.3630 - binary_accuracy: 0.4732 - val_loss: 0.3027 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 24/100\n",
      "2/2 - 5s - loss: 0.2639 - binary_accuracy: 0.5333 - val_loss: 0.2889 - val_binary_accuracy: 0.5960 - 5s/epoch - 3s/step\n",
      "Epoch 25/100\n",
      "2/2 - 6s - loss: 0.3386 - binary_accuracy: 0.4733 - val_loss: 0.3304 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 26/100\n",
      "2/2 - 7s - loss: 0.2867 - binary_accuracy: 0.4700 - val_loss: 0.3380 - val_binary_accuracy: 0.4000 - 7s/epoch - 4s/step\n",
      "Epoch 27/100\n",
      "2/2 - 7s - loss: 0.2638 - binary_accuracy: 0.5333 - val_loss: 0.2522 - val_binary_accuracy: 0.5945 - 7s/epoch - 3s/step\n",
      "Epoch 28/100\n",
      "2/2 - 6s - loss: 0.3191 - binary_accuracy: 0.4150 - val_loss: 0.2680 - val_binary_accuracy: 0.5953 - 6s/epoch - 3s/step\n",
      "Epoch 29/100\n",
      "2/2 - 6s - loss: 0.3007 - binary_accuracy: 0.4569 - val_loss: 0.4392 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 30/100\n",
      "2/2 - 6s - loss: 0.3324 - binary_accuracy: 0.5333 - val_loss: 0.3177 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 31/100\n",
      "2/2 - 6s - loss: 0.2594 - binary_accuracy: 0.5333 - val_loss: 0.2573 - val_binary_accuracy: 0.5953 - 6s/epoch - 3s/step\n",
      "Epoch 32/100\n",
      "2/2 - 6s - loss: 0.3312 - binary_accuracy: 0.4010 - val_loss: 0.2433 - val_binary_accuracy: 0.5884 - 6s/epoch - 3s/step\n",
      "Epoch 33/100\n",
      "2/2 - 7s - loss: 0.2512 - binary_accuracy: 0.5333 - val_loss: 0.2768 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 34/100\n",
      "2/2 - 6s - loss: 0.3258 - binary_accuracy: 0.3357 - val_loss: 0.3384 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 35/100\n",
      "2/2 - 7s - loss: 0.3380 - binary_accuracy: 0.3586 - val_loss: 0.3965 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 36/100\n",
      "2/2 - 6s - loss: 0.3130 - binary_accuracy: 0.5333 - val_loss: 0.2434 - val_binary_accuracy: 0.5877 - 6s/epoch - 3s/step\n",
      "Epoch 37/100\n",
      "2/2 - 6s - loss: 0.2819 - binary_accuracy: 0.4180 - val_loss: 0.2495 - val_binary_accuracy: 0.5945 - 6s/epoch - 3s/step\n",
      "Epoch 38/100\n",
      "2/2 - 6s - loss: 0.2686 - binary_accuracy: 0.5333 - val_loss: 0.2841 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 39/100\n",
      "2/2 - 6s - loss: 0.2683 - binary_accuracy: 0.4745 - val_loss: 0.3151 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 40/100\n",
      "2/2 - 6s - loss: 0.2555 - binary_accuracy: 0.5333 - val_loss: 0.2475 - val_binary_accuracy: 0.5934 - 6s/epoch - 3s/step\n",
      "Epoch 41/100\n",
      "2/2 - 6s - loss: 0.3121 - binary_accuracy: 0.4145 - val_loss: 0.2528 - val_binary_accuracy: 0.5945 - 6s/epoch - 3s/step\n",
      "Epoch 42/100\n",
      "2/2 - 6s - loss: 0.2768 - binary_accuracy: 0.5333 - val_loss: 0.2744 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 43/100\n",
      "2/2 - 6s - loss: 0.3977 - binary_accuracy: 0.2020 - val_loss: 0.3550 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 44/100\n",
      "2/2 - 6s - loss: 0.3286 - binary_accuracy: 0.3858 - val_loss: 0.3772 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 45/100\n",
      "2/2 - 5s - loss: 0.3138 - binary_accuracy: 0.5333 - val_loss: 0.2801 - val_binary_accuracy: 0.4000 - 5s/epoch - 3s/step\n",
      "Epoch 46/100\n",
      "2/2 - 6s - loss: 0.2643 - binary_accuracy: 0.4712 - val_loss: 0.3059 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 47/100\n",
      "2/2 - 6s - loss: 0.2754 - binary_accuracy: 0.4697 - val_loss: 0.3143 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 48/100\n",
      "2/2 - 6s - loss: 0.2564 - binary_accuracy: 0.5333 - val_loss: 0.2486 - val_binary_accuracy: 0.5934 - 6s/epoch - 3s/step\n",
      "Epoch 49/100\n",
      "2/2 - 5s - loss: 0.2675 - binary_accuracy: 0.5333 - val_loss: 0.2719 - val_binary_accuracy: 0.4000 - 5s/epoch - 3s/step\n",
      "Epoch 50/100\n",
      "2/2 - 6s - loss: 0.2596 - binary_accuracy: 0.4678 - val_loss: 0.3672 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 51/100\n",
      "2/2 - 6s - loss: 0.3387 - binary_accuracy: 0.3531 - val_loss: 0.4159 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 52/100\n",
      "2/2 - 6s - loss: 0.3280 - binary_accuracy: 0.5333 - val_loss: 0.2647 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 53/100\n",
      "2/2 - 6s - loss: 0.2578 - binary_accuracy: 0.4697 - val_loss: 0.3311 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 54/100\n",
      "2/2 - 6s - loss: 0.2630 - binary_accuracy: 0.5333 - val_loss: 0.2734 - val_binary_accuracy: 0.5953 - 6s/epoch - 3s/step\n",
      "Epoch 55/100\n",
      "2/2 - 6s - loss: 0.3103 - binary_accuracy: 0.4678 - val_loss: 0.3339 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "2/2 - 6s - loss: 0.2904 - binary_accuracy: 0.4853 - val_loss: 0.2859 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 57/100\n",
      "2/2 - 5s - loss: 0.2508 - binary_accuracy: 0.5333 - val_loss: 0.2519 - val_binary_accuracy: 0.5934 - 5s/epoch - 3s/step\n",
      "Epoch 58/100\n",
      "2/2 - 6s - loss: 0.2699 - binary_accuracy: 0.5333 - val_loss: 0.3016 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 59/100\n",
      "2/2 - 6s - loss: 0.3328 - binary_accuracy: 0.3368 - val_loss: 0.3952 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 60/100\n",
      "2/2 - 5s - loss: 0.3220 - binary_accuracy: 0.5333 - val_loss: 0.2831 - val_binary_accuracy: 0.4000 - 5s/epoch - 3s/step\n",
      "Epoch 61/100\n",
      "2/2 - 6s - loss: 0.2673 - binary_accuracy: 0.4687 - val_loss: 0.3294 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 62/100\n",
      "2/2 - 6s - loss: 0.2792 - binary_accuracy: 0.4870 - val_loss: 0.3071 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 63/100\n",
      "2/2 - 6s - loss: 0.3264 - binary_accuracy: 0.3565 - val_loss: 0.3882 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 64/100\n",
      "2/2 - 6s - loss: 0.3085 - binary_accuracy: 0.5333 - val_loss: 0.2443 - val_binary_accuracy: 0.5843 - 6s/epoch - 3s/step\n",
      "Epoch 65/100\n",
      "2/2 - 5s - loss: 0.3205 - binary_accuracy: 0.2828 - val_loss: 0.2433 - val_binary_accuracy: 0.5899 - 5s/epoch - 3s/step\n",
      "Epoch 66/100\n",
      "2/2 - 6s - loss: 0.2578 - binary_accuracy: 0.5333 - val_loss: 0.2773 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 67/100\n",
      "2/2 - 6s - loss: 0.2614 - binary_accuracy: 0.4773 - val_loss: 0.2867 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 68/100\n",
      "2/2 - 6s - loss: 0.2508 - binary_accuracy: 0.5333 - val_loss: 0.2453 - val_binary_accuracy: 0.5911 - 6s/epoch - 3s/step\n",
      "Epoch 69/100\n",
      "2/2 - 6s - loss: 0.2610 - binary_accuracy: 0.5333 - val_loss: 0.2828 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 70/100\n",
      "2/2 - 6s - loss: 0.2639 - binary_accuracy: 0.4687 - val_loss: 0.3320 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 71/100\n",
      "2/2 - 6s - loss: 0.2681 - binary_accuracy: 0.5333 - val_loss: 0.2698 - val_binary_accuracy: 0.5953 - 6s/epoch - 3s/step\n",
      "Epoch 72/100\n",
      "2/2 - 5s - loss: 0.2992 - binary_accuracy: 0.4723 - val_loss: 0.3244 - val_binary_accuracy: 0.4000 - 5s/epoch - 3s/step\n",
      "Epoch 73/100\n",
      "2/2 - 6s - loss: 0.2835 - binary_accuracy: 0.4716 - val_loss: 0.3298 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 74/100\n",
      "2/2 - 7s - loss: 0.2607 - binary_accuracy: 0.5333 - val_loss: 0.2452 - val_binary_accuracy: 0.5911 - 7s/epoch - 3s/step\n",
      "Epoch 75/100\n",
      "2/2 - 6s - loss: 0.2638 - binary_accuracy: 0.5333 - val_loss: 0.2750 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 76/100\n",
      "2/2 - 6s - loss: 0.2622 - binary_accuracy: 0.4761 - val_loss: 0.3371 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 77/100\n",
      "2/2 - 6s - loss: 0.2649 - binary_accuracy: 0.5333 - val_loss: 0.2495 - val_binary_accuracy: 0.5934 - 6s/epoch - 3s/step\n",
      "Epoch 78/100\n",
      "2/2 - 6s - loss: 0.2686 - binary_accuracy: 0.4593 - val_loss: 0.4241 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 79/100\n",
      "2/2 - 6s - loss: 0.3308 - binary_accuracy: 0.5333 - val_loss: 0.3559 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 80/100\n",
      "2/2 - 5s - loss: 0.2792 - binary_accuracy: 0.5333 - val_loss: 0.2519 - val_binary_accuracy: 0.5945 - 5s/epoch - 3s/step\n",
      "Epoch 81/100\n",
      "2/2 - 6s - loss: 0.2586 - binary_accuracy: 0.4738 - val_loss: 0.3869 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 82/100\n",
      "2/2 - 6s - loss: 0.3075 - binary_accuracy: 0.5333 - val_loss: 0.2434 - val_binary_accuracy: 0.5871 - 6s/epoch - 3s/step\n",
      "Epoch 83/100\n",
      "2/2 - 6s - loss: 0.3246 - binary_accuracy: 0.2781 - val_loss: 0.2438 - val_binary_accuracy: 0.5924 - 6s/epoch - 3s/step\n",
      "Epoch 84/100\n",
      "2/2 - 6s - loss: 0.2623 - binary_accuracy: 0.4579 - val_loss: 0.3611 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 85/100\n",
      "2/2 - 6s - loss: 0.2980 - binary_accuracy: 0.5333 - val_loss: 0.2432 - val_binary_accuracy: 0.5899 - 6s/epoch - 3s/step\n",
      "Epoch 86/100\n",
      "2/2 - 5s - loss: 0.2587 - binary_accuracy: 0.5333 - val_loss: 0.2689 - val_binary_accuracy: 0.4000 - 5s/epoch - 3s/step\n",
      "Epoch 87/100\n",
      "2/2 - 5s - loss: 0.2878 - binary_accuracy: 0.3562 - val_loss: 0.3134 - val_binary_accuracy: 0.4000 - 5s/epoch - 3s/step\n",
      "Epoch 88/100\n",
      "2/2 - 6s - loss: 0.2687 - binary_accuracy: 0.5333 - val_loss: 0.2738 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 89/100\n",
      "2/2 - 6s - loss: 0.2575 - binary_accuracy: 0.4809 - val_loss: 0.2822 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 90/100\n",
      "2/2 - 5s - loss: 0.2586 - binary_accuracy: 0.4775 - val_loss: 0.2965 - val_binary_accuracy: 0.4000 - 5s/epoch - 3s/step\n",
      "Epoch 91/100\n",
      "2/2 - 6s - loss: 0.3090 - binary_accuracy: 0.3374 - val_loss: 0.3505 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 92/100\n",
      "2/2 - 6s - loss: 0.2905 - binary_accuracy: 0.5333 - val_loss: 0.2704 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 93/100\n",
      "2/2 - 6s - loss: 0.2535 - binary_accuracy: 0.5333 - val_loss: 0.2452 - val_binary_accuracy: 0.5911 - 6s/epoch - 3s/step\n",
      "Epoch 94/100\n",
      "2/2 - 5s - loss: 0.3515 - binary_accuracy: 0.2720 - val_loss: 0.2436 - val_binary_accuracy: 0.5865 - 5s/epoch - 3s/step\n",
      "Epoch 95/100\n",
      "2/2 - 6s - loss: 0.2507 - binary_accuracy: 0.5333 - val_loss: 0.2904 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 96/100\n",
      "2/2 - 5s - loss: 0.3178 - binary_accuracy: 0.3555 - val_loss: 0.2977 - val_binary_accuracy: 0.4000 - 5s/epoch - 3s/step\n",
      "Epoch 97/100\n",
      "2/2 - 5s - loss: 0.2540 - binary_accuracy: 0.5333 - val_loss: 0.2444 - val_binary_accuracy: 0.5911 - 5s/epoch - 3s/step\n",
      "Epoch 98/100\n",
      "2/2 - 6s - loss: 0.2602 - binary_accuracy: 0.5333 - val_loss: 0.2774 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 99/100\n",
      "2/2 - 5s - loss: 0.3063 - binary_accuracy: 0.3585 - val_loss: 0.3351 - val_binary_accuracy: 0.4000 - 5s/epoch - 3s/step\n",
      "Epoch 100/100\n",
      "2/2 - 5s - loss: 0.2843 - binary_accuracy: 0.5333 - val_loss: 0.2756 - val_binary_accuracy: 0.4000 - 5s/epoch - 3s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23888e90a30>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4 layer\n",
    "\n",
    "training_data = []\n",
    "img_size=500\n",
    "\n",
    "def create_training_data():\n",
    "    for category in categories:\n",
    "        path = os.path.join(datadir,category)\n",
    "        class_num = categories.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n",
    "            num_array=cv2.resize(img_array,(img_size,img_size))\n",
    "            training_data.append([num_array,class_num])\n",
    "create_training_data()\n",
    "\n",
    "\n",
    "x=[]\n",
    "y=[]\n",
    "for features,label in training_data:\n",
    "    x.append(features)\n",
    "    y.append(label)\n",
    "x=np.asarray(x).reshape(-1,img_size,img_size,1)\n",
    "y=np.asarray(y)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=.25,random_state=42)\n",
    "\n",
    "model =Sequential()\n",
    "model.add(Dense(32,input_dim=1,activation='relu'))\n",
    "model.add(Dense(32,input_dim=1,activation='relu'))\n",
    "model.add(Dense(32,input_dim=1,activation='relu'))\n",
    "model.add(Dense(32,input_dim=1,activation='relu'))\n",
    "\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "             metrics=['binary_accuracy'])\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=100,batch_size=10,verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cb220d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 687ms/step - loss: 0.2756 - binary_accuracy: 0.4000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.27564671635627747, 0.40000054240226746]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c9126f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_90_input'), name='dense_90_input', description=\"created by layer 'dense_90_input'\"), but it was called on an input with incompatible shape (None, 500, 500, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_90_input'), name='dense_90_input', description=\"created by layer 'dense_90_input'\"), but it was called on an input with incompatible shape (None, 500, 500, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_90_input'), name='dense_90_input', description=\"created by layer 'dense_90_input'\"), but it was called on an input with incompatible shape (None, 500, 500, 1).\n",
      "2/2 - 9s - loss: 0.4430 - binary_accuracy: 0.3340 - val_loss: 0.3717 - val_binary_accuracy: 0.6000 - 9s/epoch - 5s/step\n",
      "Epoch 2/100\n",
      "2/2 - 7s - loss: 0.4837 - binary_accuracy: 0.4662 - val_loss: 0.3640 - val_binary_accuracy: 0.6000 - 7s/epoch - 3s/step\n",
      "Epoch 3/100\n",
      "2/2 - 7s - loss: 0.4673 - binary_accuracy: 0.4667 - val_loss: 0.3271 - val_binary_accuracy: 0.5997 - 7s/epoch - 4s/step\n",
      "Epoch 4/100\n",
      "2/2 - 7s - loss: 0.5160 - binary_accuracy: 0.2688 - val_loss: 0.3649 - val_binary_accuracy: 0.5997 - 7s/epoch - 3s/step\n",
      "Epoch 5/100\n",
      "2/2 - 7s - loss: 0.4726 - binary_accuracy: 0.4673 - val_loss: 0.3591 - val_binary_accuracy: 0.5997 - 7s/epoch - 3s/step\n",
      "Epoch 6/100\n",
      "2/2 - 7s - loss: 0.4875 - binary_accuracy: 0.4657 - val_loss: 0.3489 - val_binary_accuracy: 0.5997 - 7s/epoch - 3s/step\n",
      "Epoch 7/100\n",
      "2/2 - 7s - loss: 0.4727 - binary_accuracy: 0.4648 - val_loss: 0.2765 - val_binary_accuracy: 0.5945 - 7s/epoch - 4s/step\n",
      "Epoch 8/100\n",
      "2/2 - 7s - loss: 0.3277 - binary_accuracy: 0.5333 - val_loss: 0.3700 - val_binary_accuracy: 0.4000 - 7s/epoch - 4s/step\n",
      "Epoch 9/100\n",
      "2/2 - 7s - loss: 0.2335 - binary_accuracy: 0.6888 - val_loss: 0.3546 - val_binary_accuracy: 0.5997 - 7s/epoch - 3s/step\n",
      "Epoch 10/100\n",
      "2/2 - 6s - loss: 0.4447 - binary_accuracy: 0.4675 - val_loss: 0.3395 - val_binary_accuracy: 0.5960 - 6s/epoch - 3s/step\n",
      "Epoch 11/100\n",
      "2/2 - 7s - loss: 0.4327 - binary_accuracy: 0.4668 - val_loss: 0.2662 - val_binary_accuracy: 0.4000 - 7s/epoch - 4s/step\n",
      "Epoch 12/100\n",
      "2/2 - 7s - loss: 0.3059 - binary_accuracy: 0.4673 - val_loss: 0.4768 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 13/100\n",
      "2/2 - 8s - loss: 0.3702 - binary_accuracy: 0.5333 - val_loss: 0.2574 - val_binary_accuracy: 0.4000 - 8s/epoch - 4s/step\n",
      "Epoch 14/100\n",
      "2/2 - 7s - loss: 0.2731 - binary_accuracy: 0.4679 - val_loss: 0.5031 - val_binary_accuracy: 0.4000 - 7s/epoch - 4s/step\n",
      "Epoch 15/100\n",
      "2/2 - 7s - loss: 0.3953 - binary_accuracy: 0.5333 - val_loss: 0.4347 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 16/100\n",
      "2/2 - 7s - loss: 0.3990 - binary_accuracy: 0.3732 - val_loss: 0.5060 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 17/100\n",
      "2/2 - 7s - loss: 0.3952 - binary_accuracy: 0.5333 - val_loss: 0.4664 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 18/100\n",
      "2/2 - 7s - loss: 0.3605 - binary_accuracy: 0.5333 - val_loss: 0.2433 - val_binary_accuracy: 0.5853 - 7s/epoch - 3s/step\n",
      "Epoch 19/100\n",
      "2/2 - 6s - loss: 0.2640 - binary_accuracy: 0.5333 - val_loss: 0.2479 - val_binary_accuracy: 0.5587 - 6s/epoch - 3s/step\n",
      "Epoch 20/100\n",
      "2/2 - 6s - loss: 0.3099 - binary_accuracy: 0.4219 - val_loss: 0.3049 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 21/100\n",
      "2/2 - 7s - loss: 0.2540 - binary_accuracy: 0.5865 - val_loss: 0.2777 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 22/100\n",
      "2/2 - 7s - loss: 0.2456 - binary_accuracy: 0.5333 - val_loss: 0.3112 - val_binary_accuracy: 0.5960 - 7s/epoch - 3s/step\n",
      "Epoch 23/100\n",
      "2/2 - 6s - loss: 0.3494 - binary_accuracy: 0.4570 - val_loss: 0.5210 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 24/100\n",
      "2/2 - 7s - loss: 0.4033 - binary_accuracy: 0.5333 - val_loss: 0.4983 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 25/100\n",
      "2/2 - 7s - loss: 0.3831 - binary_accuracy: 0.5333 - val_loss: 0.4408 - val_binary_accuracy: 0.4000 - 7s/epoch - 4s/step\n",
      "Epoch 26/100\n",
      "2/2 - 7s - loss: 0.3405 - binary_accuracy: 0.5333 - val_loss: 0.2446 - val_binary_accuracy: 0.5934 - 7s/epoch - 3s/step\n",
      "Epoch 27/100\n",
      "2/2 - 7s - loss: 0.3554 - binary_accuracy: 0.4157 - val_loss: 0.3496 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 28/100\n",
      "2/2 - 7s - loss: 0.3303 - binary_accuracy: 0.4671 - val_loss: 0.3902 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 29/100\n",
      "2/2 - 7s - loss: 0.2850 - binary_accuracy: 0.5333 - val_loss: 0.2832 - val_binary_accuracy: 0.5960 - 7s/epoch - 4s/step\n",
      "Epoch 30/100\n",
      "2/2 - 7s - loss: 0.2835 - binary_accuracy: 0.4899 - val_loss: 0.4933 - val_binary_accuracy: 0.4000 - 7s/epoch - 4s/step\n",
      "Epoch 31/100\n",
      "2/2 - 9s - loss: 0.3928 - binary_accuracy: 0.5333 - val_loss: 0.4434 - val_binary_accuracy: 0.4000 - 9s/epoch - 4s/step\n",
      "Epoch 32/100\n",
      "2/2 - 8s - loss: 0.3341 - binary_accuracy: 0.5333 - val_loss: 0.2427 - val_binary_accuracy: 0.5945 - 8s/epoch - 4s/step\n",
      "Epoch 33/100\n",
      "2/2 - 7s - loss: 0.3976 - binary_accuracy: 0.2830 - val_loss: 0.3931 - val_binary_accuracy: 0.4000 - 7s/epoch - 4s/step\n",
      "Epoch 34/100\n",
      "2/2 - 7s - loss: 0.3057 - binary_accuracy: 0.5333 - val_loss: 0.2980 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 35/100\n",
      "2/2 - 6s - loss: 0.3007 - binary_accuracy: 0.4669 - val_loss: 0.4215 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 36/100\n",
      "2/2 - 7s - loss: 0.3440 - binary_accuracy: 0.5333 - val_loss: 0.4249 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 37/100\n",
      "2/2 - 7s - loss: 0.3305 - binary_accuracy: 0.5333 - val_loss: 0.2706 - val_binary_accuracy: 0.6000 - 7s/epoch - 4s/step\n",
      "Epoch 38/100\n",
      "2/2 - 7s - loss: 0.3032 - binary_accuracy: 0.5333 - val_loss: 0.2648 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 39/100\n",
      "2/2 - 8s - loss: 0.3475 - binary_accuracy: 0.3333 - val_loss: 0.3941 - val_binary_accuracy: 0.4000 - 8s/epoch - 4s/step\n",
      "Epoch 40/100\n",
      "2/2 - 6s - loss: 0.3119 - binary_accuracy: 0.5333 - val_loss: 0.2722 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 41/100\n",
      "2/2 - 6s - loss: 0.2526 - binary_accuracy: 0.5333 - val_loss: 0.2954 - val_binary_accuracy: 0.5997 - 6s/epoch - 3s/step\n",
      "Epoch 42/100\n",
      "2/2 - 7s - loss: 0.3340 - binary_accuracy: 0.4671 - val_loss: 0.4545 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 43/100\n",
      "2/2 - 7s - loss: 0.3546 - binary_accuracy: 0.5333 - val_loss: 0.3028 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 44/100\n",
      "2/2 - 7s - loss: 0.2846 - binary_accuracy: 0.4722 - val_loss: 0.3955 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 45/100\n",
      "2/2 - 6s - loss: 0.3967 - binary_accuracy: 0.2089 - val_loss: 0.4822 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 46/100\n",
      "2/2 - 7s - loss: 0.3789 - binary_accuracy: 0.5333 - val_loss: 0.4513 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 47/100\n",
      "2/2 - 7s - loss: 0.3572 - binary_accuracy: 0.5333 - val_loss: 0.3620 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 48/100\n",
      "2/2 - 7s - loss: 0.2949 - binary_accuracy: 0.5333 - val_loss: 0.3021 - val_binary_accuracy: 0.4000 - 7s/epoch - 4s/step\n",
      "Epoch 49/100\n",
      "2/2 - 7s - loss: 0.2809 - binary_accuracy: 0.4670 - val_loss: 0.3787 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 50/100\n",
      "2/2 - 7s - loss: 0.3023 - binary_accuracy: 0.5333 - val_loss: 0.2687 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 51/100\n",
      "2/2 - 6s - loss: 0.2664 - binary_accuracy: 0.4677 - val_loss: 0.3368 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 52/100\n",
      "2/2 - 7s - loss: 0.2913 - binary_accuracy: 0.4730 - val_loss: 0.3802 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 53/100\n",
      "2/2 - 7s - loss: 0.3100 - binary_accuracy: 0.5333 - val_loss: 0.2892 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 54/100\n",
      "2/2 - 6s - loss: 0.2481 - binary_accuracy: 0.5333 - val_loss: 0.2566 - val_binary_accuracy: 0.5960 - 6s/epoch - 3s/step\n",
      "Epoch 55/100\n",
      "2/2 - 7s - loss: 0.2871 - binary_accuracy: 0.5333 - val_loss: 0.2644 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "2/2 - 7s - loss: 0.2648 - binary_accuracy: 0.4731 - val_loss: 0.3356 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 57/100\n",
      "2/2 - 7s - loss: 0.2911 - binary_accuracy: 0.4669 - val_loss: 0.4027 - val_binary_accuracy: 0.4000 - 7s/epoch - 4s/step\n",
      "Epoch 58/100\n",
      "2/2 - 7s - loss: 0.3103 - binary_accuracy: 0.5333 - val_loss: 0.2595 - val_binary_accuracy: 0.5960 - 7s/epoch - 3s/step\n",
      "Epoch 59/100\n",
      "2/2 - 7s - loss: 0.2844 - binary_accuracy: 0.5333 - val_loss: 0.2672 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 60/100\n",
      "2/2 - 7s - loss: 0.3221 - binary_accuracy: 0.3528 - val_loss: 0.3156 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 61/100\n",
      "2/2 - 7s - loss: 0.2555 - binary_accuracy: 0.5333 - val_loss: 0.2571 - val_binary_accuracy: 0.5953 - 7s/epoch - 3s/step\n",
      "Epoch 62/100\n",
      "2/2 - 7s - loss: 0.2818 - binary_accuracy: 0.5333 - val_loss: 0.2710 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 63/100\n",
      "2/2 - 7s - loss: 0.3250 - binary_accuracy: 0.3550 - val_loss: 0.3446 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 64/100\n",
      "2/2 - 7s - loss: 0.2683 - binary_accuracy: 0.5333 - val_loss: 0.2461 - val_binary_accuracy: 0.5945 - 7s/epoch - 3s/step\n",
      "Epoch 65/100\n",
      "2/2 - 6s - loss: 0.2661 - binary_accuracy: 0.5333 - val_loss: 0.2705 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 66/100\n",
      "2/2 - 7s - loss: 0.2512 - binary_accuracy: 0.5333 - val_loss: 0.2567 - val_binary_accuracy: 0.5953 - 7s/epoch - 4s/step\n",
      "Epoch 67/100\n",
      "2/2 - 7s - loss: 0.3251 - binary_accuracy: 0.4074 - val_loss: 0.2656 - val_binary_accuracy: 0.5953 - 7s/epoch - 3s/step\n",
      "Epoch 68/100\n",
      "2/2 - 7s - loss: 0.3824 - binary_accuracy: 0.2939 - val_loss: 0.2906 - val_binary_accuracy: 0.5960 - 7s/epoch - 3s/step\n",
      "Epoch 69/100\n",
      "2/2 - 7s - loss: 0.3608 - binary_accuracy: 0.4654 - val_loss: 0.2430 - val_binary_accuracy: 0.5899 - 7s/epoch - 3s/step\n",
      "Epoch 70/100\n",
      "2/2 - 7s - loss: 0.3422 - binary_accuracy: 0.2894 - val_loss: 0.2473 - val_binary_accuracy: 0.5934 - 7s/epoch - 3s/step\n",
      "Epoch 71/100\n",
      "2/2 - 7s - loss: 0.3451 - binary_accuracy: 0.2840 - val_loss: 0.2495 - val_binary_accuracy: 0.5934 - 7s/epoch - 3s/step\n",
      "Epoch 72/100\n",
      "2/2 - 7s - loss: 0.3089 - binary_accuracy: 0.4091 - val_loss: 0.2554 - val_binary_accuracy: 0.5953 - 7s/epoch - 3s/step\n",
      "Epoch 73/100\n",
      "2/2 - 6s - loss: 0.2856 - binary_accuracy: 0.4706 - val_loss: 0.2733 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 74/100\n",
      "2/2 - 7s - loss: 0.2563 - binary_accuracy: 0.4746 - val_loss: 0.2866 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 75/100\n",
      "2/2 - 7s - loss: 0.2512 - binary_accuracy: 0.5333 - val_loss: 0.2429 - val_binary_accuracy: 0.5911 - 7s/epoch - 4s/step\n",
      "Epoch 76/100\n",
      "2/2 - 7s - loss: 0.2639 - binary_accuracy: 0.4567 - val_loss: 0.3861 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 77/100\n",
      "2/2 - 7s - loss: 0.3237 - binary_accuracy: 0.5333 - val_loss: 0.3416 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 78/100\n",
      "2/2 - 7s - loss: 0.2832 - binary_accuracy: 0.5333 - val_loss: 0.2710 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 79/100\n",
      "2/2 - 7s - loss: 0.2524 - binary_accuracy: 0.5333 - val_loss: 0.2466 - val_binary_accuracy: 0.5934 - 7s/epoch - 3s/step\n",
      "Epoch 80/100\n",
      "2/2 - 7s - loss: 0.2667 - binary_accuracy: 0.4584 - val_loss: 0.3975 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 81/100\n",
      "2/2 - 7s - loss: 0.3146 - binary_accuracy: 0.5333 - val_loss: 0.2671 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 82/100\n",
      "2/2 - 7s - loss: 0.2541 - binary_accuracy: 0.5333 - val_loss: 0.2518 - val_binary_accuracy: 0.5945 - 7s/epoch - 3s/step\n",
      "Epoch 83/100\n",
      "2/2 - 6s - loss: 0.3068 - binary_accuracy: 0.4085 - val_loss: 0.2505 - val_binary_accuracy: 0.5945 - 6s/epoch - 3s/step\n",
      "Epoch 84/100\n",
      "2/2 - 7s - loss: 0.3637 - binary_accuracy: 0.2827 - val_loss: 0.2541 - val_binary_accuracy: 0.5945 - 7s/epoch - 3s/step\n",
      "Epoch 85/100\n",
      "2/2 - 7s - loss: 0.3150 - binary_accuracy: 0.4074 - val_loss: 0.2439 - val_binary_accuracy: 0.5865 - 7s/epoch - 3s/step\n",
      "Epoch 86/100\n",
      "2/2 - 7s - loss: 0.2589 - binary_accuracy: 0.4785 - val_loss: 0.3248 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 87/100\n",
      "2/2 - 7s - loss: 0.2640 - binary_accuracy: 0.5333 - val_loss: 0.2438 - val_binary_accuracy: 0.5865 - 7s/epoch - 3s/step\n",
      "Epoch 88/100\n",
      "2/2 - 7s - loss: 0.2512 - binary_accuracy: 0.5333 - val_loss: 0.2853 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 89/100\n",
      "2/2 - 7s - loss: 0.2535 - binary_accuracy: 0.5333 - val_loss: 0.2484 - val_binary_accuracy: 0.5934 - 7s/epoch - 3s/step\n",
      "Epoch 90/100\n",
      "2/2 - 6s - loss: 0.3035 - binary_accuracy: 0.4023 - val_loss: 0.2430 - val_binary_accuracy: 0.5899 - 6s/epoch - 3s/step\n",
      "Epoch 91/100\n",
      "2/2 - 6s - loss: 0.2558 - binary_accuracy: 0.5333 - val_loss: 0.2761 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 92/100\n",
      "2/2 - 6s - loss: 0.2570 - binary_accuracy: 0.4732 - val_loss: 0.3099 - val_binary_accuracy: 0.4000 - 6s/epoch - 3s/step\n",
      "Epoch 93/100\n",
      "2/2 - 7s - loss: 0.3179 - binary_accuracy: 0.3378 - val_loss: 0.3521 - val_binary_accuracy: 0.4000 - 7s/epoch - 4s/step\n",
      "Epoch 94/100\n",
      "2/2 - 7s - loss: 0.2825 - binary_accuracy: 0.5333 - val_loss: 0.2429 - val_binary_accuracy: 0.5891 - 7s/epoch - 3s/step\n",
      "Epoch 95/100\n",
      "2/2 - 7s - loss: 0.2802 - binary_accuracy: 0.4028 - val_loss: 0.2565 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 96/100\n",
      "2/2 - 7s - loss: 0.2514 - binary_accuracy: 0.4790 - val_loss: 0.2818 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 97/100\n",
      "2/2 - 7s - loss: 0.2788 - binary_accuracy: 0.5333 - val_loss: 0.2611 - val_binary_accuracy: 0.5953 - 7s/epoch - 3s/step\n",
      "Epoch 98/100\n",
      "2/2 - 7s - loss: 0.2949 - binary_accuracy: 0.4583 - val_loss: 0.3113 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 99/100\n",
      "2/2 - 7s - loss: 0.2735 - binary_accuracy: 0.5333 - val_loss: 0.2741 - val_binary_accuracy: 0.4000 - 7s/epoch - 3s/step\n",
      "Epoch 100/100\n",
      "2/2 - 7s - loss: 0.2553 - binary_accuracy: 0.5333 - val_loss: 0.2437 - val_binary_accuracy: 0.5899 - 7s/epoch - 4s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2388213a820>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5 layer\n",
    "\n",
    "training_data = []\n",
    "img_size=500\n",
    "\n",
    "def create_training_data():\n",
    "    for category in categories:\n",
    "        path = os.path.join(datadir,category)\n",
    "        class_num = categories.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n",
    "            num_array=cv2.resize(img_array,(img_size,img_size))\n",
    "            training_data.append([num_array,class_num])\n",
    "create_training_data()\n",
    "\n",
    "\n",
    "x=[]\n",
    "y=[]\n",
    "for features,label in training_data:\n",
    "    x.append(features)\n",
    "    y.append(label)\n",
    "x=np.asarray(x).reshape(-1,img_size,img_size,1)\n",
    "y=np.asarray(y)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=.25,random_state=42)\n",
    "\n",
    "model =Sequential()\n",
    "model.add(Dense(32,input_dim=1,activation='relu'))\n",
    "model.add(Dense(32,input_dim=1,activation='relu'))\n",
    "model.add(Dense(32,input_dim=1,activation='relu'))\n",
    "model.add(Dense(32,input_dim=1,activation='relu'))\n",
    "model.add(Dense(32,input_dim=1,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "             metrics=['binary_accuracy'])\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=100,batch_size=10,verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4610675a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 920ms/step - loss: 0.2437 - binary_accuracy: 0.5899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24370649456977844, 0.5898807048797607]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562b7995",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
